<!DOCTYPE html>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="UTF-8">

    

    

    <title>Flink笔记 | Coderss</title>
    <meta name="author" content="coder">
    <meta name="version" content="1.0.0">
    <meta name="keywords" content="">
    <meta name="description" content="Flink相关笔记 
Flink设计理念与基本架构Flink与主流计算引擎对比Hadoop MapReduceMapReduce是由谷歌首次在论文“MapReduce: Simplified Data Processing on Large Clusters”（谷歌大数据三驾马车之一）中提出的，是一种处理和生成大数据的编程模型。Hadoop MapReduce借鉴了谷歌这篇论文的思想，将大的任务分拆成较小的任务后进行处理，因此拥有更好的扩展性。

如图所示，Hadoop MapReduce包括两">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    <meta name="baidu-site-verification" content="F0CXvmUgA9">

    
    
    <link rel="icon" href="/favicon.png">
    

    <link rel="stylesheet" href="/css/style.css">
</head>
<body>

    <div class="app">
        <header class="header clearfix">
    <div id="nav" class="nav">
    <button id="open-panel" class="open-panel"><i class="icon-library"></i></button>

    <nav class="nav-inner">

        
        
        <li class="nav-item">
            <a class="nav-link" href="/">首页</a>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/categories/back-end">Java后端</a>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/categories/cpp">Cpp嵌入式</a>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/categories/go">Go云原生</a>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/categories/cloud">Linux安全</a>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/categories/reverse">Win安全</a>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/categories/data">数据与算法</a>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/categories/work">工作相关</a>
        </li>
        
        
        
        <li class="nav-item nav-item-tag">
            <a id="nav-tag" class="nav-link" href="#">文章标签</a>
            <div id="nav-tags" class="nav-tag-wrap">
                <i class="nav-tag-arrow"></i>
                
  <div class="widget-wrap">
    <h3 class="widget-title">
        <i class="icon-tag vm"></i>
        <span class="vm">Tags</span>
    </h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AI/">AI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Boost库/">Boost库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Collection/">Collection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Cpp编程/">Cpp编程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Fescar/">Fescar</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gc/">Gc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/K8s/">K8s</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MapReduce/">MapReduce</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Math/">Math</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Net/">Net</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nosql/">Nosql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python计算库/">Python计算库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Rust/">Rust</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sharding-jdbc/">Sharding-jdbc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SkyWalking/">SkyWalking</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/">Spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TensorFlow/">TensorFlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Turi/">Turi</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Windows系统/">Windows系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Windows驱动/">Windows驱动</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Yarn/">Yarn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/assembly/">assembly</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/c-cpp语言/">c/cpp语言</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/debug/">debug</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/design/">design</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/">docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dubbo/">dubbo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/eth/">eth</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flume/">flume</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go/">go</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go-kernel/">go-kernel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/io/">io</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/juc/">juc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kubernetes/">kubernetes</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/map/">map</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mfc/">mfc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/microservice/">microservice</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mybatis/">mybatis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/netty/">netty</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python-book/">python-book</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/qt/">qt</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sentinel/">sentinel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/skycoin/">skycoin</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spring/">spring</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spring-cloud/">spring-cloud</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/stl/">stl</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tomcat/">tomcat</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/x86-Windows系统总结/">x86 Windows系统总结</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/中台/">中台</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分布式文件系统/">分布式文件系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/多线程编程/">多线程编程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/嵌入式/">嵌入式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/架构/">架构</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/消息队列/">消息队列</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网络编程/">网络编程</a></li></ul>
    </div>
  </div>


            </div>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/archives">历史归档</a>
        </li>
        
        
        

    </nav>
</div>

    <aside id="aside" class="aside">
    <div id="aside-mask" class="aside-mask"></div>
    <div id="aside-inner" class="aside-inner">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"><i class="icon-search-stroke"></i></button><input type="hidden" name="sitesearch" value="http://www.coderss.cn"></form>

        
        
        
        
        

        
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Flink设计理念与基本架构"><span class="toc-number">1.</span> <span class="toc-text">Flink设计理念与基本架构</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Flink与主流计算引擎对比"><span class="toc-number">1.1.</span> <span class="toc-text">Flink与主流计算引擎对比</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Hadoop-MapReduce"><span class="toc-number">1.1.1.</span> <span class="toc-text">Hadoop MapReduce</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark"><span class="toc-number">1.1.2.</span> <span class="toc-text">Spark</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Flink"><span class="toc-number">1.1.3.</span> <span class="toc-text">Flink</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Flink基本架构"><span class="toc-number">1.2.</span> <span class="toc-text">Flink基本架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#分层架构"><span class="toc-number">1.2.1.</span> <span class="toc-text">分层架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#运行时架构"><span class="toc-number">1.2.2.</span> <span class="toc-text">运行时架构</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#编程模型与API"><span class="toc-number">2.</span> <span class="toc-text">编程模型与API</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#DataStream"><span class="toc-number">2.1.</span> <span class="toc-text">DataStream</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#算子"><span class="toc-number">2.2.</span> <span class="toc-text">算子</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#StreamFlatMap"><span class="toc-number">2.2.1.</span> <span class="toc-text">StreamFlatMap</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#keyBy规则分区"><span class="toc-number">2.2.2.</span> <span class="toc-text">keyBy规则分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#aggregation聚合计算"><span class="toc-number">2.2.3.</span> <span class="toc-text">aggregation聚合计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#window及window-apply"><span class="toc-number">2.2.4.</span> <span class="toc-text">window及window apply</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#union"><span class="toc-number">2.2.5.</span> <span class="toc-text">union</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#window-join"><span class="toc-number">2.2.6.</span> <span class="toc-text">window join</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#interval-join"><span class="toc-number">2.2.7.</span> <span class="toc-text">interval join</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#窗口"><span class="toc-number">2.3.</span> <span class="toc-text">窗口</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#窗口的基本概念"><span class="toc-number">2.3.1.</span> <span class="toc-text">窗口的基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Keyed-Window"><span class="toc-number">2.3.1.1.</span> <span class="toc-text">Keyed Window</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Non-Keyed-Window"><span class="toc-number">2.3.1.2.</span> <span class="toc-text">Non-Keyed Window</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#窗口的执行流程"><span class="toc-number">2.3.2.</span> <span class="toc-text">窗口的执行流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#窗口分配器"><span class="toc-number">2.3.3.</span> <span class="toc-text">窗口分配器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#滚动窗口"><span class="toc-number">2.3.3.1.</span> <span class="toc-text">滚动窗口</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#滑动窗口"><span class="toc-number">2.3.3.2.</span> <span class="toc-text">滑动窗口</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#会话窗口"><span class="toc-number">2.3.3.3.</span> <span class="toc-text">会话窗口</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#全局窗口"><span class="toc-number">2.3.3.4.</span> <span class="toc-text">全局窗口</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#触发器"><span class="toc-number">2.3.4.</span> <span class="toc-text">触发器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#窗口函数"><span class="toc-number">2.3.5.</span> <span class="toc-text">窗口函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#ReduceFunction"><span class="toc-number">2.3.5.1.</span> <span class="toc-text">ReduceFunction</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AggregateFunction"><span class="toc-number">2.3.5.2.</span> <span class="toc-text">AggregateFunction</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#运行时组件与通信"><span class="toc-number">3.</span> <span class="toc-text">运行时组件与通信</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#运行时组件"><span class="toc-number">3.1.</span> <span class="toc-text">运行时组件</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#REST"><span class="toc-number">3.1.1.</span> <span class="toc-text">REST</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#初始化所有Handler"><span class="toc-number">3.1.1.1.</span> <span class="toc-text">初始化所有Handler</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Handler注册Router"><span class="toc-number">3.1.1.2.</span> <span class="toc-text">Handler注册Router</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#创建与启动NettyServer"><span class="toc-number">3.1.1.3.</span> <span class="toc-text">创建与启动NettyServer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#启动Leader选举服务"><span class="toc-number">3.1.1.4.</span> <span class="toc-text">启动Leader选举服务</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dispatcher"><span class="toc-number">3.1.2.</span> <span class="toc-text">Dispatcher</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#检查作业是否重复"><span class="toc-number">3.1.2.1.</span> <span class="toc-text">检查作业是否重复</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#作业提交过程"><span class="toc-number">3.1.2.2.</span> <span class="toc-text">作业提交过程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ResourceManager"><span class="toc-number">3.1.3.</span> <span class="toc-text">ResourceManager</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#SlotManager"><span class="toc-number">3.1.3.1.</span> <span class="toc-text">SlotManager</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#组件间通信"><span class="toc-number">3.2.</span> <span class="toc-text">组件间通信</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Akka与Actor模型"><span class="toc-number">3.2.1.</span> <span class="toc-text">Akka与Actor模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RemoteServerActor的实现"><span class="toc-number">3.2.1.1.</span> <span class="toc-text">RemoteServerActor的实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RemoteServerActorLauncher"><span class="toc-number">3.2.1.2.</span> <span class="toc-text">RemoteServerActorLauncher</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LocalClient"><span class="toc-number">3.2.1.3.</span> <span class="toc-text">LocalClient</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#总结流程"><span class="toc-number">3.2.1.4.</span> <span class="toc-text">总结流程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#组件间通信实现"><span class="toc-number">3.2.2.</span> <span class="toc-text">组件间通信实现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#AkkaRpcActor"><span class="toc-number">3.2.2.1.</span> <span class="toc-text">AkkaRpcActor</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AkkaRpcService"><span class="toc-number">3.2.2.2.</span> <span class="toc-text">AkkaRpcService</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AkkaInvocationHandler"><span class="toc-number">3.2.2.3.</span> <span class="toc-text">AkkaInvocationHandler</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#状态管理与容错"><span class="toc-number">4.</span> <span class="toc-text">状态管理与容错</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#状态"><span class="toc-number">4.1.</span> <span class="toc-text">状态</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#状态的原理与实现"><span class="toc-number">4.1.1.</span> <span class="toc-text">状态的原理与实现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Managed-Keyed-State介绍"><span class="toc-number">4.1.1.1.</span> <span class="toc-text">Managed Keyed State介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Managed-Operator-State介绍"><span class="toc-number">4.1.1.2.</span> <span class="toc-text">Managed Operator State介绍</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#检查点"><span class="toc-number">4.2.</span> <span class="toc-text">检查点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#检查点机制原理"><span class="toc-number">4.2.1.</span> <span class="toc-text">检查点机制原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#检查点执行过程"><span class="toc-number">4.2.2.</span> <span class="toc-text">检查点执行过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#任务容错"><span class="toc-number">4.2.3.</span> <span class="toc-text">任务容错</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#状态后端"><span class="toc-number">4.3.</span> <span class="toc-text">状态后端</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#任务提交与执行"><span class="toc-number">5.</span> <span class="toc-text">任务提交与执行</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#任务提交整体流程"><span class="toc-number">5.1.</span> <span class="toc-text">任务提交整体流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DAG转换"><span class="toc-number">5.2.</span> <span class="toc-text">DAG转换</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#DAG的4层转换"><span class="toc-number">5.2.1.</span> <span class="toc-text">DAG的4层转换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WordCount转换过程"><span class="toc-number">5.2.2.</span> <span class="toc-text">WordCount转换过程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#算子到StreamGraph的转换"><span class="toc-number">5.2.2.1.</span> <span class="toc-text">算子到StreamGraph的转换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#StreamGraph到JobGraph的转换"><span class="toc-number">5.2.2.2.</span> <span class="toc-text">StreamGraph到JobGraph的转换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#JobGraph到ExecutionGraph的转换"><span class="toc-number">5.2.2.3.</span> <span class="toc-text">JobGraph到ExecutionGraph的转换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ExecutionGraph到Task的转换"><span class="toc-number">5.2.2.4.</span> <span class="toc-text">ExecutionGraph到Task的转换</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Slot分配"><span class="toc-number">5.3.</span> <span class="toc-text">Slot分配</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#相关概念和实现类"><span class="toc-number">5.3.1.</span> <span class="toc-text">相关概念和实现类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#SlotManager和SlotPool"><span class="toc-number">5.3.1.1.</span> <span class="toc-text">SlotManager和SlotPool</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#PhysicalSlot、LogicalSlot、MultiTaskSlot、SingleTaskSlot"><span class="toc-number">5.3.1.2.</span> <span class="toc-text">PhysicalSlot、LogicalSlot、MultiTaskSlot、SingleTaskSlot</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Slot申请流程"><span class="toc-number">5.3.2.</span> <span class="toc-text">Slot申请流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#任务部署"><span class="toc-number">5.3.3.</span> <span class="toc-text">任务部署</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#任务执行机制"><span class="toc-number">5.4.</span> <span class="toc-text">任务执行机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#任务执行过程"><span class="toc-number">5.4.1.</span> <span class="toc-text">任务执行过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MailBox线程模型"><span class="toc-number">5.4.2.</span> <span class="toc-text">MailBox线程模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#改进理由"><span class="toc-number">5.4.2.1.</span> <span class="toc-text">改进理由</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MailBox模型"><span class="toc-number">5.4.2.2.</span> <span class="toc-text">MailBox模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#具体实现"><span class="toc-number">5.4.2.3.</span> <span class="toc-text">具体实现</span></a></li></ol></li></ol></li></ol></li></ol>
        
    </div>
</aside>

</header>

        <div id="content" class="content"><article class="article" itemscope="" itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
           Flink笔记
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="/2022/12/05/flink/">
    
    <i class="icon-calendar"></i>
    
    <time datetime="2022-12-05T02:56:49.000Z" itemprop="datePublished">2022-12-05</time>
</a>

            

        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <p>Flink相关笔记<br><a id="more"></a> </p>
<h1 id="Flink设计理念与基本架构"><a href="#Flink设计理念与基本架构" class="headerlink" title="Flink设计理念与基本架构"></a>Flink设计理念与基本架构</h1><h2 id="Flink与主流计算引擎对比"><a href="#Flink与主流计算引擎对比" class="headerlink" title="Flink与主流计算引擎对比"></a>Flink与主流计算引擎对比</h2><h3 id="Hadoop-MapReduce"><a href="#Hadoop-MapReduce" class="headerlink" title="Hadoop MapReduce"></a>Hadoop MapReduce</h3><p>MapReduce是由谷歌首次在论文“MapReduce: Simplified Data Processing on Large Clusters”（谷歌大数据三驾马车之一）中提出的，是一种处理和生成大数据的编程模型。<br>Hadoop MapReduce借鉴了谷歌这篇论文的思想，将大的任务分拆成较小的任务后进行处理，因此拥有更好的扩展性。</p>
<p><img src="/2022/12/05/flink/image-01.png" width="700px"></p>
<p>如图所示，Hadoop MapReduce包括两个阶段——Map和Reduce：Map阶段将数据映射为键值对（key/value），map函数在Hadoop中用Mapper类表示;<br>Reduce阶段使用shuffle后的键值对数据，并使用自身提供的算法对其进行处理，得到输出结果，reduce函数在Hadoop中用Reducer类表示。<br>其中shuffle阶段对MapReduce模式开发人员透明。</p>
<p><br></p>
<h3 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h3><p>Spark是由加州大学伯克利分校开源的类Hadoop MapReduce的大数据处理框架。与Hadoop MapReduce相比，它最大的不同是将计算中间的结果存储于内存中，而不需要存储到HDFS中。Spark的基本数据模型为RDD（Resilient Distributed Dataset，弹性分布式数据集）。</p>
<p>RDD是一个不可改变的分布式集合对象，由许多分区（partition）组成，每个分区包含RDD的一部分数据，且每个分区可以在不同的节点上存储和计算。</p>
<p>在Spark中，所有的计算都是通过RDD的创建和转换来完成的。<br>Spark Streaming是在Spark Core的基础上扩展而来的，用于支持实时流式数据的处理。</p>
<p><img src="/2022/12/05/flink/image-02.png" width="700px"></p>
<p>如图所示，Spark Streaming对流入的数据进行分批、转换和输出。微批处理无法满足低延迟的要求，只能算是近实时计算。</p>
<blockquote>
<p>Structured Streaming是基于Streaming SQL引擎的可扩展和容错的流式计算引擎。</p>
</blockquote>
<p><img src="/2022/12/05/flink/image-03.png" width="400px"></p>
<p>如图所示，Structured Streaming将流式的数据整体看成一张无界表，将每一条流入的数据看成无界的输入表，对输入进行处理会生成结果表。<br>生成结果表可以通过触发器来触发，目前支持的触发器都是定时触发的，整个处理类似Spark Streaming的微批处理；从Spark 2.3开始引入持续处理。<br>持续处理是一种新的、处于实验状态的流式处理模型，它在Structured Streaming的基础上支持持续触发来实现低延迟。</p>
<p><br></p>
<h3 id="Flink"><a href="#Flink" class="headerlink" title="Flink"></a>Flink</h3><p>Flink是对有界数据和无界数据进行有状态计算的分布式引擎，它是纯流式处理模式。<br>流入Flink的数据会经过预定的DAG（Directed Acyclic Graph，有向无环图）节点，Flink会对这些数据进行有状态计算，整个计算过程类似于管道。<br>每个计算节点会有本地存储，用来存储计算状态，而计算节点中的状态会在一定时间内持久化到分布式存储，来保证流的容错</p>
<p><img src="/2022/12/05/flink/image-04.png" width="800px"></p>
<p>如图所示。这种纯流式模式保证了Flink的低延迟，使其在诸多的实时计算引擎竞争中具有优势。</p>
<p><br><br><br></p>
<h2 id="Flink基本架构"><a href="#Flink基本架构" class="headerlink" title="Flink基本架构"></a>Flink基本架构</h2><h3 id="分层架构"><a href="#分层架构" class="headerlink" title="分层架构"></a>分层架构</h3><p>Flink是分层架构的分布式计算引擎，每层的实现依赖下层提供的服务，同时提供抽象的接口和服务供上层使用。</p>
<p><img src="/2022/12/05/flink/image-05.png" width="500px"></p>
<p>部署：Flink支持本地运行，支持Standalone集群以及YARN、Mesos、Kubernetes管理的集群，还支持在云上运行。（注：Flink部署模式会在第8章详细介绍。）<br>核心：Flink的运行时是整个引擎的核心，是分布式数据流的实现部分，实现了运行时组件之间的通信及组件的高可用等。<br>API：DataStream提供流式计算的API，DataSet提供批处理的API，Table和SQL API提供对Flink流式计算和批处理的SQL的支持。<br>Library：在Library层，Flink提供了复杂事件处理（CEP）、图计算（Gelly）及机器学习库。</p>
<h3 id="运行时架构"><a href="#运行时架构" class="headerlink" title="运行时架构"></a>运行时架构</h3><p>Flink运行时架构经历过一次不小的演变。在Flink 1.5版本之前，运行时架构如图所示</p>
<p><img src="/2022/12/05/flink/image-06.png" width="900px"></p>
<p>Client负责编译提交的作业，生成DAG，并向JobManager提交作业，往JobManager发送操作作业的命令。<br>JobManager作为Flink引擎的Master角色，主要有两个功能：作业调度和检查点协调。<br>TaskManager为Flink引擎的Worker角色，是作业实际执行的地方。TaskManager通过Slot对其资源进行逻辑分割，以确定TaskManager运行的任务数量。</p>
<blockquote>
<p>从Flink 1.5开始，Flink运行时有两种模式，分别是Session模式和Per-Job模式。</p>
</blockquote>
<ul>
<li>Session模式：在Flink 1.5之前都是Session模式，1.5及之后的版本与之前不同的是引入了Dispatcher。Dispatcher负责接收作业提交和持久化，生成多个JobManager和维护Session的一些状态，如图所示。</li>
</ul>
<p><img src="/2022/12/05/flink/image-07.png" width="900px"></p>
<ul>
<li>Per-Job模式：该模式启动后只会运行一个作业，且集群的生命周期与作业的生命周期息息相关，而Session模式可以有多个作业运行、多个作业共享TaskManager资源，如图所示</li>
</ul>
<p><img src="/2022/12/05/flink/image-08.png" width="900px"></p>
<p><br><br><br></p>
<h1 id="编程模型与API"><a href="#编程模型与API" class="headerlink" title="编程模型与API"></a>编程模型与API</h1><p>Flink中的主要概念和接口都是围绕DataStream展开</p>
<h2 id="DataStream"><a href="#DataStream" class="headerlink" title="DataStream"></a>DataStream</h2><p>在Flink中用DataSet和DataStream来表示数据集，DataSet表示有界的数据，DataStream表示无界的数据。<br>当然这只是概念层面的抽象，DataStream并没有真正的数据。DataStream通过初始化Source来构造，通过一系列的转换来表达计算过程，最后通过Sinker把结果输出到外部系统。<br>Flink内部集成了大量与外部系统交互的Source和Sink，这部分对应Flink中的Connectors模块；还有大量的Transformation，这部分对应Flink中的算子（Operator）。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.Time;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WindowWordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; dataStream = env</span><br><span class="line">                .socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line">                .flatMap(<span class="keyword">new</span> Splitter())</span><br><span class="line">                .keyBy(<span class="number">0</span>)</span><br><span class="line">                .timeWindow(Time.seconds(<span class="number">5</span>))</span><br><span class="line">                .sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        dataStream.print();</span><br><span class="line"></span><br><span class="line">        env.execute(<span class="string">"Window WordCount"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Splitter</span> <span class="keyword">implements</span> <span class="title">FlatMapFunction</span>&lt;<span class="title">String</span>, <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String sentence, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            <span class="keyword">for</span> (String word: sentence.split(<span class="string">" "</span>)) &#123;</span><br><span class="line">                out.collect(<span class="keyword">new</span> Tuple2&lt;String, Integer&gt;(word, <span class="number">1</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这个例子中，env.socketTextStream方法（从socket得到数据）得到DataStream，然后经过DataStream的各种转换，这里有flatMap、keyBy、window等转换，最后通过print把结果输出到标准输出。</p>
<p><img src="/2022/12/05/flink/image-09.png" width="500px"></p>
<p>上面的例子是通过socketTextStream从网络端口读取数据得到DataStream，还有一些其他方式<br>比如:通过读取文件，readFile (fileInputFormat, path)；通过读取集合数据集，fromCollection (Collection)。<br>当然也可以通过方法StreamExecutionEnvironment.addSource (sourceFunction)来定制数据的读取，用户需要实现SourceFunction接口。</p>
<p>我们来看下这个方法是怎么得到DataStream的，关键代码如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;OUT&gt; <span class="function">DataStreamSource&lt;OUT&gt; <span class="title">addSource</span><span class="params">(SourceFunction&lt;OUT&gt; function,</span></span></span><br><span class="line"><span class="function"><span class="params">        String sourceName, TypeInformation&lt;OUT&gt; typeInfo)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 此处省略不相关的代码</span></span><br><span class="line">    clean(function);</span><br><span class="line">    <span class="keyword">final</span> StreamSource&lt;OUT, ?&gt; sourceOperator = <span class="keyword">new</span> StreamSource&lt;&gt;(function);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> DataStreamSource&lt;&gt;(<span class="keyword">this</span>, typeInfo, sourceOperator, isParallel, sourceName);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可以看到该方法新建了一个DataStreamSource。</p>
<p>继续看DataStreamSource你会发现，它继承了SingleOutputStreamOperator（这个类从命名看不是很清楚，很容易让人把它误认为是个算子，但实际上它是个DataStream子类），这样我们就得到了一个DataStream。</p>
<blockquote>
<p>DataStream之间是怎么相互转换的呢？来看DataStream的flatMap方法</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;R&gt; <span class="function">SingleOutputStreamOperator&lt;R&gt; <span class="title">flatMap</span><span class="params">(FlatMapFunction&lt;T, R&gt; flatMapper)</span> </span>&#123;</span><br><span class="line">    TypeInformation&lt;R&gt; outType = TypeExtractor.getFlatMapReturnTypes(</span><br><span class="line">            clean(flatMapper), getType(), Utils.getCallLocationName(), <span class="keyword">true</span>);</span><br><span class="line">    <span class="comment">// 这里用FlatMapFunction构造了一个StreamOperator</span></span><br><span class="line">    <span class="keyword">return</span> transform(<span class="string">"Flat Map"</span>, outType, <span class="keyword">new</span> StreamFlatMap&lt;&gt;(clean(flatMapper)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里构造了一个StreamFlatMap类型的算子，然后继续调用transform方法。我们接着看transform方法：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;R&gt; <span class="function">SingleOutputStreamOperator&lt;R&gt; <span class="title">transform</span><span class="params">(String operatorName,</span></span></span><br><span class="line"><span class="function"><span class="params">        TypeInformation&lt;R&gt; outTypeInfo, OneInputStreamOperator&lt;T, R&gt; operator)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//构造Transformation</span></span><br><span class="line">    OneInputTransformation&lt;T, R&gt; resultTransform = <span class="keyword">new</span> OneInputTransformation&lt;&gt;(</span><br><span class="line">            <span class="keyword">this</span>.transformation,</span><br><span class="line">            operatorName,</span><br><span class="line">            operator,</span><br><span class="line">            outTypeInfo,</span><br><span class="line">            environment.getParallelism());</span><br><span class="line"></span><br><span class="line">    SingleOutputStreamOperator&lt;R&gt; returnStream = <span class="keyword">new</span> SingleOutputStreamOperator(</span><br><span class="line">            environment, resultTransform);</span><br><span class="line">    <span class="comment">// 把所有的Transformation都保存到StreamExecutionEnvironment中</span></span><br><span class="line">    getExecutionEnvironment().addOperator(resultTransform);</span><br><span class="line">    <span class="keyword">return</span> returnStream;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可以看到其中最主要的工作是基于刚才的算子新建了一个OneInputTransformation，然后把该Transformation保存下来。<br>那么StreamExecutionEnvironment中保存的Transformation用来做什么呢？实际上Flink根据这些Transformation生成整个运行的拓扑，整个生成过程大致如下：</p>
<ul>
<li>1）根据Transformation生成StreamGraph；</li>
<li>2）根据StreamGraph生成JobGraph；</li>
<li>3）根据JobGraph生成可以调度运行的ExecutionGraph。</li>
</ul>
<p>这里用户的执行代码FlatMapFunction实际上是通过先传递给算子，然后由算子来调用执行的。<br>最后本例通过dataStream.print()将结果输出。<br>同样Flink提供了很多API来把结果写到外部系统，</p>
<ul>
<li>writeAsText()：输出字符串到文件。</li>
<li>writeAsCsv()：输出CSV格式文本。</li>
<li>print()/printToErr()：标准输出/标准错误输出。</li>
<li>writeToSocket()：输出到socket。</li>
<li>addSink()：addSink与addSource一样，提供可以供用户扩展的输出方式，用户需要实现SinkFunction接口。</li>
</ul>
<p><br></p>
<h2 id="算子"><a href="#算子" class="headerlink" title="算子"></a>算子</h2><p>DataStream的相互转换会生成算子，Flink中DataStream的转换有哪些，会生成哪些算子。这只选择一些有代表性的转换进行解释说明。</p>
<h3 id="StreamFlatMap"><a href="#StreamFlatMap" class="headerlink" title="StreamFlatMap"></a>StreamFlatMap</h3><p>flatMap作用：循环遍历Map中的元素并用相应的函数进行处理。该方法会生成算子StreamFlatMap。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dataStream.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String value, Collector&lt;String&gt; out)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(String word: value.split(<span class="string">" "</span>))&#123;</span><br><span class="line">            out.collect(word);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h3 id="keyBy规则分区"><a href="#keyBy规则分区" class="headerlink" title="keyBy规则分区"></a>keyBy规则分区</h3><p>keyBy作用：按一定规则分区，比如常用的根据某个字段进行keyBy操作，Flink会根据该字段值的hashCode进行分区。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">computeOperatorIndexForKeyGroup</span><span class="params">(<span class="keyword">int</span> maxParallelism,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">int</span> parallelism, <span class="keyword">int</span> keyGroupId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> keyGroupId * parallelism / maxParallelism;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里的keyGroupId就是根据字段的hashCode和Flink的最大并行度计算出来的。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataStream.keyBy(<span class="string">"someKey"</span>)</span><br><span class="line">dataStream.keyBy(<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<p>该方法并不会生成一个算子，也就是说keyBy并没有生成运算拓扑的节点；<br>但是keyBy依然生成了Transformation，也就是说它规定了上下两个节点数据的分区方式。<br>Flink还有其他几种分区方式。</p>
<ul>
<li>rebalance：重新平衡分区，用于均衡数据，保证下游每个分区（在流系统中基本可以认为分区和并发是一个概念）的负载相同。</li>
<li>broadcast：广播分区，将输出的每条数据都发送到下游所有分区。</li>
<li>shuffle：随机分区，将输出的数据随机分发到下游分区。</li>
<li>forward：本地分区，将输出的数据分发到本地分区。</li>
<li>rescale：重新缩放分区，上下游根据分区数量分配对应的分配方式，然后循环发送。比如，如果上游分区为2，而下游分区为4，那么一个上游分区会把数据分发给两个下游分区，而另一个上游分区则把数据分发给其他两个下游分区，分区方式是循环分发。反之，如果下游操作的分区为2，而上游操作的分区为4，那么两个上游分区会把数据分发给一个下游分区，而另两个上游分区则把数据分发给另一个下游分区。</li>
<li>global：全局分区，所有数据进入下游第一个分区。</li>
</ul>
<p>在Flink实现中，StreamPartitioner是分区接口类，每种分区对应一个StreamPartitioner的实现类。<br>我们来看下rebalance对应的RebalancePartitioner。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> DataStream&lt;T&gt; <span class="title">rebalance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> setConnectionType(<span class="keyword">new</span> RebalancePartitioner&lt;T&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到设置了分区方式，分区方式（要注意的是StreamPartitioner并不是算子）就是RebalancePartitioner。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RebalancePartitioner</span>&lt;<span class="title">T</span>&gt; <span class="keyword">extends</span> <span class="title">StreamPartitioner</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> nextChannelToSendTo;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(<span class="keyword">int</span> numberOfChannels)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.setup(numberOfChannels);</span><br><span class="line"></span><br><span class="line">        nextChannelToSendTo = ThreadLocalRandom.current().nextInt(numberOfChannels);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">selectChannel</span><span class="params">(SerializationDelegate&lt;StreamRecord&lt;T&gt;&gt; record)</span> </span>&#123;</span><br><span class="line">        nextChannelToSendTo = (nextChannelToSendTo + <span class="number">1</span>) % numberOfChannels;</span><br><span class="line">        <span class="keyword">return</span> nextChannelToSendTo;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>主要方法selectChannel的源代码实现比较简单，就是随机选择下发的分区。</p>
<h3 id="aggregation聚合计算"><a href="#aggregation聚合计算" class="headerlink" title="aggregation聚合计算"></a>aggregation聚合计算</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">keyedStream.sum(<span class="number">0</span>);</span><br><span class="line">keyedStream.sum(<span class="string">"key"</span>);</span><br><span class="line">keyedStream.min(<span class="number">0</span>);</span><br><span class="line">keyedStream.min(<span class="string">"key"</span>);</span><br><span class="line">keyedStream.max(<span class="number">0</span>);</span><br><span class="line">keyedStream.max(<span class="string">"key"</span>);</span><br><span class="line">keyedStream.minBy(<span class="number">0</span>);</span><br><span class="line">keyedStream.minBy(<span class="string">"key"</span>);</span><br><span class="line">keyedStream.maxBy(<span class="number">0</span>);</span><br><span class="line">keyedStream.maxBy(<span class="string">"key"</span>);</span><br></pre></td></tr></table></figure>
<p>该方法会生成算子StreamGroupedReduce，包括fold、reduce及aggregation，只能作用于KeyedStream。<br>需要注意的一点是，这些聚合计算都是针对某个键（Key）的，如果要求全局的最大值、最小值，该方法是无法做到的。</p>
<h3 id="window及window-apply"><a href="#window及window-apply" class="headerlink" title="window及window apply"></a>window及window apply</h3><p>根据窗口聚合计算数据</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">dataStream.keyBy(<span class="number">0</span>).window(TumblingEventTimeWindows.of(Time.seconds(<span class="number">5</span>)));</span><br><span class="line">windowedStream.apply (<span class="keyword">new</span> WindowFunction&lt;Tuple2&lt;String,Integer&gt;, Integer, Tuple, Window&gt;() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">apply</span> <span class="params">(Tuple tuple,</span></span></span><br><span class="line"><span class="function"><span class="params">            Window window,</span></span></span><br><span class="line"><span class="function"><span class="params">            Iterable&lt;Tuple2&lt;String, Integer&gt;&gt; values,</span></span></span><br><span class="line"><span class="function"><span class="params">            Collector&lt;Integer&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (value t: values) &#123;</span><br><span class="line">            sum += t.f1;</span><br><span class="line">        &#125;</span><br><span class="line">        out.collect (<span class="keyword">new</span> Integer(sum));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>该方法会生成窗口。<br>窗口分为Keyed Window和Non-Keyed Window（用WindowAll转换得到），二者的区别在于使用window转换之前是否进行keyBy操作。<br>窗口将会在后面详细介绍。</p>
<h3 id="union"><a href="#union" class="headerlink" title="union"></a>union</h3><p>合并多个DataStream。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataStream.union(otherStream1, otherStream2, ...);</span><br></pre></td></tr></table></figure></p>
<p>该方法有个有意思的使用方式是可以合并数据本身，这样就可以得到一个两倍数据的流。该方法同样不会产生算子。</p>
<h3 id="window-join"><a href="#window-join" class="headerlink" title="window join"></a>window join</h3><p>通过给定的键和窗口关联两个DataStream。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dataStream.join(otherStream)</span><br><span class="line">    .where(&lt;key selector&gt;).equalTo(&lt;key selector&gt;)</span><br><span class="line">    .window(TumblingEventTimeWindows.of(Time.seconds(<span class="number">3</span>)))</span><br><span class="line">    .apply (<span class="keyword">new</span> JoinFunction () &#123;...&#125;);</span><br></pre></td></tr></table></figure>
<p>这里我们通过一个例子来看下Flink中window join是怎么实现的。<br>假如我们有streamA（图中用深灰色元素表示）和streamB（图中用浅灰色元素表示）经过window join处理，伪代码如下（这段代码的主要内容就是两个流进行window join处理的用法示例）：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Integer&gt; streamA = ...</span><br><span class="line">DataStream&lt;Integer&gt; streamB = ...</span><br><span class="line"></span><br><span class="line">streamA.join(streamB)</span><br><span class="line">        .where(&lt;KeySelector&gt;)</span><br><span class="line">        .equalTo(&lt;KeySelector&gt;)</span><br><span class="line">        .window(TumblingEventTimeWindows.of(Time.milliseconds(<span class="number">2</span>)))</span><br><span class="line">        .apply(<span class="keyword">new</span> JoinFunction&lt;Integer, Integer, String&gt; ()&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">join</span><span class="params">(Integer first, Integer second)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> first + <span class="string">","</span> + second;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p><img src="/2022/12/05/flink/image-10.png" width="700px"></p>
<p>圆圈内的数字表示数据元素本身及事件时间，经过处理之后得到图下方给出的数字组合（这里假设图中给定的同一个窗口内数据的键是一样的，即每个窗口内的数据都满足join条件）。<br>可以看出这里join的行为和普通的inner join非常类似。<br>为了更好地理解join的结果，我们来看下其源代码实现。window join实现可以从JoinedStreams的apply方法着手。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T&gt; <span class="function">DataStream&lt;T&gt; <span class="title">apply</span><span class="params">(JoinFunction&lt;T1, T2, T&gt; function,</span></span></span><br><span class="line"><span class="function"><span class="params">        TypeInformation&lt;T&gt; resultType)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 清除闭包</span></span><br><span class="line">    function = input1.getExecutionEnvironment().clean(function);</span><br><span class="line"></span><br><span class="line">    coGroupedWindowedStream = input1.coGroup(input2)</span><br><span class="line">            .where(keySelector1)</span><br><span class="line">            .equalTo(keySelector2)</span><br><span class="line">            .window(windowAssigner)</span><br><span class="line">            .trigger(trigger)</span><br><span class="line">            .evictor(evictor)</span><br><span class="line">            .allowedLateness(allowedLateness);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> coGroupedWindowedStream.apply(</span><br><span class="line">        <span class="keyword">new</span> JoinCoGroupFunction&lt;&gt;(function), resultType);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里可以看到window join是通过coGroup来实现的，生成一个CoGroupedStreams，然后应用JoinCoGroupFunction。</p>
<blockquote>
<p>那么coGroup又是怎么实现window join的呢？</p>
</blockquote>
<p>我们继续来看CoGroupedStreams的apply方法（略去了无关代码）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">public &lt;T&gt; DataStream&lt;T&gt; apply(CoGroupFunction&lt;T1, T2, T&gt; function,</span><br><span class="line">        TypeInformation&lt;T&gt; resultType) &#123;</span><br><span class="line"></span><br><span class="line">    DataStream&lt;TaggedUnion&lt;T1, T2&gt;&gt; taggedInput1 = input1</span><br><span class="line">            .map(new Input1Tagger&lt;T1, T2&gt;())</span><br><span class="line">            .setParallelism(input1.getParallelism())</span><br><span class="line">            .returns(unionType);</span><br><span class="line">    DataStream&lt;TaggedUnion&lt;T1, T2&gt;&gt; taggedInput2 = input2</span><br><span class="line">            .map(new Input2Tagger&lt;T1, T2&gt;())</span><br><span class="line">            .setParallelism(input2.getParallelism())</span><br><span class="line">            .returns(unionType);</span><br><span class="line">    // 1</span><br><span class="line">    DataStream&lt;TaggedUnion&lt;T1, T2&gt;&gt; unionStream = taggedInput1.union(taggedInput2);</span><br><span class="line">    // 2</span><br><span class="line">    windowedStream = new KeyedStream&lt;TaggedUnion&lt;T1, T2&gt;, KEY&gt;(</span><br><span class="line">            unionStream, unionKeySelector, keyType).window(windowAssigner);</span><br><span class="line">    // 3</span><br><span class="line">    return windowedStream.apply(</span><br><span class="line">            new CoGroupWindowFunction&lt;T1, T2, T, KEY, W&gt;(function), resultType);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这部分代码非常清楚地展示了其实现过程：代码1调用union把两个DataStream联合在一起，代码2生成一个WindowedStream，代码3对WindowedStream执行窗口函数。<br>window join本质上还是通过union和window等更基础的算子实现的。<br>我们再来看一下这个过程中传入的JoinCoGroupFunction：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">JoinCoGroupFunction</span>&lt;<span class="title">T1</span>, <span class="title">T2</span>, <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="class">        <span class="keyword">extends</span> <span class="title">WrappingFunction</span>&lt;<span class="title">JoinFunction</span>&lt;<span class="title">T1</span>, <span class="title">T2</span>, <span class="title">T</span>&gt;&gt;</span></span><br><span class="line"><span class="class">        <span class="keyword">implements</span> <span class="title">CoGroupFunction</span>&lt;<span class="title">T1</span>, <span class="title">T2</span>, <span class="title">T</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">coGroup</span><span class="params">(Iterable&lt;T1&gt; first, Iterable&lt;T2&gt; second,</span></span></span><br><span class="line"><span class="function"><span class="params">            Collector&lt;T&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (T1 val1: first) &#123;</span><br><span class="line">            <span class="keyword">for</span> (T2 val2: second) &#123;</span><br><span class="line">                out.collect(wrappedFunction.join(val1, val2));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这个函数就是图描述的不同数据相互连接配对的实现逻辑。<br>window join的窗口还可以是滑动窗口、会话窗口，这里不再详细讲解，实现原理基本一样。</p>
<h3 id="interval-join"><a href="#interval-join" class="headerlink" title="interval join"></a>interval join</h3><p>通过给定的键和时间范围连接两个DataStream。假如有数据e1和e2分别来自两个DataStream，那么要让两个数据可以连接输出，需要</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">e1.timestamp + lowerBound &lt;= e2.timestamp &lt;= e1.timestamp + upperBound</span><br></pre></td></tr></table></figure>
<p>interval join只支持基于事件时间的范围。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">keyedStream.intervalJoin(otherKeyedStream)</span><br><span class="line">        .between(Time.milliseconds(-2), Time.milliseconds(2)) // 下界和上界</span><br><span class="line">        .upperBoundExclusive(true) // 可选</span><br><span class="line">        .lowerBoundExclusive(true) // 可选</span><br><span class="line">        .process(new IntervalJoinFunction() &#123;...&#125;);</span><br></pre></td></tr></table></figure></p>
<p>Flink API中实现了两种join：一种是window join，另一种就是interval join。<br>两种join最大的不同在于join的数据分组不一样：window join是在同一个时间窗口内连接；interval join是每个数据元素根据自己的时间都有一个join取值范围，这个范围是由lowerBound和upperBound决定的。<br>我们通过一个例子来直观地看下interval join的过程，然后分析其实现。</p>
<p>如图所示，我们有两个流streamA和streamB，其数据分别用深灰色和浅灰色的圆圈表示，圆圈中的数字代表数据元素本身及事件时间。<br>interval join的伪代码如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Integer&gt; streamA = ...</span><br><span class="line">DataStream&lt;Integer&gt; streamB = ...</span><br><span class="line"></span><br><span class="line">streamA.keyBy(&lt;KeySelector&gt;)</span><br><span class="line">        .intervalJoin(streamB.keyBy(&lt;KeySelector&gt;))</span><br><span class="line">        .between(Time.milliseconds(-2), Time.milliseconds(1))</span><br><span class="line">        .process (new ProcessJoinFunction&lt;Integer, Integer, String()&#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void processElement(Integer left, Integer right, Context ctx,</span><br><span class="line">            Collector&lt;String&gt; out) &#123;</span><br><span class="line">        out.collect(first + &quot;,&quot; + second);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<p><img src="/2022/12/05/flink/image-11.png" width="700px"></p>
<p>可以看到判断两个流的数据可以连接的依据是两个流的数据符合lowerBound和upperBound界定的范围，即<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">streamA.data.ts + lowerBound &lt;= streamB.data.ts.ts &lt;= streamA.data.ts + upperBound</span><br></pre></td></tr></table></figure></p>
<p>streamA的每个数据元素都可以根据lowerBound和upperBound在streamB上界定一个可以连接的范围，比如：当图中streamA的数据元素2被处理的时候，发现streamB的数据元素0和1满足界定范围，这时输出2，0和2，1<br>在图中streamB的数据元素1进入算子之后，也会根据范围界限找到符合范围条件的streamA的0数据元素，然后输出0，1。</p>
<p>我们接下来看下Flink中interval join是怎么实现的。<br>关键代码是IntervalJoinOperator中的processElement方法，实现过程与图给出的逻辑一致。<br>首先需要两个状态保存两个流的数据，这里用的是MapState；然后处理数据元素，遍历另一个流的数据，查询是否有满足界定范围的数据，如果有的话就将其发送出去；最后注册一个状态清理函数，用来清理掉永远无法连接上的过期数据。</p>
<p>这里只介绍了几个常用的Transformation和算子，像Connect、CoMap、Split、Select之类的操作和转换就不一一介绍了，有兴趣的可以通过官网和源代码学习了解。</p>
<p><br><br><br></p>
<h2 id="窗口"><a href="#窗口" class="headerlink" title="窗口"></a>窗口</h2><h3 id="窗口的基本概念"><a href="#窗口的基本概念" class="headerlink" title="窗口的基本概念"></a>窗口的基本概念</h3><p>窗口是无边界流式系统中非常重要的概念，窗口把数据切分成一段段有限的数据集，然后进行计算。Flink中窗口按照是否并发执行，分为Keyed Window和Non-Keyed Window，它们的主要区别是有无keyBy动作。<br>Keyed Window可以按照指定的分区方式并发执行，所有相同的键会被分配到相同的任务上执行。<br>Non-Keyed Window会把所有数据放到一个任务上执行，并发度为1。</p>
<h4 id="Keyed-Window"><a href="#Keyed-Window" class="headerlink" title="Keyed Window"></a>Keyed Window</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">stream.keyBy(...)</span><br><span class="line">    .window(...)          // 接受WindowAssigner参数，用来分配窗口</span><br><span class="line">    [.trigger(...)]       // 可选的，接受Trigger类型参数，用来触发窗口</span><br><span class="line">    [.evictor(...)]       // 可选的，接受Evictor类型参数，用来驱逐窗口中的数据</span><br><span class="line">    [.allowedLateness(...)]</span><br><span class="line">    // 可选的，接受Time类型参数，表示窗口允许的最大延迟，超过该延迟，数据会被丢弃</span><br><span class="line">    [.sideOutputLateData(...)]</span><br><span class="line"></span><br><span class="line">    // 可选的，接受OutputTag类型参数，用来定义抛弃数据的输出</span><br><span class="line">    .reduce/aggregate/fold/apply()      // 窗口函数</span><br><span class="line">    [.getSideOutput(...)]               // 可选的，获取指定的DataStream</span><br></pre></td></tr></table></figure>
<h4 id="Non-Keyed-Window"><a href="#Non-Keyed-Window" class="headerlink" title="Non-Keyed Window"></a>Non-Keyed Window</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">stream.windowAll(...)           // 接受WindowAssigner参数，用来分配窗口</span><br><span class="line">    [.trigger(...)]             // 可选的，接受Trigger类型参数，用来触发窗口</span><br><span class="line">    [.evictor(...)]             // 可选的，接受Evictor类型参数，用来驱逐窗口中的数据</span><br><span class="line">    [.allowedLateness(...)]</span><br><span class="line"></span><br><span class="line">    // 可选的，接受Time类型参数，表示窗口允许的最大延迟，超过该延迟，数据会被丢弃</span><br><span class="line">    [.sideOutputLateData(...)]</span><br><span class="line"></span><br><span class="line">    // 可选的，接受OutputTag类型参数，用来定义抛弃数据的输出</span><br><span class="line">    .reduce/aggregate/fold/apply()      // 窗口函数</span><br><span class="line">    [.getSideOutput(...)]               // 可选的，获取指定的DataStream</span><br></pre></td></tr></table></figure>
<p>因为实际生产中我们大多会使用Keyed Window，所以后续的解读都是针对Keyed Window展开的。<br>我们来看下上面提到的几个主要概念。</p>
<ul>
<li>WindowAssigner：窗口分配器。我们常说的滚动窗口、滑动窗口、会话窗口等就是由WindowAssigner决定的，比如TumblingEventTimeWindows可以产生基于事件时间的滚动窗口。</li>
<li>Trigger：触发器。Flink根据WindowAssigner把数据分配到不同的窗口，还需要一个执行时机，Trigger就是用来判断执行时机的。Trigger类中定义了一些返回值类型，根据返回值类型来决定是否触发及触发什么动作。</li>
<li>Evictor：驱逐器。在窗口触发之后，在调用窗口函数之前或者之后，Flink允许我们定制要处理的数据集合，Evictor就是用来驱逐或者过滤不需要的数据集的。</li>
<li>Allowed Lateness：最大允许延迟。主要用在基于事件时间的窗口，表示在水位线到达之后的最长允许数据延迟时间。在最长允许延迟时间内，窗口都不会销毁。</li>
<li>Window Function：窗口函数。用户代码执行函数，用来做真正的业务计算。</li>
<li>Side Output：丢弃数据的集合。通过getSideOutput方法可以获取丢弃数据的DataStream，方便用户进行扩展。</li>
</ul>
<p><br></p>
<h3 id="窗口的执行流程"><a href="#窗口的执行流程" class="headerlink" title="窗口的执行流程"></a>窗口的执行流程</h3><p>在深入介绍窗口之前，我们先从整体上看下窗口的执行过程，以便有个全局的概念。</p>
<p>从整体上介绍窗口的执行流程，如果其中有细节不清楚的地方，直接看后面几节，再回过头来看本节内容。<br>窗口本质上也是一个算子所以我们直接来看其实现类：EvictingWindowOperator和WindowOperator。<br>这两个类的区别是前者带驱逐器，后者不带。<br>为了覆盖更多的场景，我们用EvictingWindowOperator来分析。 我们直接从算子最重要的方法processElement开始。</p>
<ul>
<li>整个过程从分配窗口（WindowAssigner的主要作用）开始分配好窗口后，用当前窗口来设置窗口状态的命名空间;</li>
<li>之后把当前数据加入状态中（如果是聚合函数的话，还会有计算过程），并用当前数据去判断触发器是否触发，如果触发那就调用emitWindowContents方法处理数据，该方法的主要过程是调用驱逐器清除数据;</li>
<li>然后调用窗口函数计算结果；最后注册一个窗口本身的清除定时器。</li>
</ul>
<p><img src="/2022/12/05/flink/image-12.png" width="900px"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(StreamRecord&lt;IN&gt; element)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> Collection&lt;W&gt; elementWindows = windowAssigner.assignWindows(</span><br><span class="line">            element.getValue(), element.getTimestamp(), windowAssignerContext);</span><br><span class="line">    <span class="keyword">if</span> (windowAssigner <span class="keyword">instanceof</span> MergingWindowAssigner) &#123;</span><br><span class="line">        MergingWindowSet&lt;W&gt; mergingWindows = getMergingWindowSet();</span><br><span class="line">        W actualWindow = mergingWindows.addWindow(...)</span><br><span class="line">    &#125;</span><br><span class="line">    evictingWindowState.setCurrentNamespace(stateWindow);</span><br><span class="line">    evictingWindowState.add(element);</span><br><span class="line"></span><br><span class="line">    TriggerResult triggerResult = triggerContext.onElement(element);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (triggerResult.isFire()) &#123;</span><br><span class="line">        Iterable&lt;StreamRecord&lt;IN&gt;&gt; contents = evictingWindowState.get();</span><br><span class="line">        <span class="keyword">if</span> (contents == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        emitWindowContents(actualWindow, contents, evictingWindowState);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    registerCleanupTimer(window);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="窗口分配器"><a href="#窗口分配器" class="headerlink" title="窗口分配器"></a>窗口分配器</h3><p>主要介绍Flink中窗口分配器的作用及几种典型实现，这几种典型的实现实际上对应着几种典型的窗口。<br>熟悉流计算的读者可能知道，窗口（时间窗口）大致可以分为滑动窗口和滚动窗口。</p>
<blockquote>
<p>那么这个分类是由什么决定的呢？</p>
</blockquote>
<p>显然它是由数据分配到不同窗口的方式决定的。<br>在Flink中这个分配的动作就是由窗口分配器完成的。不同的窗口分配器实现类对应不同的窗口。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">WindowAssigner</span>&lt;<span class="title">T</span>, <span class="title">W</span> <span class="keyword">extends</span> <span class="title">Window</span>&gt; <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> Collection&lt;W&gt; <span class="title">assignWindows</span><span class="params">(T element,</span></span></span><br><span class="line"><span class="function"><span class="params">            <span class="keyword">long</span> timestamp, WindowAssignerContext context)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> Trigger&lt;T, W&gt; <span class="title">getDefaultTrigger</span><span class="params">(StreamExecutionEnvironment env)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> TypeSerializer&lt;W&gt; <span class="title">getWindowSerializer</span><span class="params">(ExecutionConfig executionConfig)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">boolean</span> <span class="title">isEventTime</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WindowAssignerContext</span> </span>&#123;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 返回当前的处理时间</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">long</span> <span class="title">getCurrentProcessingTime</span><span class="params">()</span></span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中最关键的是assignWindows方法，它用来分配窗口。我们来看几种常用的实现。</p>
<h4 id="滚动窗口"><a href="#滚动窗口" class="headerlink" title="滚动窗口"></a>滚动窗口</h4><p>Flink中有TumblingEventTimeWindows和TumblingProcessingTimeWindows两种滚动窗口（Tumbling Window），分别对应基于事件时间的滚动窗口和基于系统时间的滚动窗口。<br>这两种实现分配数据的策略实际上是一样的，只是基于的时间不同。<br>我们来看下TumblingEventTimeWindows的assignWindows方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Collection&lt;TimeWindow&gt; <span class="title">assignWindows</span><span class="params">(Object element,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">long</span> timestamp, WindowAssignerContext context)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (timestamp &gt; Long.MIN_VALUE) &#123;</span><br><span class="line">        <span class="comment">// 计算窗口开始的时间</span></span><br><span class="line">        <span class="keyword">long</span> start = TimeWindow.getWindowStartWithOffset(timestamp, offset, size);</span><br><span class="line">        <span class="keyword">return</span> Collections.singletonList(<span class="keyword">new</span> TimeWindow(start, start + size));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(</span><br><span class="line">            <span class="string">"Record has Long.MIN_VALUE timestamp (= no timestamp marker). "</span></span><br><span class="line">            + <span class="string">"Is the time characteristic set to 'ProcessingTime', "</span> + <span class="string">"or did you forget to call "</span></span><br><span class="line">            + <span class="string">"'DataStream.assignTimestampsAndWatermarks(...)'?"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，其实现还是比较清楚的，根据窗口的大小（size）、偏移量（offset）、数据时间计算窗口的开始时间。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">getWindowStartWithOffset</span><span class="params">(<span class="keyword">long</span> timestamp, <span class="keyword">long</span> offset, <span class="keyword">long</span> windowSize)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> timestamp - (timestamp - offset + windowSize) % windowSize;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>返回一个TimeWindow。</p>
<h4 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h4><p>和滚动窗口一样，滑动窗口（Sliding Window）也有SlidingEventTimeWindows和Sliding-ProcessingTimeWindows两种实现，两种实现也基本是一样的。<br>我们来看SlidingProcessing-TimeWindows的assignWindows方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Collection&lt;TimeWindow&gt; <span class="title">assignWindows</span><span class="params">(Object element, <span class="keyword">long</span> timestamp,</span></span></span><br><span class="line"><span class="function"><span class="params">        WindowAssignerContext context)</span> </span>&#123;</span><br><span class="line">    timestamp = context.getCurrentProcessingTime();</span><br><span class="line">    List&lt;TimeWindow&gt; windows = <span class="keyword">new</span> ArrayList&lt;&gt;((<span class="keyword">int</span>) (size / slide));</span><br><span class="line">    <span class="keyword">long</span> lastStart = TimeWindow.getWindowStartWithOffset(timestamp, offset, slide);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">long</span> start = lastStart;</span><br><span class="line">        start &gt; timestamp - size;</span><br><span class="line">        start -= slide) &#123;</span><br><span class="line">            windows.add(<span class="keyword">new</span> TimeWindow(start, start + size));</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">return</span> windows;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先我们看到一个最明显的区别是返回的TimeWindow个数不同，滚动窗口只返回一个，而滑动窗口返回多个，这也符合我们对滑动窗口的理解：滑动窗口是可以重叠的，一个数据可以落入多个窗口内（可以思考一下一个数据最多可以落入几个窗口内）。<br>与滚动窗口一样，计算最后一个窗口的开始时间，然后不断回溯（前一个窗口的开始时间减去滑动时间）寻找位于时间范围内的窗口，直到窗口的结束时间早于系统时间（或者事件时间）。</p>
<h4 id="会话窗口"><a href="#会话窗口" class="headerlink" title="会话窗口"></a>会话窗口</h4><p>会话窗口（Session Window）是Flink中比较独特的窗口类型，其他流式系统不支持它，或支持得不够好。<br>会话窗口可以按照一个会话来分配数据，而会话的长度可以是固定的（EventTimeSessionWindows、ProcessingTimeSessionWindows），也可以是不断变化的（DynamicProcessingTimeSessionWindows、DynamicEventTimeSessionWindows）。<br>使用过会话的读者可能知道，只要不过期会话就可以一直存在，新的数据必然会加入某个会话，同时会导致会话的超时时间发生改变。<br>在Flink中，会话的不断变化就对应着会话窗口的不断合并。我们以EventTimeSessionWindows为例来看下会话窗口的实现，其中比较复杂的是窗口的合并。</p>
<p>会话窗口中数据的分配和滚动窗口很像，即返回一个计算好的窗口（TimeWindow）。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Collection&lt;TimeWindow&gt; <span class="title">assignWindows</span><span class="params">(Object element, <span class="keyword">long</span> timestamp,</span></span></span><br><span class="line"><span class="function"><span class="params">        WindowAssignerContext context)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> Collections.singletonList(<span class="keyword">new</span> TimeWindow(timestamp, timestamp + sessionTimeout));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>窗口的分配过程结束后，会得到一个窗口。这个新分配的窗口属于哪个会话（真正的窗口）呢？<br>我们来看图中的例子（例子中sessionTimeout=3）。</p>
<p><img src="/2022/12/05/flink/image-13.png" width="400px"></p>
<p>假如Flink接收到数据时间为1的数据（上图中的步骤1）（这里我们假设键相同或者是Non-Keyed Window），那么这个时候会生成TimeWindow(1,4)，并处理数据时间为5的数据，生成TimeWindow(5,8)；<br>然后继续处理时间为3的数据，这个时候应该生成TimeWindow(3,6)的窗口，但是由于TimeWindow(1,4)对应的会话还没有过期，应该把时间为3的数据归到这个会话中，所以Flink中进行TimeWindow的合并。<br>同理当TimeWindow(1,4)和TimeWindow(3,6)合并为TimeWindow(1,6)的时候，也应该将TimeWindow(5,8)同自己合并，这样最后合并为TimeWindow(1,8)。<br>当然不只是将TimeWindow合并，还需要将窗口对应的触发器、数据合并。</p>
<p>我们来看合并的关键代码，合并发生在数据被WindowOperator处理的过程中：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">W actualWindow = mergingWindows.addWindow(window, <span class="keyword">new</span> MergingWindowSet.MergeFunction&lt;W&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(W mergeResult,</span></span></span><br><span class="line"><span class="function"><span class="params">            Collection&lt;W&gt; mergedWindows, W stateWindowResult,</span></span></span><br><span class="line"><span class="function"><span class="params">            Collection&lt;W&gt; mergedStateWindows)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ((windowAssigner.isEventTime() &lt;&lt; mergeResult.maxTimestamp() +</span><br><span class="line">                allowedLateness &lt;= internalTimerService.currentWatermark())) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(<span class="string">"The end timestamp of an "</span></span><br><span class="line">                + <span class="string">"event-time window cannot become earlier than the current watermark "</span></span><br><span class="line">                + <span class="string">"by merging. Current watermark: "</span></span><br><span class="line">                + internalTimerService.currentWatermark()</span><br><span class="line">                + <span class="string">" window: "</span> + mergeResult);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!windowAssigner.isEventTime()) &#123;</span><br><span class="line">            <span class="keyword">long</span> currentProcessingTime = internalTimerService.currentProcessingTime();</span><br><span class="line">            <span class="keyword">if</span> (mergeResult.maxTimestamp() &lt;= currentProcessingTime) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(<span class="string">"The end timestamp of a "</span></span><br><span class="line">                + <span class="string">"processing-time window cannot become earlier than "</span></span><br><span class="line">                + <span class="string">"the current processing time "</span></span><br><span class="line">                + <span class="string">"by merging. Current processing time: "</span> + currentProcessingTime</span><br><span class="line">                + <span class="string">" window: "</span> + mergeResult);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        triggerContext.key = key;</span><br><span class="line">        triggerContext.window = mergeResult;</span><br><span class="line"></span><br><span class="line">        triggerContext.onMerge(mergedWindows);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (W m: mergedWindows) &#123;</span><br><span class="line">            triggerContext.window = m;</span><br><span class="line">            triggerContext.clear();</span><br><span class="line">            deleteCleanupTimer(m);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 合并状态</span></span><br><span class="line">        windowMergingState.mergeNamespaces(stateWindowResult, mergedStateWindows);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>其中关键的方法是MergingWindowSet的addWindow方法，其中TimeWindow合并的细节在其mergeWindows方法中，合并的规则就是我们上面介绍的。</p>
<blockquote>
<p>合并的主要过程如下</p>
</blockquote>
<ul>
<li>找出合并之前的窗口集合和合并之后的窗口;</li>
<li>找出合并之后的窗口对应的状态窗口（方式是从合并窗口集合中挑选第一个窗口的状态窗口）;</li>
<li>执行merge方法（合并窗口需要做的工作，也就是执行MergingWindowSet的addWindow方法）。</li>
</ul>
<blockquote>
<p>这里不好理解的是合并结果的窗口和结果对应的状态窗口（用来获取合并之后的数据），我们来看图</p>
</blockquote>
<p><img src="/2022/12/05/flink/image-14.png" width="400px"></p>
<p>MergingWindowSet（窗口合并的工具类）中有个map，用来保存窗口和状态窗口的对应关系</p>
<blockquote>
<p>那么怎么理解这个状态窗口呢？</p>
</blockquote>
<p>如果我们在得到TimeWindow(1,4)时基于TimeWindow(1,4)在状态中保存了数据（数据A），也就是说状态的命名空间是TimeWindow(1,4)，在得到TimeWindow(5,8)时基于TimeWindow(5,8)在状态中保存了数据（数据B），当第三个数据（数据C）来的时候，又经过合并窗口得到了TimeWindow(1,8)</p>
<blockquote>
<p>那么怎么获取合并窗口的数据集AB呢？</p>
</blockquote>
<p>显然我们还需要原来的TimeWindow(1,4)或者TimeWindow(5,8)，原来的TimeWindow(1,4)在这里就是状态窗口。</p>
<p>这里窗口合并的同时会把窗口对应的状态所保存的数据合并到结果窗口对应的状态窗口对应的状态中。<br>这里有点绕，还是看图，最终合并窗口的结果窗口是TimeWindow(1,8)。</p>
<blockquote>
<p>我们怎么获取TimeWindow(1,8)对应的数据集ABC呢？</p>
</blockquote>
<p>这个时候可以通过MergingWindowSet中保存的TimeWindow(1,8)对应的状态窗口TimeWindow(1,4)来获取合并后的状态，即数据集ABC。<br>会话窗口的其他过程与滑动窗口及滚动窗口没有什么区别。</p>
<h4 id="全局窗口"><a href="#全局窗口" class="headerlink" title="全局窗口"></a>全局窗口</h4><p>全局窗口（Global Window），顾名思义就是所有的元素都分配到同一个窗口中，我们常用的Count Window就是一种全局窗口。<br>其实现GlobalWindow的主要方法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Collection&lt;GlobalWindow&gt; <span class="title">assignWindows</span><span class="params">(Object element, <span class="keyword">long</span> timestamp,</span></span></span><br><span class="line"><span class="function"><span class="params">        WindowAssignerContext context)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> Collections.singletonList(GlobalWindow.get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里需要说明的是全局窗口和Non-Keyed Window是完全不同的概念:</p>
<ul>
<li>Non-Keyed Window是指并发为1的窗口，可以是滚动窗口或者滑动窗口;</li>
<li>而全局窗口既可以是Non-Keyed Window，也可以是Keyed Window。</li>
</ul>
<p><br></p>
<h3 id="触发器"><a href="#触发器" class="headerlink" title="触发器"></a>触发器</h3><p>触发器决定窗口函数什么时候执行以及执行的状态。<br>触发器通过返回值来决定什么时候执行，其返回值有如下几种类型。</p>
<ul>
<li>CONTINUE：什么也不做。</li>
<li>FIRE：触发窗口的计算。</li>
<li>PURGE：清除窗口中的数据。</li>
<li>FIRE_AND_PURGE：触发计算并清除数据。</li>
</ul>
<p>其接口定义如下（列出主要方法）：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Trigger</span>&lt;<span class="title">T</span>, <span class="title">W</span> <span class="keyword">extends</span> <span class="title">Window</span>&gt; <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="comment">//每个增加到窗口中的数据都需要调用该方法，根据返回结果判定窗口是否触发</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> TriggerResult <span class="title">onElement</span><span class="params">(T element, <span class="keyword">long</span> timestamp,</span></span></span><br><span class="line"><span class="function"><span class="params">            W window, TriggerContext ctx)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">    <span class="comment">//当注册的系统时间定时器到期后调用，其调用是通过WindowOperator中的triggerContext进行的</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> TriggerResult <span class="title">onProcessingTime</span><span class="params">(<span class="keyword">long</span> time, W window,</span></span></span><br><span class="line"><span class="function"><span class="params">            TriggerContext ctx)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">    <span class="comment">//当注册的事件时间定时器到期后调用，其调用是通过WindowOperator中的triggerContext进行的</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> TriggerResult <span class="title">onEventTime</span><span class="params">(<span class="keyword">long</span> time, W window,</span></span></span><br><span class="line"><span class="function"><span class="params">            TriggerContext ctx)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">    <span class="comment">//主要用在sessionWindow，窗口合并的时候调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onMerge</span><span class="params">(W window, OnMergeContext ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(<span class="string">"This trigger does not support merging."</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Flink实现了几种常用的触发器。</p>
<ul>
<li>EventTimeTrigger：当水位线大于窗口的结束时间时触发，一般用在事件时间的语义下。</li>
<li>ProcessingTimeTrigger：当系统时间大于窗口结束时间时触发，一般用在系统时间的语义下。</li>
<li>CountTrigger：当窗口中的数据量大于一定值时触发。</li>
<li>DeltaTrigger：根据阈值函数计算出的阈值来判断窗口是否触发。</li>
</ul>
<p>其中经常会用到的是根据系统时间和事件来判断窗口是否触发的触发器，我们来看下其实现过程。<br>我们先来看ProcessingTimeTrigger是怎么实现的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> TriggerResult <span class="title">onElement</span><span class="params">(Object element, <span class="keyword">long</span> timestamp,</span></span></span><br><span class="line"><span class="function"><span class="params">        TimeWindow window, TriggerContext ctx)</span> </span>&#123;</span><br><span class="line">    ctx.registerProcessingTimeTimer(window.maxTimestamp());</span><br><span class="line">    <span class="keyword">return</span> TriggerResult.CONTINUE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在onElement方法中，调用triggerContext注册了窗户最大时间的定时器，tiggerContext中调用InternalTimerService来进行定时器注册。<br>InternalTimerService是Flink内部定时器的存储管理类。<br>整个调用及实现过程如图所示。</p>
<p><img src="/2022/12/05/flink/image-15.png" width="700px"></p>
<p>ProcessingTimeTriggerInternalTimerServiceImpl内部维护了一个有序的队列，用来存储定时器（TimerHeap-InternalTimer），并且利用ProcessingTimeService来延迟调度基于系统时间生成的Trigger-Task。<br>TriggerTask会调用InternalTimerServiceImpl的onProcessingTime方法，onProcessing-Time会调用真正的目标（WindowOperator）onProcessingTime方法，完成一次定时器的触发。<br>在InternalTimerServiceImpl调用onProcessingTime方法的过程中，会重设上下文（Context）的键，确保后续操作都是针对当前键对应的数据。</p>
<blockquote>
<p>那么EventTimeTrigger和ProcessingTimeTrigger在实现上有什么不一样呢？</p>
</blockquote>
<p>首先我们知道，基于事件时间的触发器必然与事件时间有关。而事件时间不是有序的，不能像系统时间那样，用延迟任务来触发。</p>
<p>么什么时候触发基于事件时间的定时器呢？<br>水位线（Watermark）在Flink中是用来推动基于事件时间的处理动作执行的，也就是说水位线代表了事件的最晚到达时间。<br>我们就可以采用水位线来触发基于事件时间的定时器，事实上Flink也是如此实现的，我们来看代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> TriggerResult <span class="title">onElement</span><span class="params">(Object element, <span class="keyword">long</span> timestamp,</span></span></span><br><span class="line"><span class="function"><span class="params">        TimeWindow window, TriggerContext ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (window.maxTimestamp() &lt;= ctx.getCurrentWatermark()) &#123;</span><br><span class="line">        <span class="comment">// 如果水位线经过窗口，那么就触发</span></span><br><span class="line">        <span class="keyword">return</span> TriggerResult.FIRE;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        ctx.registerEventTimeTimer(window.maxTimestamp());</span><br><span class="line">        <span class="keyword">return</span> TriggerResult.CONTINUE;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上代码是EventTimeTrigger的onElement方法，与ProcessingTimeTrigger一样，如果条件不满足，那就调用TriggerContext来注册一个事件时间定时器，这里的依据是水位线是否大于窗口最大时间。<br>同样TriggerContext会调用InternalTimerServiceImpl的registerEventTimeTimer来真正注册定时器，InternalTimerServiceImpl注册的动作也就是把定时器（TimerHeapInternalTimer）放到一个有序队列中（eventTimeTimersQueue），之后就等水位线来触发。</p>
<p>如图所示整个触发过程是通过StreamTask处理水位线来驱动的，经过一系列的调用，由InternalTimeServiceManager完成触发器的触发，触发条件是水位线大于定时器的时间。</p>
<p><img src="/2022/12/05/flink/image-16.png" width="800px"></p>
<p>上面分析了EventTimeTrigger和ProcessingTimeTrigger的实现过程，其他触发器，如CountTrigger相对简单些，通过条件（数量是否大于阈值）就可以完成是否触发的判断，这里不再讨论。</p>
<h3 id="窗口函数"><a href="#窗口函数" class="headerlink" title="窗口函数"></a>窗口函数</h3><p>当前介绍当窗口完成触发的时候，窗口函数怎么执行。</p>
<p>Flink中的窗口函数主要有ReduceFunction、AggregateFunction、ProcessWindow-Function三种（FoldFunction理论上可以通过AggregateFunction实现，并且Flink从1.8版本开始已经把该函数标记为Deprecated，因此该函数我们不再讨论）。<br>在实际使用中推荐使用前两种，因为它们是增量计算，每条数据都会触发计算，而且窗口状态中只保留计算结果。<br>而ProcessWindowFunction（或者使用了驱逐器之后）需要窗口把所有的数据保留下来，到窗口触发的时候，调用窗口函数计算，效率比较低，而且会造成大量状态缓存。</p>
<p>下面我们详细看下前两种窗户函数的实现。</p>
<h4 id="ReduceFunction"><a href="#ReduceFunction" class="headerlink" title="ReduceFunction"></a>ReduceFunction</h4><p>ReduceFunction的接口定义如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ReduceFunction</span>&lt;<span class="title">T</span>&gt; <span class="keyword">extends</span> <span class="title">Function</span>, <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="function">T <span class="title">reduce</span><span class="params">(T value1, T value2)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ReduceFunction是一个输入、输出类型一样的简单聚合函数，可以用来实现max()、min()、sum()等聚合函数。<br>在WindowOperator中并不直接使用ReduceFunction作为算子的userFunction，而要经过层层包装。主要包装类有两类。</p>
<ul>
<li>一类是WindowFunction，用来指导具体的窗口函数怎么计算。比如PassThroughWindowFunction，它表示不调用用户的窗口函数，直接输出结果，用来包装ReduceFunction和AggregateFunction，因为这两个函数在窗口触发的时候已经计算好了结果，只需要发送结果即可。</li>
<li>另一类是InternalWindowFunction的实现类，主要用来封装窗口数据的类型，然后实际调用前面讲的第一类包装窗口类。</li>
</ul>
<p>这么讲有点抽象，我们具体来看ReduceFunction函数在Flink中是怎么调用的。我们看在WindowStream中调用reduce方法之后会发生什么。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> SingleOutputStreamOperator&lt;T&gt; <span class="title">reduce</span><span class="params">(ReduceFunction&lt;T&gt; function)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (function <span class="keyword">instanceof</span> RichFunction) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(</span><br><span class="line">            <span class="string">"ReduceFunction of reduce can not be a RichFunction. "</span></span><br><span class="line">            + <span class="string">"Please use reduce(ReduceFunction, WindowFunction) instead."</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 清除闭包</span></span><br><span class="line">    function = input.getExecutionEnvironment().clean(function);</span><br><span class="line">    <span class="keyword">return</span> reduce(function, <span class="keyword">new</span> PassThroughWindowFunction&lt;K, W, T&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接着调用重载的reduce方法（下面只列出关键代码）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;R&gt; <span class="function">SingleOutputStreamOperator&lt;R&gt; <span class="title">reduce</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        ReduceFunction&lt;T&gt; reduceFunction,</span></span></span><br><span class="line"><span class="function"><span class="params">        WindowFunction&lt;T, R, K, W&gt; function,</span></span></span><br><span class="line"><span class="function"><span class="params">        TypeInformation&lt;R&gt; resultType)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    operator = <span class="keyword">new</span> WindowOperator&lt;&gt;(</span><br><span class="line">            windowAssigner,</span><br><span class="line">            windowAssigner.getWindowSerializer(getExecutionEnvironment().getConfig()),</span><br><span class="line">            keySel,</span><br><span class="line">            input.getKeyType().createSerializer(getExecutionEnvironment().getConfig()),</span><br><span class="line">            stateDesc,</span><br><span class="line">            <span class="keyword">new</span> InternalSingleValueWindowFunction&lt;&gt;(function),</span><br><span class="line">            trigger,</span><br><span class="line">            allowedLateness,</span><br><span class="line">            lateDataOutputTag);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到最终传给WindowOperartor的function是一个new InternalSingleValue-WindowFunction (new PassThroughWindowFunction())的实例对象。<br>PassThroughWindow-Function我们在前面讲过，该函数什么也不做只是把输出发送出去。<br>再看InternalSingle-ValueWindowFunction，它也是基本什么都不做（只是把单个input对象转为集合对象<br>这就是我们刚才说的该类包装类用来把输入转换为合适的类型），只是调用刚才传入它内部的PassThroughWindowFunction，WindowOperator最终拿到的窗口函数就是把结果发送出去，不进行任何计算。</p>
<blockquote>
<p>那么我们传入的ReduceFunction怎么起作用？什么时候调用呢？</p>
</blockquote>
<p>我们来看ReduceFunction传入WindowedStream之后用在了哪里，还是刚才的reduce方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ReducingStateDescriptor&lt;T&gt; stateDesc = <span class="keyword">new</span> ReducingStateDescriptor&lt;&gt;(</span><br><span class="line">    <span class="string">"window-contents"</span>,</span><br><span class="line">    reduceFunction,</span><br><span class="line">    input.getType().createSerializer(getExecutionEnvironment().getConfig()));</span><br></pre></td></tr></table></figure>
<p>由这样一段代码可以看到reduceFunction被放到了StateDescriptor中，用来生成我们需要的ReducingState，并且reduceFunction被传递给ReducingState，用来进行真正的计算。<br>我们来看ReducingState的实现类RocksDBReducingState的add方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(V value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">byte</span>[] key = getKeyBytes();</span><br><span class="line">    V oldValue = getInternal(key);</span><br><span class="line">    <span class="comment">// 这里reduceFunction函数被调用</span></span><br><span class="line">    V newValue = oldValue == <span class="keyword">null</span> ? value : reduceFunction.reduce(oldValue, value);</span><br><span class="line">    updateInternal(key, newValue);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><br></p>
<h4 id="AggregateFunction"><a href="#AggregateFunction" class="headerlink" title="AggregateFunction"></a>AggregateFunction</h4><p>AggregateFunction是对ReduceFunction的扩展，可以接受三种类型的参数——输出、计算和输出，它的适用范围比ReduceFunction更广。<br>其实现过程与ReduceFunction基本一致，这里不再赘述。</p>
<p><br><br><br> </p>
<h1 id="运行时组件与通信"><a href="#运行时组件与通信" class="headerlink" title="运行时组件与通信"></a>运行时组件与通信</h1><p>Flink运行时作为Flink引擎的核心部分，支撑着Flink流作业和批作业的运行，同时保障作业的高可用和可扩展性等。<br>Flink运行时采用Master-Worker的架构，其中Flink的Master节点为JobManager，Worker节点为TaskManager。<br>本节结合运行时架构设计与源代码的实现来深入剖析运行时组件、组件间通信及运行时组件的高可用。</p>
<p>首先介绍运行时的主要组件REST、Dispatcher、JobMaster、Resource-Manager和TaskExecutor<br>然后对这些组件的通信架构和组件间的核心通信进行深入分析，最后对运行时组件的高可用的设计与实现进行剖析。</p>
<h2 id="运行时组件"><a href="#运行时组件" class="headerlink" title="运行时组件"></a>运行时组件</h2><p><img src="/2022/12/05/flink/image-17.png" width="800px"></p>
<p>运行时组件的功能如下。</p>
<p>在运行时的架构里，JobManager（Master节点）包括REST、Dispatcher、Resource-Manager和JobMaster，而TaskManager（Worker节点）主要有TaskExecutor。</p>
<ul>
<li>REST的主体部分WebMonitorEndpoint接收客户端的HTTP请求，提供各种REST服务，如作业、集群的指标、各种作业信息的情况、操作作业等。</li>
<li>Dispatcher的主要功能是接收REST转发的操作JobMaster请求，启动和管理JobMaster。</li>
<li>JobMaster主要负责作业的运行调度和检查点的协调。</li>
<li>ResourceManager在不同部署模式下对资源进行管理（主要包括申请、回收资源及资源状态管控）。</li>
<li>TaskExecutor对资源（CPU、内存等）以逻辑的Slot进行划分，Slot供作业的Task调度到其上运行。</li>
</ul>
<h3 id="REST"><a href="#REST" class="headerlink" title="REST"></a>REST</h3><p>REST是JobManager暴露给外部的服务，主要为客户端和前端提供HTTP服务。<br>REST部分源代码的核心是WebMonitorEndpoint类，WebMonitorEndpoint相关类的类图架构如图所示。</p>
<p><img src="/2022/12/05/flink/image-18.png" width="500px"></p>
<p>从REST的类图可以知道以下两点。</p>
<ul>
<li>WebMonitorEndpoint继承RestServerEndpoint类，实现JsonArchivist和Leader-Contender接口<br>  其中：RestServerEndpoint是基于Netty实现的抽象类，是整个暴露REST服务的核心部分；JsonArchivist接口定义了基于ExecutionGraph（作业执行图）生成JSON的接口，供查询作业执行图信息的Handler（处理器）来实现；LeaderContender接口定义了WebMonitorEndpoint在首领（Leader）选举方面的处理方法。LeaderContender会在后面节详细介绍。</li>
<li>MiniDispatcherRestEndpoint和DispatcherRestEndpoint作为WebMonitorEndpoint的子类实现。<br>  两者的区别是MiniDispatcherRestEndpoint是作为Per-Job模式（一个作业对应一个集群的模式）的实现，而DispatcherRestEndpoint是作为Session模式的实现（一个集群可以有多个作业的模式）。</li>
</ul>
<p>WebMonitorEndpoint的核心是启动过程，启动完成即可为外部提供REST服务。<br>WebMontiorEndpoint的启动过程如下</p>
<ul>
<li>初始化处理外部请求的Handler；</li>
<li>将处理外部请求Handler注册到路由器（Router）</li>
<li>创建并启动NettyServer；</li>
<li>启动首领选举服务。</li>
</ul>
<h4 id="初始化所有Handler"><a href="#初始化所有Handler" class="headerlink" title="初始化所有Handler"></a>初始化所有Handler</h4><p>在WebMonitorEndpoint的启动过程中，会调用父类RestServerEndpoint的start方法，而该方法执行流程的第一步是初始化Handler，如代码清单所示。<br>代码清单RestServerEndpoint启动过程中调用初始化的所有Handler部分</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line">        Preconditions.checkState(state == State.CREATED, <span class="string">"The RestServerEndpoint cannot be restarted."</span>);</span><br><span class="line"></span><br><span class="line">        log.info(<span class="string">"Starting rest endpoint."</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> Router router = <span class="keyword">new</span> Router();</span><br><span class="line">        <span class="keyword">final</span> CompletableFuture&lt;String&gt; restAddressFuture = <span class="keyword">new</span> CompletableFuture&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        handlers = initializeHandlers(restAddressFuture);</span><br><span class="line">        ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中initializeHandlers方法在RestServerEndpoint类里是抽象的，具体实现在Web-MonitorEndpoint和DispatcherRestEndpoint类里。<br>DispatcherRestEndpoint与WebMonitor-Endpoint的initializeHandlers方法实现的不同之处在于</p>
<ul>
<li>DispatcherRestEndpoint作为Web-MonitorEndpoint的子类，会调用其initializeHandlers方法，同时多添加JobSubmitHandler，开启Web提交功能（默认是开启的），会添加WebSubmissionExtension类里对应的Handler</li>
<li>而WebSubmissionExtension里对应的Handler就是处理Flink UI中Submit New Job选项卡中相关的请求，包括上传Jar包、生成Jar列表、删除Jar、执行Jar、生成执行图。</li>
</ul>
<p>WebMonitorEndpoint与DispatcherRestEndpoint的initializeHandlers方法分别如代码清单所示。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">protected</span> List&lt;Tuple2&lt;RestHandlerSpecification, ChannelInboundHandler&gt;&gt;</span><br><span class="line">        initializeHandlers(<span class="keyword">final</span> CompletableFuture&lt;String&gt; localAddressFuture) &#123;</span><br><span class="line">    ArrayList&lt;Tuple2&lt;RestHandlerSpecification, ChannelInboundHandler&gt;&gt; handlers = <span class="keyword">new</span> ArrayList&lt;&gt;(<span class="number">30</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> Time timeout = restConfiguration.getTimeout();</span><br><span class="line"></span><br><span class="line">    ClusterOverviewHandler clusterOverviewHandler = <span class="keyword">new</span> ClusterOverviewHandler(</span><br><span class="line">            leaderRetriever,</span><br><span class="line">            timeout,</span><br><span class="line">            responseHeaders,</span><br><span class="line">            ClusterOverviewHeaders.getInstance());</span><br><span class="line">            ...</span><br><span class="line">            handlers.add(Tuple2.of(clusterOverviewHandler.getMessageHeaders(), clusterOverviewHandler));</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> handlers</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">protected</span> List&lt;Tuple2&lt;RestHandlerSpecification, ChannelInboundHandler&gt;&gt;</span><br><span class="line">        initializeHandlers(<span class="keyword">final</span> CompletableFuture&lt;String&gt; localAddressFuture) &#123;</span><br><span class="line">    List&lt;Tuple2&lt;RestHandlerSpecification, ChannelInboundHandler&gt;&gt; handlers =</span><br><span class="line">            <span class="keyword">super</span>.initializeHandlers(localAddressFuture);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> Time timeout = restConfiguration.getTimeout();</span><br><span class="line"></span><br><span class="line">    JobSubmitHandler jobSubmitHandler = <span class="keyword">new</span> JobSubmitHandler(</span><br><span class="line">            leaderRetriever,</span><br><span class="line">            timeout,</span><br><span class="line">            responseHeaders,</span><br><span class="line">            executor,</span><br><span class="line">            clusterConfiguration);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (restConfiguration.isWebSubmitEnabled()) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            webSubmissionExtension = WebMonitorUtils.loadWebSubmissionExtension(</span><br><span class="line">                    leaderRetriever,</span><br><span class="line">                    timeout,</span><br><span class="line">                    responseHeaders,</span><br><span class="line">                    localAddressFuture,</span><br><span class="line">                    uploadDir,</span><br><span class="line">                    executor,</span><br><span class="line">                    clusterConfiguration);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 注册WebSubmissionExtension的Handler</span></span><br><span class="line">            handlers.addAll(webSubmissionExtension.getHandlers());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (FlinkException e) &#123;</span><br><span class="line">            <span class="keyword">if</span> (log.isDebugEnabled()) &#123;</span><br><span class="line">                log.debug(<span class="string">"Failed to load web based job submission extension."</span>, e);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                log.info(<span class="string">"Failed to load web based job submission extension. "</span></span><br><span class="line">                + <span class="string">"Probable reason: flink-runtime-web is not in the classpath."</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        log.info(<span class="string">"Web-based job submission is not enabled."</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    handlers.add(Tuple2.of(jobSubmitHandler.getMessageHeaders(), jobSubmitHandler));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> handlers;</span><br></pre></td></tr></table></figure></p>
<p>所有的Handler都继承自AbstractHandler，而AbstractHandler类的架构如图所示。</p>
<p><img src="/2022/12/05/flink/image-19.png" width="400px"></p>
<p>从图可知AbstractHandler会继承SimpleChannelInboundHandler，可以添加到ChannelPipeline，来处理Channel入站的数据以及各种状态变化。所有的Handler都有以下几个特点。</p>
<ul>
<li>所有的Handler类在org.apache.flink.runtime.rest.handler包下面。</li>
<li>所有的Handler都有MessageHeaders的属性。MessageHeaders属性包含请求的URL、请求的参数类型、请求参数、响应的类型、响应返回码、HTTP请求类型和是否接收文件上传等。</li>
<li>Handler会根据各自的需要，使用WebMonitor的LeaderRetriever和ResourceManager-Retriever字段分别对Dispatcher和ResourceManager进行访问，来获取与作业和资源相关的信息。</li>
</ul>
<p><br></p>
<h4 id="Handler注册Router"><a href="#Handler注册Router" class="headerlink" title="Handler注册Router"></a>Handler注册Router</h4><p>WebMonitorEndpoint的启动过程为：初始化所有的Handler，初始化后的Handler会注册到Router，方便后面的RouterHandler将请求路由到正确的Handler进行处理。<br>WebMonitorEndpoint的子类DispatcherRestEndpoint的启动过程为：初始化Handler，并将Handler注册到Router的列表中，如代码清单所示。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">    handlers = initializeHandlers(restAddressFuture);</span><br><span class="line">    <span class="comment">// 基于URL进行排序</span></span><br><span class="line">    Collections.sort(</span><br><span class="line">            handlers,</span><br><span class="line">            RestHandlerUrlComparator.INSTANCE);</span><br><span class="line">    <span class="comment">// 遍历所有Handler并将其注册到Router</span></span><br><span class="line">    handlers.forEach(handler -&gt; &#123;</span><br><span class="line">        registerHandler(router, handler, log);</span><br><span class="line">    &#125;);</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如代码清单所示，Handler注册到Router时（DispatcherRestEndpoint调用父类RestServerEnpoint类的registerHandler方法），DispatcherRestEndpoint会根据HttpMethod的请求，调用将Handler注册到Router中对应的HttpMethod的列表中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">registerHandler</span><span class="params">(Router router, String handlerURL,</span></span></span><br><span class="line"><span class="function"><span class="params">        HttpMethodWrapper httpMethod, ChannelInboundHandler handler)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">switch</span> (httpMethod) &#123;</span><br><span class="line">        <span class="keyword">case</span> GET:</span><br><span class="line">            router.addGet(handlerURL, handler);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> POST:</span><br><span class="line">            router.addPost(handlerURL, handler);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> DELETE:</span><br><span class="line">            router.addDelete(handlerURL, handler);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> PATCH:</span><br><span class="line">            router.addPatch(handlerURL, handler);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"Unsupported http method: "</span>+httpMethod+<span class="string">'.'</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中Router类的Handler的注册信息是一个嵌套的Map结构，Router的routers属性（Router类的Handler注册信息）是一个HttpMethod映射到MethodlessRouter的Map（Map&lt;HttpMethod,MethodlessRouter&gt;），而MethodlessRouter中的routes属性是一个PathPattern映射到Handler的Map，其中PathPattern由请求URL的path全路径和path基于path分隔符拆分成单词的数组属性组成。</p>
<p>Router的Handler注册信息的结构如图所示。</p>
<p><img src="/2022/12/05/flink/image-20.png" width="400px"></p>
<p><br></p>
<h4 id="创建与启动NettyServer"><a href="#创建与启动NettyServer" class="headerlink" title="创建与启动NettyServer"></a>创建与启动NettyServer</h4><p>在初始化所有Handler并将其注册到Router列表后，会创建和启动NettyServer，以暴露给外部REST服务。<br>创建与启动NettyServer有两部分：初始化处理Channel和绑定端口启动，如代码清单所示。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    ChannelInitializer&lt;SocketChannel&gt; initializer = <span class="keyword">new</span> ChannelInitializer&lt;SocketChannel&gt;() &#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">initChannel</span><span class="params">(SocketChannel ch)</span> </span>&#123;</span><br><span class="line">            RouterHandler handler = <span class="keyword">new</span> RouterHandler(router, responseHeaders);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (isHttpsEnabled()) &#123;</span><br><span class="line">                ch.pipeline().addLast(<span class="string">"ssl"</span>, <span class="keyword">new</span> RedirectingSslHandler(</span><br><span class="line">                            restAddress, restAddressFuture, sslHandlerFactory));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            ch.pipeline()</span><br><span class="line">                    .addLast(<span class="keyword">new</span> HttpServerCodec())</span><br><span class="line">                    .addLast(<span class="keyword">new</span> FileUploadHandler(uploadDir))</span><br><span class="line">                    .addLast(<span class="keyword">new</span> FlinkHttpObjectAggregator(maxContentLength, responseHeaders))</span><br><span class="line">                    .addLast(<span class="keyword">new</span> ChunkedWriteHandler())</span><br><span class="line">                    .addLast(handler.getName(), handler)</span><br><span class="line">                    .addLast(<span class="keyword">new</span> PipelineErrorHandler(log, responseHeaders));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    NioEventLoopGroup bossGroup = <span class="keyword">new</span> NioEventLoopGroup(<span class="number">1</span>,</span><br><span class="line">            <span class="keyword">new</span> ExecutorThreadFactory(<span class="string">"flink-rest-server-netty-boss"</span>));</span><br><span class="line">    NioEventLoopGroup workerGroup = <span class="keyword">new</span> NioEventLoopGroup(<span class="number">0</span>,</span><br><span class="line">            <span class="keyword">new</span> ExecutorThreadFactory(<span class="string">"flink-rest-server-netty-worker"</span>));</span><br><span class="line"></span><br><span class="line">    bootstrap = <span class="keyword">new</span> ServerBootstrap();</span><br><span class="line">    bootstrap</span><br><span class="line">            .group(bossGroup, workerGroup)</span><br><span class="line">            .channel(NioServerSocketChannel.class)</span><br><span class="line">            .childHandler(initializer);</span><br><span class="line"></span><br><span class="line">    Iterator&lt;Integer&gt; portsIterator;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        portsIterator = NetUtils.getPortRangeFromString(restBindPortRange);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IllegalConfigurationException e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Invalid port range definition: "</span> + restBindPortRange);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> chosenPort = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (portsIterator.hasNext()) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            chosenPort = portsIterator.next();</span><br><span class="line">            <span class="keyword">final</span> ChannelFuture channel;</span><br><span class="line">            <span class="keyword">if</span> (restBindAddress == <span class="keyword">null</span>) &#123;</span><br><span class="line">                channel = bootstrap.bind(chosenPort);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                channel = bootstrap.bind(restBindAddress, chosenPort);</span><br><span class="line">            &#125;</span><br><span class="line">            serverChannel = channel.syncUninterruptibly().channel();</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (<span class="keyword">final</span> Exception e) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!(e <span class="keyword">instanceof</span> org.jboss.netty.channel.ChannelException</span><br><span class="line">                    || e <span class="keyword">instanceof</span> java.net.BindException)) &#123;</span><br><span class="line">                <span class="keyword">throw</span> e;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (serverChannel == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> BindException(<span class="string">"Could not start rest endpoint on any port in port range "</span></span><br><span class="line">                + restBindPortRange);</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中初始化Channel会创建ChannelPipeline。ChannelPipeline的结构如图所示，它包含六部分，各部分的功能如下</p>
<p><img src="/2022/12/05/flink/image-21.png" width="700px"></p>
<ul>
<li>HttpServerCodec：负责HTTP消息的解码与编码。FileUploadHandler：负责处理文件上传。</li>
<li>FlinkHttpObjectAggragator：继承HttpObjectAggregator，负责将多个HTTP消息组装成一个完整的HTTP请求或者HTTP响应。</li>
<li>ChunkedWriteHandler：负责大的数据流的处理，比如查看TaskManager/JobManager的日志和标准输出的Handler的处理。</li>
<li>RouterHandler：REST服务暴露的核心，会根据URL路由到正确的Handler进行相应的逻辑处理。</li>
<li>PipelineErrorHandler：负责记录异常日志，并返回HTTP异常响应。只有前面五部分因异常情况没有发送HTTP响应，才会执行到PipelineErrorHandler。</li>
</ul>
<p>RouterHandler负责将HTTP请求路由到正确的Handler，分以下两个步骤。</p>
<ul>
<li>通过初始化Handler注册到Router的注册信息，找到HTTP请求对应的路由结果，对于路由结果为空的，返回消息为Not Found、状态码为404的HTTP响应，如代码清单所示。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">channelRead0</span><span class="params">(ChannelHandlerContext channelHandlerContext, HttpRequest httpRequest)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (HttpHeaders.is100ContinueExpected(httpRequest)) &#123;</span><br><span class="line">        channelHandlerContext.writeAndFlush(<span class="keyword">new</span> DefaultFullHttpResponse(</span><br><span class="line">                HttpVersion.HTTP_1_1, HttpResponseStatus.CONTINUE));</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 根据HTTP请求信息，在路由列表中查找</span></span><br><span class="line">    HttpMethod method = httpRequest.getMethod();</span><br><span class="line">    QueryStringDecoder qsd = <span class="keyword">new</span> QueryStringDecoder(httpRequest.uri());</span><br><span class="line">    RouteResult&lt;?&gt; routeResult = router.route(method, qsd.path(), qsd.parameters());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (routeResult == <span class="keyword">null</span>) &#123;</span><br><span class="line">        respondNotFound(channelHandlerContext, httpRequest);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    routed(channelHandlerContext, routeResult, httpRequest);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>根据路由的结果，触发对应的Handler的消息处理，如代码清单所示。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">routed</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        ChannelHandlerContext channelHandlerContext,</span></span></span><br><span class="line"><span class="function"><span class="params">        RouteResult&lt;?&gt; routeResult,</span></span></span><br><span class="line"><span class="function"><span class="params">        HttpRequest httpRequest)</span> </span>&#123;</span><br><span class="line">    ChannelInboundHandler handler = (ChannelInboundHandler) routeResult.target();</span><br><span class="line"></span><br><span class="line">    ChannelPipeline pipeline  = channelHandlerContext.pipeline();</span><br><span class="line">    ChannelHandler addedHandler = pipeline.get(ROUTED_HANDLER_NAME);</span><br><span class="line">    <span class="keyword">if</span> (handler != addedHandler) &#123;</span><br><span class="line">        <span class="keyword">if</span> (addedHandler == <span class="keyword">null</span>) &#123;</span><br><span class="line">            pipeline.addAfter(ROUTER_HANDLER_NAME, ROUTED_HANDLER_NAME, handler);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            pipeline.replace(addedHandler, ROUTED_HANDLER_NAME, handler);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    RoutedRequest&lt;?&gt; request = <span class="keyword">new</span> RoutedRequest&lt;&gt;(routeResult, httpRequest);</span><br><span class="line">    channelHandlerContext.fireChannelRead(request.retain());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><br></p>
<h4 id="启动Leader选举服务"><a href="#启动Leader选举服务" class="headerlink" title="启动Leader选举服务"></a>启动Leader选举服务</h4><p>在WebMonitorEndpoint的启动过程中，最后的部分启动首领选举服务，如代码清单所示。<br>首领选举服务会在后面节详细介绍。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    startInternal();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">startInternal</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    leaderElectionService.start(<span class="keyword">this</span>);</span><br><span class="line">    <span class="keyword">if</span> (hasWebUI) &#123;</span><br><span class="line">        log.info(<span class="string">"Web frontend listening at &#123;&#125;."</span>, getRestBaseUrl());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><br></p>
<h3 id="Dispatcher"><a href="#Dispatcher" class="headerlink" title="Dispatcher"></a>Dispatcher</h3><p>Dispatcher组件负责接收作业的提交、对作业进行持久化、产生新的JobMaster执行作业、在JobManager节点崩溃恢复时恢复所有作业的执行，以及管理作业对应JobMaster的状态。<br>Dispatcher组件的基础类为Dispatcher，Dispatcher组件相关的类图如图所示。</p>
<p><img src="/2022/12/05/flink/image-22.png" width="800px"></p>
<blockquote>
<p>从上类图得知以下几点</p>
</blockquote>
<ul>
<li>Dispatcher作为抽象类，继承FencedRpcEndpoint类，来对外部提供RPC（Remote Procedure Call，远程过程调用）；Dispatcher实现LeaderContender接口，来处理首领选举；Dispatcher实现DispatcherGateway接口，提供给REST组件通过RPC调用的方法来暴露其服务；Dispatcher实现SubmittedJobGraphListener接口，来实现侦听持久化作业信息变更后的处理逻辑。</li>
<li>MiniDispatcher类和StandaloneDispatcher类作为Dispatcher的子类实现。两者的不同是，MiniDispatcher类是作为Per-Job模式（一个作业对应一个集群的模式）的实现，而StandaloneDispatcher是作为Session模式（一个集群可以有多个作业的模式）的实现。</li>
</ul>
<blockquote>
<p>接下来重点看下Dispatcher接收到REST提交作业的消息后的处理过程</p>
</blockquote>
<p><img src="/2022/12/05/flink/image-23.png" width="200px"></p>
<ul>
<li>检查作业是否重复，防止一个作业在JobManager进程中被多次调度运行；</li>
<li>执行该作业前一次运行未完成的终止逻辑（同一个jobId的作业）；</li>
<li>持久化作业的jobGraph；</li>
<li>创建JobManagerRunner；</li>
<li>JobManagerRunner构建JobMaster用来负责作业的运行；</li>
<li>启动JobManagerRunner。</li>
</ul>
<p>其中REST将作业提交到Dispatcher，是通过RPC调用Dispatcher实现DispatcherGateway的submitJob方法完成的。<br>该方法包括两部分：对提交的作业进行检查和执行提交作业逻辑，其中执行提交作业逻辑对应于上面处理过程的第2～6步。</p>
<blockquote>
<p>Dispatcher处理作业提交方法</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Acknowledge&gt; <span class="title">submitJob</span><span class="params">(JobGraph jobGraph, Time timeout)</span> </span>&#123;</span><br><span class="line">    log.info(<span class="string">"Received JobGraph submission &#123;&#125; (&#123;&#125;)."</span>, jobGraph.getJobID(), jobGraph.getName());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 检查作业是否重复</span></span><br><span class="line">        <span class="keyword">if</span> (isDuplicateJob(jobGraph.getJobID())) &#123;</span><br><span class="line">            <span class="keyword">return</span> FutureUtils.completedExceptionally(</span><br><span class="line">                    <span class="keyword">new</span> JobSubmissionException(jobGraph.getJobID(), <span class="string">"Job has already been submitted."</span>));</span><br><span class="line">        <span class="comment">// 检查作业是否进行对Task（任务）级别进行资源设置</span></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (isPartialResourceConfigured(jobGraph)) &#123;</span><br><span class="line">            <span class="keyword">return</span> FutureUtils.completedExceptionally(</span><br><span class="line">                <span class="keyword">new</span> JobSubmissionException(jobGraph.getJobID(),</span><br><span class="line">                    <span class="string">"Currently jobs is not supported if parts of the vertices have "</span></span><br><span class="line">                    + <span class="string">"resources configured. The limitation will be removed "</span></span><br><span class="line">                    + <span class="string">"in future versions."</span>));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> internalSubmitJob(jobGraph);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (FlinkException e) &#123;</span><br><span class="line">        <span class="keyword">return</span> FutureUtils.completedExceptionally(e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="检查作业是否重复"><a href="#检查作业是否重复" class="headerlink" title="检查作业是否重复"></a>检查作业是否重复</h4><p>处理作业的第一步是检查作业是否重复。<br>如代码清单所示，检查作业是否重复的逻辑就是判断作业是否执行过或者作业是否正在执行中。<br>其中jobManagerRunnerFutures属性在创建jobManagerRunner成功时会添加数据，而在创建或者启动JobManagerRunner失败以及移除作业时，会移除对应作业的数据。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">isDuplicateJob</span><span class="params">(JobID jobId)</span> <span class="keyword">throws</span> FlinkException </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> RunningJobsRegistry.JobSchedulingStatus jobSchedulingStatus;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        jobSchedulingStatus = runningJobsRegistry.getJobSchedulingStatus(jobId);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> FlinkException(String.format(</span><br><span class="line">              <span class="string">"Failed to retrieve job scheduling status for job %s."</span>, jobId), e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> jobSchedulingStatus == RunningJobsRegistry.JobSchedulingStatus.DONE</span><br><span class="line">            || jobManagerRunnerFutures.containsKey(jobId);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="作业提交过程"><a href="#作业提交过程" class="headerlink" title="作业提交过程"></a>作业提交过程</h4><p>如代码清单所示，提交作业的处理过程是先执行作业的前一次未完成的退出逻辑，再执行持久化和运行作业（上面提到的处理逻辑的第3~5步）。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> CompletableFuture&lt;Acknowledge&gt; <span class="title">internalSubmitJob</span><span class="params">(JobGraph jobGraph)</span> </span>&#123;</span><br><span class="line">    log.info(<span class="string">"Submitting job &#123;&#125; (&#123;&#125;)."</span>, jobGraph.getJobID(), jobGraph.getName());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> CompletableFuture&lt;Acknowledge&gt; persistAndRunFuture =</span><br><span class="line">            waitForTerminatingJobManager(jobGraph.getJobID(), jobGraph, <span class="keyword">this</span>::persistAndRunJob)</span><br><span class="line">            .thenApply(ignored -&gt; Acknowledge.get());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> persistAndRunFuture.handleAsync((acknowledge, throwable) -&gt; &#123;</span><br><span class="line">        <span class="keyword">if</span> (throwable != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 持久化和运行作业失败，清除作业对应的数据（主要是作业的HA的数据，// 存储在ZooKeeper和HDFS中）</span></span><br><span class="line">            cleanUpJobData(jobGraph.getJobID(), <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">final</span> Throwable strippedThrowable = ExceptionUtils.stripCompletionException(throwable);</span><br><span class="line">            log.error(<span class="string">"Failed to submit job &#123;&#125;."</span>, jobGraph.getJobID(), strippedThrowable);</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> CompletionException(</span><br><span class="line">                    <span class="keyword">new</span> JobSubmissionException(jobGraph.getJobID(), <span class="string">"Failed to submit job."</span>,</span><br><span class="line">                        strippedThrowable));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> acknowledge;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, getRpcService().getExecutor());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中执行作业前一次未完成的终止过程是先获取前一次未完成的终止逻辑，执行终止成功后再调用持久化运行作业方法，如代码清单所示。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> CompletableFuture&lt;Void&gt; <span class="title">waitForTerminatingJobManager</span><span class="params">(JobID jobId, JobGraph jobGraph, FunctionWithException&lt;JobGraph, CompletableFuture&lt;Void&gt;, ?&gt; action)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> CompletableFuture&lt;Void&gt; jobManagerTerminationFuture = getJobTerminationFuture(jobId).exceptionally((Throwable throwable) -&gt; &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> CompletionException(<span class="keyword">new</span> DispatcherException(String.format(</span><br><span class="line">            <span class="string">"Termination of previous JobManager for job %s failed. Cannot submit"</span></span><br><span class="line">            + <span class="string">"job under the same job id."</span>,</span><br><span class="line">            jobId), throwable)); &#125;);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> jobManagerTerminationFuture.thenComposeAsync(</span><br><span class="line">            FunctionUtils.uncheckedFunction((ignored) -&gt; &#123;</span><br><span class="line">                jobManagerTerminationFutures.remove(jobId);</span><br><span class="line">                <span class="comment">// action是persistAndRunJob方法</span></span><br><span class="line">                <span class="keyword">return</span> action.apply(jobGraph);</span><br><span class="line">            &#125;),</span><br><span class="line">            getMainThreadExecutor());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码如下所示获取作业前一次未完成的终止的处理逻辑方法。<br>如果该作业还在运行列表中，则返回作业还在运行中的异常；否则就从终止作业的进度列表中获取。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">CompletableFuture&lt;Void&gt; <span class="title">getJobTerminationFuture</span><span class="params">(JobID jobId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (jobManagerRunnerFutures.containsKey(jobId)) &#123;</span><br><span class="line">        <span class="keyword">return</span> FutureUtils.completedExceptionally(<span class="keyword">new</span> DispatcherException(String.format(<span class="string">"Job with job id %s is still running."</span>, jobId)));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> jobManagerTerminationFutures.getOrDefault(jobId, CompletableFuture.completedFuture(<span class="keyword">null</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如下代码所示，在处理完作业前一次未完成的终止的逻辑后，执行持久化与运行作业。<br>持久化作业是指SumittedJobGraphStore对作业的JobGraph信息进行持久化，其中持久化作业的JobGraph信息是为了在JobManager崩溃恢复时，JobManager可以对作业进行恢复。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> CompletableFuture&lt;Void&gt; <span class="title">persistAndRunJob</span><span class="params">(JobGraph jobGraph)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="comment">// 持久化作业的DAG（JobGraph）</span></span><br><span class="line">    submittedJobGraphStore.putJobGraph(<span class="keyword">new</span> SubmittedJobGraph(jobGraph));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> CompletableFuture&lt;Void&gt; runJobFuture = runJob(jobGraph);</span><br><span class="line">    <span class="keyword">return</span> runJobFuture.whenComplete(BiConsumerWithException.unchecked((Object ignored, Throwable throwable) -&gt; &#123;</span><br><span class="line">        <span class="keyword">if</span> (throwable != <span class="keyword">null</span>) &#123;</span><br><span class="line">            submittedJobGraphStore.removeJobGraph(jobGraph.getJobID());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>而运行作业的逻辑是，首先创建JobManagerRunner，将创建JobManagerRunner的进度记录到已在运行的作业列表中，表示该作业已在执行，再启动JobManagerRunner，如下代码清单所示。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">CompletableFuture&lt;Void&gt; <span class="title">runJob</span><span class="params">(JobGraph jobGraph)</span> </span>&#123;</span><br><span class="line">    Preconditions.checkState(!jobManagerRunnerFutures.containsKey(jobGraph.getJobID()));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> CompletableFuture&lt;JobManagerRunner&gt; jobManagerRunnerFuture = createJobManagerRunner(jobGraph);</span><br><span class="line"></span><br><span class="line">    jobManagerRunnerFutures.put(jobGraph.getJobID(), jobManagerRunnerFuture);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> jobManagerRunnerFuture</span><br><span class="line">        .thenApply(FunctionUtils.uncheckedFunction(<span class="keyword">this</span>::startJobManagerRunner))</span><br><span class="line">        .thenApply(FunctionUtils.nullFn())</span><br><span class="line">        .whenCompleteAsync((ignored, throwable) -&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span> (throwable != <span class="keyword">null</span>) &#123;</span><br><span class="line">                jobManagerRunnerFutures.remove(jobGraph.getJobID());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, getMainThreadExecutor());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中启动JobManagerRunner的逻辑不单是处理JobManagerRunner的启动过程，还会通过JobManagerRunner调用getResultFuture方法，来对作业的执行情况进行侦听。<br>对于一直在正常运行的作业，getResultFuture是返回值，即不会执行handleAsync方法里的逻辑;<br>当作业运行状态变成终态（作业的终态有：CANCELED，作业被停止；FINISHED，作业已完成；FAILED，作业已不可恢复地异常失败）<br>以及JobManager启动或者运行出现异常时，会执行handleAsync方法里的逻辑，如下代码清单所示。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> JobManagerRunner <span class="title">startJobManagerRunner</span><span class="params">(JobManagerRunner jobManagerRunner)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> JobID jobId = jobManagerRunner.getJobGraph().getJobID();</span><br><span class="line">    FutureUtils.assertNoException(</span><br><span class="line">        jobManagerRunner.getResultFuture().handleAsync(</span><br><span class="line">        (ArchivedExecutionGraph archivedExecutionGraph, Throwable throwable) -&gt; &#123;</span><br><span class="line">            <span class="comment">// 检查作业是否在执行中</span></span><br><span class="line">            <span class="keyword">final</span> CompletableFuture&lt;JobManagerRunner&gt; jobManagerRunnerFuture =</span><br><span class="line">                    jobManagerRunnerFutures.get(jobId);</span><br><span class="line">            <span class="keyword">final</span> JobManagerRunner currentJobManagerRunner =</span><br><span class="line">                    jobManagerRunnerFuture != <span class="keyword">null</span> ? jobManagerRunnerFuture.getNow(<span class="keyword">null</span>) : <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">if</span> (jobManagerRunner == currentJobManagerRunner) &#123;</span><br><span class="line">                <span class="comment">// 作业达到终态</span></span><br><span class="line">                <span class="keyword">if</span> (archivedExecutionGraph != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    jobReachedGloballyTerminalState(archivedExecutionGraph);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="keyword">final</span> Throwable strippedThrowable = ExceptionUtils.stripCompletionException(throwable);</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// 作业处于not finished状态，被通知非正常终止异常</span></span><br><span class="line">                    <span class="keyword">if</span> (strippedThrowable <span class="keyword">instanceof</span> JobNotFinishedException) &#123;</span><br><span class="line">                        jobNotFinished(jobId);</span><br><span class="line">                        <span class="comment">// 作业对应的jobMaster失败的异常</span></span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        jobMasterFailed(jobId, strippedThrowable);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                log.debug(<span class="string">"There is a newer JobManagerRunner for the job &#123;&#125;."</span>, jobId);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;, getMainThreadExecutor()));</span><br><span class="line"></span><br><span class="line">    jobManagerRunner.start();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> jobManagerRunner;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在Dispatcher的重要逻辑中，除了提交作业，还有JobManager进程崩溃后在恢复时的恢复作业，恢复作业与HA中的首领选举有关，会在后面节详细展开。<br>在Dispatcher的代码里出现了getMainThreadExecutor方法和getRpcService().getExecutor()方法<br>这看起来有点让人迷惑，因为用getMainThreadExecutor这个方法处理不需要加锁来保证线程安全，而getRpcService().getExecutor()需要考虑线程安全。</p>
<p><br></p>
<h3 id="ResourceManager"><a href="#ResourceManager" class="headerlink" title="ResourceManager"></a>ResourceManager</h3><p>ResourceManager组件负责资源的分配与释放，以及资源状态的管理。ResourceManager组件的基础类为ResourceManager，ResourceManager类的组织架构如图所示。<br>Resource-Manager类的实现接口和继承类整体与Dispatcher类类似，唯一不同的是Resource-Manager类实现的是ResourceManagerGateway接口，实现的方法供Dispatcher、REST、JobMaster组件调用。<br>ResourceManager的子类有StandaloneResourceManager、MesosResource-Manager、YarnResourceManager，作为不同部署模式的实现，实现在各种部署模式下与资源管控的交互。</p>
<p><img src="/2022/12/05/flink/image-24.png" width="700px"></p>
<blockquote>
<p>ResourceManager与其他组件的通信主要有以下几种。</p>
</blockquote>
<ul>
<li>REST组件通过Dispatcher透传或者直接与ResourceManager通信来获取TaskExecutor的详细信息、集群的资源情况、TaskExecutor Metric查询服务的信息、TaskExecutor的日志和标志输出。具体体现在Flink UI上。</li>
<li>JobMaster与ResourceManager的交互主要体现在申请Slot、释放Slot、将JobMaster注册到ResourceManager，以及组件之间的心跳。</li>
<li>TaskExecutor与ResourceManager的交互主要是将TaskExecutor注册到Resource-Manager、汇报TaskExecutor上Slot的情况，以及组件之间心跳通信。</li>
</ul>
<p>对于资源Slot，在TaskExecutor上以Slot逻辑单元对TaskManager资源（资源CPU、内存等）进行划分，供作业的Task调度；<br>在JobMaster和ResourceManager上维护与Task-Executor的Slot的映射关系，JobManager通过SlotPool来管理运行作业的Slot，Resource-Manager通过SlotManager来管理TaskManager注册过来的Slot，供多个JobMaster的SlotPool来申请和分配。</p>
<p>接下来详细介绍ResourceManager、JobMaster与TaskExecutor之间的重要流程——申请资源Slot。<br>后面的JobMaster和TaskExecutor也会围绕申请资源Slot过程中的各个组件处理流程展开介绍。<br>整个申请资源Slot的流程如图所示。</p>
<p><img src="/2022/12/05/flink/image-25.png" width="400px"></p>
<ul>
<li>JobMaster会根据Task的调度按需向ResourceManager发出申请Slot的请求。</li>
<li>ResourceManager根据自身注册TaskManager的Slot空闲情况进行处理：TaskManager的空闲Slot资源足够时，就直接往对应的TaskManager发起申请占有Slot的请求；不够时则先会向各种部署模式（Standalone/Kubernetes/YARN）对应的资源管控中心申请TaskManager。</li>
<li>各种部署模式的资源管控中心根据ResourceManager申请TaskManager资源的规格，分配并启动TaskManager。</li>
<li>启动的TaskManager会注册到ResourceManager，注册成功后，TaskManager汇报自身的Slot情况（TaskManager汇报Slot过程）。</li>
<li>ResourceManager根据TaskManager汇报的Slot情况向TaskManager申请占有Slot（ResourceManager的申请占有Slot过程）。</li>
<li>TaskManager根据申请占有Slot信息中的作业信息注册对应的JobMaster，并将Slot提供给JobMaster调用分配Task（OfferSlot的过程）。</li>
</ul>
<p><br></p>
<h4 id="SlotManager"><a href="#SlotManager" class="headerlink" title="SlotManager"></a>SlotManager</h4><p>SlotManager作为ResourceManager的重要部分，维护和注册来自TaskManager的Slot，并处理来自JobMaster的Slot申请。<br>其中SlotManager服务的实现类为SlotManagerImpl。SlotManager处理来自所有JobManager的Slot申请，其处理过程分成两部分：申请资源Slot和处理TaskManager的注册Slot。<br>接下来以SlotManager处理来自JobMaster的Slot申请的过程和TaskManagerSlot的状态转换来展开介绍SlotManager。</p>
<blockquote>
<p>申请Slot与分配</p>
</blockquote>
<p>SlotManager在接收到JobMaster的Slot申请后，进行申请Slot过程，其过程主要有以下几部分：</p>
<ul>
<li>检测Slot申请是否有效；</li>
<li>匹配SlotManager空闲的Slot（TaskManagerSlot）和待完成资源申请的Slot请求（PendingTaskManager），即Slot与待完成资源申请的Slot请求匹配过程；</li>
<li>申请TaskManager资源或者分配空闲的Slot（TaskManagerSlot）（申请资源与分配过程）。</li>
</ul>
<blockquote>
<p>如代码清单&gt;所示，检测Slot申请是否有效，首先检查该Slot申请对应的JobMaster是否已注册，如果未注册则拒绝该Slot申请，反之执行后续的有效性检测。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Acknowledge&gt; <span class="title">requestSlot</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        JobMasterId jobMasterId,</span></span></span><br><span class="line"><span class="function"><span class="params">        SlotRequest slotRequest,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">final</span> Time timeout)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    JobID jobId = slotRequest.getJobId();</span><br><span class="line">    JobManagerRegistration jobManagerRegistration = jobManagerRegistrations.get(jobId);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> != jobManagerRegistration) &#123;</span><br><span class="line">        <span class="comment">// 判断该Slot申请对应的JobMaster是否已经注册到ResourceManager</span></span><br><span class="line">        <span class="keyword">if</span> (Objects.equals(jobMasterId, jobManagerRegistration.getJobMasterId())) &#123;</span><br><span class="line">            log.info(<span class="string">"Request slot with profile &#123;&#125; for job &#123;&#125; with allocation id &#123;&#125;."</span>,</span><br><span class="line">                    slotRequest.getResourceProfile(),</span><br><span class="line">                    slotRequest.getJobId(),</span><br><span class="line">                    slotRequest.getAllocationId());</span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                slotManager.registerSlotRequest(slotRequest);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (ResourceManagerException e) &#123;</span><br><span class="line">                <span class="keyword">return</span> FutureUtils.completedExceptionally(e);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> CompletableFuture.completedFuture(Acknowledge.get());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> FutureUtils.completedExceptionally(<span class="keyword">new</span> ResourceManagerException(</span><br><span class="line">                    <span class="string">"The job leader's id "</span></span><br><span class="line">                    + jobManagerRegistration.getJobMasterId()</span><br><span class="line">                    + <span class="string">"does not match the received id "</span> + jobMasterId + <span class="string">'.'</span>));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> FutureUtils.completedExceptionally(<span class="keyword">new</span> ResourceManagerException(</span><br><span class="line">                <span class="string">"Could not find registered job manager for job "</span> + jobId + <span class="string">'.'</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如下代码清单所示，检测Slot申请的有效性，还会检测SlotManager是否已经启动（通过检查started属性）以及申请的Slot是否重复提交过。<br>其中申请的Slot是否重复提交过的检测方式是：检查待分配或者已经完成和活跃的Slot申请Map中是否存在该Slot的AllocationID。<br>申请Slot的AllocationID是在JobMaster组件中就产生的，是唯一确定的。<br>在检测完Slot申请的有效性后，会通过internalRequestSlot方法执行Slot和待分配请求匹配的逻辑。</p>
<blockquote>
<p>SlotManager类的注册Slot申请请求方法</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">registerSlotRequest</span><span class="params">(SlotRequest slotRequest)</span> <span class="keyword">throws</span> ResourceManagerException </span>&#123;</span><br><span class="line">    <span class="comment">// 检查是否已经启动</span></span><br><span class="line">    checkInit();</span><br><span class="line">    <span class="comment">// 检查申请的Slot是否重复提交过</span></span><br><span class="line">    <span class="keyword">if</span> (checkDuplicateRequest(slotRequest.getAllocationId())) &#123;</span><br><span class="line">        LOG.debug(<span class="string">"Ignoring a duplicate slot request with allocation id &#123;&#125;."</span>,</span><br><span class="line">                slotRequest.getAllocationId());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        PendingSlotRequest pendingSlotRequest = <span class="keyword">new</span> PendingSlotRequest(slotRequest);</span><br><span class="line"></span><br><span class="line">        pendingSlotRequests.put(slotRequest.getAllocationId(), pendingSlotRequest);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            internalRequestSlot(pendingSlotRequest);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ResourceManagerException e) &#123;</span><br><span class="line">            pendingSlotRequests.remove(slotRequest.getAllocationId());</span><br><span class="line"></span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> ResourceManagerException(<span class="string">"Could not fulfill slot request"</span></span><br><span class="line">                    + slotRequest.getAllocationId() + <span class="string">'.'</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如下代码清单所示，内部申请Slot方法的处理流程为：先根据申请的Slot的资源规格匹配SlotManager的空闲Slot列表，匹配上空闲Slot，则完成该空闲Slot的分配过程，否则匹配待分配的申请请求和申请TaskManager。</p>
<blockquote>
<p>SlotManager类内部申请Slot的方法 </p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">internalRequestSlot</span><span class="params">(PendingSlotRequest pendingSlotRequest)</span> <span class="keyword">throws</span> ResourceManagerException </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> ResourceProfile resourceProfile = pendingSlotRequest.getResourceProfile();</span><br><span class="line"></span><br><span class="line">    OptionalConsumer.of(findMatchingSlot(resourceProfile))</span><br><span class="line">        .ifPresent(taskManagerSlot -&gt; allocateSlot(taskManagerSlot, pendingSlotRequest))</span><br><span class="line">        .ifNotPresent(() -&gt; fulfillPendingSlotRequestWithPendingTaskManagerSlot(pendingSlotRequest));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Slot匹配过程是根据Slot匹配策略（slotMatchingStrategy）从SlotManager注册的空闲TaskManagerSlot列表中挑选符合条件的TaskManagerSlot。<br>其Task-ManagerSlot记录Slot在TaskManager的地址，在TaskManager的SlotTable中的下标，Slot在TaskManager上的占用情况以及在ResourceManager的状态。</p>
<p>slotMatchingStrategy对应类的实现有两种，分别是Any-MatchingSlotMatchingStrategy和LeastUtilizationSlotMatchingStrategy。</p>
<ul>
<li>AnyMatchingSlot-MatchingStrategy的挑选策略是从空闲的TaskManagerSlot中任意挑选一个，这是默认的挑选策略；</li>
<li>LeastUtilizationSlotMatchingStrategy是在空闲的TaskManagerSlot中挑选空闲Slot数量最多的TaskManager的TaskManagerSlot，该策略需要将参数cluster.evenly-spread-out-slots的值设置为true才会生效。</li>
</ul>
<p><br><br><br></p>
<h2 id="组件间通信"><a href="#组件间通信" class="headerlink" title="组件间通信"></a>组件间通信</h2><p>前面已经介绍了Flink的运行时基本组件REST、Dispatcher、JobMaster、Resource-Manager和TaskExecutor，接下来看看这些运行时组件间通信的设计与实现。<br>组件间的远程通信、组件内的本地通信以及组件内的状态在并发情况下的维护，都是基于Akka Actor来实现的。<br>在开始介绍组件间通信的设计和实现之前，先来看看组件实现的基础——消息传递模式（Akka）。</p>
<h3 id="Akka与Actor模型"><a href="#Akka与Actor模型" class="headerlink" title="Akka与Actor模型"></a>Akka与Actor模型</h3><p>Akka是构建高并发、分布式、可扩展应用的框架。Akka让开发者只需要关注业务逻辑，不需要写底层代码来支持可靠性、容错和高性能。Akka带来了诸多好处，比如</p>
<ul>
<li>提供新的多线程模型，不需要使用低级的锁和原子性的操作来解决内存可见性问题；</li>
<li>提供透明的远程通信，不再需要编写和维护复杂的网络代码；</li>
<li>提供集群式、高可用的架构，方便构建真正的响应式模式（Reactive）的应用。</li>
</ul>
<p>Akka是基于Actor模型实现的，Actor模型类似于Erlang的并行模型，能使实现并发、并行和分布式应用更加简单。<br>Actor是Actor模型中最重要的构成部分，作为最基本的计算单位，能接收消息并基于其执行计算。每个Actor都有自己的邮箱，用来存储接收到的消息。</p>
<p>每个Actor维持私有的状态，来实现Actor之间的隔离。<br>下图是各个Actor之间的通信示例情况。从图中可知，每个Actor都是由单个线程负责从各自的邮箱拉取消息，并连续处理接收到的消息。<br>对于接收到的消息，Actor可以更改其内部的状态，或者将其传给其他Actor，或者创建新的Actor。</p>
<p><img src="/2022/12/05/flink/image-26.png" width="400px"></p>
<blockquote>
<p>下面通过一个实例来更好地了解Actor的创建、启动以及消息的发送。</p>
</blockquote>
<h4 id="RemoteServerActor的实现"><a href="#RemoteServerActor的实现" class="headerlink" title="RemoteServerActor的实现"></a>RemoteServerActor的实现</h4><blockquote>
<p>实现AbstractActor的createReceive方法，来实现接收到消息的处理逻辑：接收到String的消息，将消息内容打印到控制台。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RemoteServerActor</span> <span class="keyword">extends</span> <span class="title">AbstractActor</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Receive <span class="title">createReceive</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> receiveBuilder()</span><br><span class="line">            .match(String.class, message-&gt; &#123;</span><br><span class="line">                System.out.println(message);</span><br><span class="line">            &#125;)</span><br><span class="line">            .build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="RemoteServerActorLauncher"><a href="#RemoteServerActorLauncher" class="headerlink" title="RemoteServerActorLauncher"></a>RemoteServerActorLauncher</h4><blockquote>
<p>启动Actor和发送消息</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RemoteServerActorLauncher</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Config config = ConfigFactory.load(<span class="string">"remote.conf"</span>);</span><br><span class="line"></span><br><span class="line">        ActorSystem actorSystem = ActorSystem.create(<span class="string">"remote"</span>, config);</span><br><span class="line">        ActorRef actor = actorSystem.actorOf(Props.create(RemoteServerActor.class), <span class="string">"remoteServerActor"</span>);</span><br><span class="line">            actor.tell(<span class="string">"hello!"</span>, ActorRef.noSender());</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>附带的配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">akka &#123;</span><br><span class="line">    actor &#123;</span><br><span class="line">        provider = &quot;akka.remote.RemoteActorRefProvider&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    remote &#123;</span><br><span class="line">        enabled-transports = [&quot;akka.remote.netty.tcp&quot;]</span><br><span class="line">        netty.tcp &#123;</span><br><span class="line">            hostname = &quot;127.0.0.1&quot;</span><br><span class="line">            port = 50010</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="LocalClient"><a href="#LocalClient" class="headerlink" title="LocalClient"></a>LocalClient</h4><blockquote>
<p>进行远程访问的LocalClient</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LocalClient</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Config config = ConfigFactory.load(<span class="string">"client.conf"</span>);</span><br><span class="line">        ActorSystem actorSystem = ActorSystem.create(<span class="string">"local"</span>, config);</span><br><span class="line"></span><br><span class="line">        ActorSelection toFind = actorSystem.actorSelection(</span><br><span class="line">            <span class="string">"akka.tcp://remote@127.0.0.1:50010/user/remoteServerActor"</span>);</span><br><span class="line">        toFind.tell(<span class="string">"I am from local."</span>, ActorRef.noSender());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在上面的示例中，发送消息使用了tell模式。<br>Actor的发送消息模式有ask、tell和forward，三者的特点如下。</p>
<ul>
<li>ask模式：发送消息异步，并返回一个Future来代表可能的消息回应。</li>
<li>tell模式：一种fire-and-forget（发后即忘）的方式，发送消息异步并立即返回，无返回信息。</li>
<li>forward模式：类似邮件的转发，将收到的消息由一个Actor转发到另一个Actor。</li>
</ul>
<p>至此与组件通信相关的Actor知识就介绍得差不多了，想要更深入地了解Akka Actor通信知识的读者可以查阅Akka官方网站（<a href="https://akka.io/）。" target="_blank" rel="noopener">https://akka.io/）。</a></p>
<h4 id="总结流程"><a href="#总结流程" class="headerlink" title="总结流程"></a>总结流程</h4><ul>
<li>创建远程的ActorSystem。</li>
<li>创建并启动RemoteServerActorLauncher实例，返回ActorRef，创建消息并通过ActorRef发送消息。</li>
<li>ActorRef将消息委托给Dispatcher发送到Actor。</li>
<li>Dispatcher把消息暂存在邮箱中，Dispatcher中封装了一个线程池，用于消息派发，实现异步消息发送的效果。</li>
<li>从邮箱中取出消息，委派给RemoteServerActorLauncher中通过createReceive方法创建的Receive实例来处理。</li>
</ul>
<p><img src="/2022/12/05/flink/image-27.png" width="500px"></p>
<p><br></p>
<h3 id="组件间通信实现"><a href="#组件间通信实现" class="headerlink" title="组件间通信实现"></a>组件间通信实现</h3><p>之前介绍了运行时的组件，对于这些组件内的多线程访问，没有锁和算子操作来保证状态，而主要通过runAsync方法、callAsync方法，以及通过getMainThreadExecutor调度来执行Future的回调方法，来实现对组件状态的安全操作。<br>组件间通过RpcGateway子类的方法实现远程的方法调用。<br>组件内部的安全状态操作是基于本地Actor实现的，而组件间的通信是通过远程Actor实现的。<br>至于组件内的本地通信与组件间通信的设计与实现，下面就来揭开其神秘的面纱。</p>
<p><img src="/2022/12/05/flink/image-28.png" width="1200px"></p>
<ul>
<li>RpcEndpoint：远程过程调用端点（rpc）基础类，提供远程过程调用的分布式组件需要继承这个基础类。前面提到的运行时组件Dispatcher、TaskExecutor、Resource-Manager和JobMaster组件都继承了RpcEndpoint。</li>
<li>AkkaRpcActor：接收RpcInvocation、RunAsync、CallAsync和ControlMessages的消息来实现运行时组件中状态的安全操作。</li>
<li>AkkaInvocationHandler：作为RpcAkka调用的Handler，AkkaRpcActor接收到的RunAsync、CallAsync和RpcInvocation消息都由AkkaInvocationHandler发送。</li>
<li>AkkaRpcService：实现RpcService接口，负责启动AkkaRpcActor和连接到RpcEndpoint。连接到一个RpcEndpoint，会返回RpcGateway，供远程过程调用。</li>
</ul>
<h4 id="AkkaRpcActor"><a href="#AkkaRpcActor" class="headerlink" title="AkkaRpcActor"></a>AkkaRpcActor</h4><p>首先来看处理消息的AkkaRpcActor。除REST以外，其他运行时组件（Dispatcher、TaskExecutor、ResourceManager和JobMaster）都有一个AkkaRpcActor对象。AkkaRpc-Actor负责接收消息，并对消息进行处理，以操作RpcEndpoint（Dispatcher、TaskExecutor、<br>ResourceManager和JobMaster是RpcEnpoint类中的子类）的状态，实现对RpcEndpoint实现类对象的生命周期控制和状态操作。<br>AkkaRpcActor处理的消息分为远程握手消息（RemoteHandshakeMessage）、控制消息和普通消息。远程握手消息主要用于在RpcEndpoint之间的远程通信建立连接之前，检查RpcEndpoint之间版本是否兼容。</p>
<p>控制消息分START消息、STOP消息和TERMINATE消息。AkkaRpcActor接收到不同控制消息的场景与处理逻辑各不相同，具体如下。</p>
<ul>
<li>当AkkaRpcActor接收到START消息时，只有AkkaRpcActor的状态设置为开始状态，才可以处理流入的普通消息。在AkkaRpcActor对应的RpcEndpoint启动时，会发送START消息给AkkaRpcActor。</li>
<li>当AkkaRpcActor接收到STOP消息时，AkkaRpcActor处于不再处理流入的普通消息且将接收到的普通消息丢弃的状态。此时只会发生JobMaster失去首领角色的情况。在这种情况下，JobMaster会将作业设置为暂停状态（Suspended），同时向与其对应的AkkaRpcActor发送STOP消息。</li>
<li>当AkkaRpcActor接收到TERMINATE消息时，会调用对应RpcEndpoint的退出（onStop方法）逻辑。只有在Master或Worker进程正常退出或者进程中的组件发生致命错误（Fatal Error）而退出时，才会接收到TERMINATE消息。</li>
</ul>
<p>普通消息有RunAsync、CallAsync和RpcInvocation消息三种类型。普通消息在组件内部与组件间的使用场景各不相同，具体如下。</p>
<ul>
<li>RunAsync消息包含所需执行的Runnable和待执行的时间点，不需要返回执行结果。组件中的runAsync和scheduleRunAsync方法最终会将RunAsync消息发送给AkkaRpcActor，从而线程安全地执行Runnable的run方法，修改RpcEndpoint实现类对象的状态。</li>
<li>CallAsync消息包含所需执行的Callable，需要返回执行结果。调用callAsync方法会触发客户端以ask模式将CallAsync消息发送给AkkaRpcActor。</li>
<li>RpcInvocation消息分LocalRpcInvocation消息和RemoteRpcInvocation消息，二者的区别是：LocalRpcInvocation用于本地Actor之间的RPC，不需要消息的序列化和反序列化，用于Master上运行时组件间的通信（如ResourceManager与JobMaster的通信）；RemoteRpcInvocation用于Actor远程通信中的RPC，需要序列化与反序列化，用于Master组件与Worker组件的远程通信（如JobMaster与TaskExecutor的通信）。</li>
</ul>
<h4 id="AkkaRpcService"><a href="#AkkaRpcService" class="headerlink" title="AkkaRpcService"></a>AkkaRpcService</h4><p>接下来看下AkkaRpcActor的创建与启动过程。<br>AkkaRpcService负责创建和启动AkkaRpcActor，而这个过程是在AkkaRpcService的startServer方法中进行的。<br>如代码清单所示，AkkaRpcService中startServer方法的处理逻辑分成两部分</p>
<ul>
<li>创建与启动AkkaRpcActor，用来接收和处理消息</li>
<li>构建RpcServer代理对象，使用发送消息给AkkaRpcActor的方式实现状态的线程安全操作。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> &lt;C extends RpcEndpoint &lt; RpcGateway&gt; <span class="function">RpcServer <span class="title">startServer</span><span class="params">(C rpcEndpoint)</span> </span>&#123;</span><br><span class="line">        checkNotNull(rpcEndpoint, <span class="string">"rpc endpoint"</span>);</span><br><span class="line"></span><br><span class="line">    CompletableFuture&lt;Void&gt; terminationFuture = <span class="keyword">new</span> CompletableFuture&lt;&gt;();</span><br><span class="line">    <span class="keyword">final</span> Props akkaRpcActorProps;</span><br><span class="line">    <span class="comment">// 根据是否需要带FencingToken访问的RpcEndpoint实现类对象，创建不同类型的AkkaRpcActor// 的属性</span></span><br><span class="line">    <span class="keyword">if</span> (rpcEndpoint <span class="keyword">instanceof</span> FencedRpcEndpoint) &#123;</span><br><span class="line">        akkaRpcActorProps = Props.create(</span><br><span class="line">            FencedAkkaRpcActor.class,</span><br><span class="line">            rpcEndpoint,</span><br><span class="line">            terminationFuture,</span><br><span class="line">            getVersion(),</span><br><span class="line">            configuration.getMaximumFramesize());</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        akkaRpcActorProps = Props.create(</span><br><span class="line">            AkkaRpcActor.class,</span><br><span class="line">            rpcEndpoint,</span><br><span class="line">            terminationFuture,</span><br><span class="line">            getVersion(),</span><br><span class="line">            configuration.getMaximumFramesize());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ActorRef actorRef;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line">        checkState(!stopped, <span class="string">"RpcService is stopped"</span>);</span><br><span class="line">        <span class="comment">// 启动AkkaRpcActor</span></span><br><span class="line">        actorRef = actorSystem.actorOf(akkaRpcActorProps, rpcEndpoint.getEndpointId());</span><br><span class="line">        actors.put(actorRef, rpcEndpoint);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    LOG.info(<span class="string">"Starting RPC endpoint for &#123;&#125; at &#123;&#125; ."</span>, rpcEndpoint.getClass().getName(), actorRef.path());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> String akkaAddress = AkkaUtils.getAkkaURL(actorSystem, actorRef);</span><br><span class="line">    <span class="keyword">final</span> String hostname;</span><br><span class="line">    Option&lt;String&gt; host = actorRef.path().address().host();</span><br><span class="line">    <span class="keyword">if</span> (host.isEmpty()) &#123;</span><br><span class="line">        hostname = <span class="string">"localhost"</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        hostname = host.get();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Set&lt;Class&lt;?&gt;&gt; implementedRpcGateways = <span class="keyword">new</span> HashSet&lt;&gt;(</span><br><span class="line">            RpcUtils.extractImplementedRpcGateways(rpcEndpoint.getClass()));</span><br><span class="line"></span><br><span class="line">    implementedRpcGateways.add(RpcServer.class);</span><br><span class="line">    implementedRpcGateways.add(AkkaBasedEndpoint.class);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> InvocationHandler akkaInvocationHandler;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 根据是否需要带FencingToken访问的RpcEndpoint实现类对象，</span></span><br><span class="line">    <span class="comment">// 创建不同类型的AkkaInvocationHandler来与AkkaActor交互，实现方法的线程安全调用</span></span><br><span class="line">    <span class="keyword">if</span> (rpcEndpoint <span class="keyword">instanceof</span> FencedRpcEndpoint) &#123;</span><br><span class="line">        akkaInvocationHandler = <span class="keyword">new</span> FencedAkkaInvocationHandler&lt;&gt;(</span><br><span class="line">                akkaAddress,</span><br><span class="line">                hostname,</span><br><span class="line">                actorRef,</span><br><span class="line">                configuration.getTimeout(),</span><br><span class="line">                configuration.getMaximumFramesize(),</span><br><span class="line">                terminationFuture,</span><br><span class="line">                ((FencedRpcEndpoint&lt;?&gt;) rpcEndpoint)::getFencingToken);</span><br><span class="line"></span><br><span class="line">        implementedRpcGateways.add(FencedMainThreadExecutable.class);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        akkaInvocationHandler = <span class="keyword">new</span> AkkaInvocationHandler(</span><br><span class="line">                akkaAddress,</span><br><span class="line">                hostname,</span><br><span class="line">                actorRef,</span><br><span class="line">                configuration.getTimeout(),</span><br><span class="line">                configuration.getMaximumFramesize(),</span><br><span class="line">                terminationFuture);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ClassLoader classLoader = getClass().getClassLoader();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 根据RpcEndpoint实现类对象的实现接口中所有继承RpcGateway的接口、</span></span><br><span class="line">    <span class="comment">// RpcServer接口、AkkaBasedEndpoint接口构建RpcServer代理对象</span></span><br><span class="line">    <span class="comment">// 对于FencedRpcEndpoint实现类对象，代理对象会多实现FencedMainThreadExecutable接口</span></span><br><span class="line">    <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line">    RpcServer server = (RpcServer) Proxy.newProxyInstance(</span><br><span class="line">            classLoader,</span><br><span class="line">            implementedRpcGateways.toArray(<span class="keyword">new</span> Class&lt;?&gt;[implementedRpcGateways.size()]),</span><br><span class="line">            akkaInvocationHandler);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> server;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在AkkaRpcService调用startServer方法、RpcEndpoint实现类对象获取到RpcServer代理对象、RpcServer代理对象调用start方法后，AkkaRpcActor即可处理普通消息。<br>至此FencedRpcEndpoint/RpcEndpoint中runAsync、callAsync和scheduleRunAsync方法的处理流程已十分清晰，如图所示，具体处理流程如下。</p>
<p><img src="/2022/12/05/flink/image-29.png" width="600px"></p>
<blockquote>
<p>组件内runAsync、callAsync、scheduleRunAsync的处理流程</p>
</blockquote>
<ul>
<li>FencedRpcEndpoint/RpcEndpoint实现类对象中调用runAsync、callAsync和schedule-RunAsync方法是通过RpcServer代理对象完成的。</li>
<li>RpcServer代理对象调用runAsync、callAsync和scheduleRunAsync方法时会调用AkkaRpcInvocation的invoke方法，invoke方法会将这三种方法转换为RunAsync消息和CallAsync消息发送给AkkaRpcActor。</li>
<li>AkkaRpcActor接收到RunAsync消息和CallAsync消息，进行FencedRpcEndpoint/RpcEndpoint实现类对象的线程安全的状态修改，或者将执行结果原路返回。</li>
</ul>
<h4 id="AkkaInvocationHandler"><a href="#AkkaInvocationHandler" class="headerlink" title="AkkaInvocationHandler"></a>AkkaInvocationHandler</h4><p>下面介绍RpcServer代理对象的InvocationHandler类AkkaInvocationHandler在组件内部与组件之间通信的作用。<br>作为RpcServer代理对象和创建远程连接的RpcGateway代理对象（后面会提到）的InvocationHandler，AkkaInvocationHandler能与本地AkkaRpcActor、远程AkkaRpcActor的消息交互。<br>之所以能够这样主要是因为AkkaInvocationHandler拥有ActorRef类型的对象rpcEndpoint（该rpcEndpoint与RpcEndpoint类无关），并且能够通过该对象直接与对应的Actor通信。</p>
<p>AkkaInvocationHandler类的所有逻辑的入口是实现InvocationHandler的invoke方法。如代码清单所示，当RpcServer代理对象或RpcGateway代理对象执行某个方法时，AkkaInvocationHandler的invoke方法会被调用。<br>而AkkaInvocationHandler的invoke方法的处理逻辑是，先获取调用方法的定义类，然后根据不同调用方法的定义类进行不同的处理。</p>
<p>对于不同调用方法的定义类，处理情况如下。</p>
<ul>
<li>调用方法的定义类属于AkkaBasedEndpoint、Object、RpcGateway、StartStoppable、MainThreadExecutable和RpcServer，这是通过反射调用AkkaInvocationHandler的方法，这个场景用于RpcServer调用相应方法时（如调用runAsync、callAsync等方法）。</li>
<li>调用方法对应的定义类为FencedRpcGateway时，不支持，直接抛出异常，Fenced-RpcGateway接口定义的方法只有getFencingToken。</li>
<li>调用方法的定义类为其他时，调用invokeRpc来处理逻辑，这个场景用于继承RpcGateway接口的代理对象调用相应方法时。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(Object proxy, Method method, Object[] args)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">    Class&lt;?&gt; declaringClass = method.getDeclaringClass();</span><br><span class="line"></span><br><span class="line">    Object result;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (declaringClass.equals(AkkaBasedEndpoint.class)</span><br><span class="line">        ||declaringClass.equals(Object.class)</span><br><span class="line">        ||declaringClass.equals(RpcGateway.class)</span><br><span class="line">        ||declaringClass.equals(StartStoppable.class)</span><br><span class="line">        ||declaringClass.equals(MainThreadExecutable.class)</span><br><span class="line">        ||declaringClass.equals(RpcServer.class)) &#123;</span><br><span class="line">        result = method.invoke(<span class="keyword">this</span>, args);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (declaringClass.equals(FencedRpcGateway.class)) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(</span><br><span class="line">            <span class="string">"AkkaInvocationHandler does not support the call FencedRpcGateway#"</span></span><br><span class="line">            + method.getName()</span><br><span class="line">            + <span class="string">". This indicates that you retrieved a FencedRpcGateway without"</span></span><br><span class="line">            + <span class="string">"specifying a fencing token. Please use RpcService#connect("</span> + <span class="string">"RpcService, F, Time) with F being the fencing token to "</span></span><br><span class="line">            + <span class="string">"retrieve a properly FencedRpcGateway."</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        result = invokeRpc(method, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>RpcServer代理对象的方法调用是通过AkkaHandler的invoke调用来实现的（invoke调用的实现即通过反射调用其相应的方法，用于本地调用）。<br>RpcServer代理对象的调用方法有runAsync、scheduleRunAsync、callAsync、start和stop，这些方法的主要逻辑是通过ActorRef的rpcEndpoint属性往本地AkkaRpcActor发送RunAsync消息、CallAsync和控制消息。</p>
<blockquote>
<p>AkkaInvocationHandler类往本地Actor发送消息的方法</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">runAsync</span><span class="params">(Runnable runnable)</span> </span>&#123;</span><br><span class="line">    scheduleRunAsync(runnable, <span class="number">0L</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">scheduleRunAsync</span><span class="params">(Runnable runnable, <span class="keyword">long</span> delayMillis)</span> </span>&#123;</span><br><span class="line">    checkNotNull(runnable, <span class="string">"runnable"</span>);</span><br><span class="line">    checkArgument(delayMillis &gt;= <span class="number">0</span>, <span class="string">"delay must be zero or greater"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (isLocal) &#123;</span><br><span class="line">        <span class="keyword">long</span> atTimeNanos = delayMillis == <span class="number">0</span> ? <span class="number">0</span> : System.nanoTime() + (delayMillis * <span class="number">1_000_000</span>);</span><br><span class="line">        tell(<span class="keyword">new</span> RunAsync(runnable, atTimeNanos));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"Trying to send a Runnable to a remote actor at "</span></span><br><span class="line">                + rpcEndpoint.path() + <span class="string">". This is not supported."</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> &lt;V&gt; <span class="function">CompletableFuture&lt;V&gt; <span class="title">callAsync</span><span class="params">(Callable&lt;V&gt; callable, Time callTimeout)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (isLocal) &#123;</span><br><span class="line">    <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line">        CompletableFuture&lt;V&gt; resultFuture =</span><br><span class="line">                (CompletableFuture&lt;V&gt;) ask(<span class="keyword">new</span> CallAsync(callable), callTimeout);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> resultFuture;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"Trying to send a Callable to a remote actor at "</span></span><br><span class="line">                + rpcEndpoint.path() + <span class="string">". This is not supported."</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    rpcEndpoint.tell(ControlMessages.START, ActorRef.noSender());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">stop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    rpcEndpoint.tell(ControlMessages.STOP, ActorRef.noSender());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>AkkaInvocationHandler对于需要发送RpcInvocation的逻辑</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Object <span class="title">invokeRpc</span><span class="params">(Method method, Object[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    String methodName = method.getName();</span><br><span class="line">    Class&lt;?&gt;[] parameterTypes = method.getParameterTypes();</span><br><span class="line">    Annotation[][] parameterAnnotations = method.getParameterAnnotations();</span><br><span class="line">    Time futureTimeout = extractRpcTimeout(parameterAnnotations, args, timeout);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 根据需调用的方法名、参数类型和参数值创建RpcInvocation</span></span><br><span class="line">    <span class="keyword">final</span> RpcInvocation rpcInvocation = createRpcInvocationMessage(methodName, parameterTypes, args);</span><br><span class="line"></span><br><span class="line">    Class&lt;?&gt; returnType = method.getReturnType();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> Object result;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (Objects.equals(returnType, Void.TYPE)) &#123;</span><br><span class="line">        <span class="comment">// 对于不需要返回结果的调用，通过tell模式往相应的AkkaRpcActor发送RpcInvocation// 消息</span></span><br><span class="line">        tell(rpcInvocation);</span><br><span class="line"></span><br><span class="line">        result = <span class="keyword">null</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 对于需要返回结果的调用，通过ask模式往相应的AkkaRpcActor发送RpcInvocation消息</span></span><br><span class="line">        CompletableFuture&lt;?&gt; resultFuture = ask(rpcInvocation, futureTimeout);</span><br><span class="line"></span><br><span class="line">        CompletableFuture&lt;?&gt; completableFuture = resultFuture.thenApply((Object o) -&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span> (o <span class="keyword">instanceof</span> SerializedValue) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="keyword">return</span> ((SerializedValue&lt;?&gt;) o).deserializeValue(getClass().getClassLoader());</span><br><span class="line">                &#125; <span class="keyword">catch</span> (IOException | ClassNotFoundException e) &#123;</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> CompletionException(</span><br><span class="line">                        <span class="keyword">new</span> RpcException(<span class="string">"Could not deserialize the "</span> + <span class="string">"serialized payload of RPC method : "</span></span><br><span class="line">                            + methodName, e));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> o;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 根据调用方法的不同返回类型处理返回的消息</span></span><br><span class="line">        <span class="keyword">if</span> (Objects.equals(returnType, CompletableFuture.class)) &#123;</span><br><span class="line">            result = completableFuture;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                result = completableFuture.get(futureTimeout.getSize(), futureTimeout.getUnit());</span><br><span class="line">            &#125; <span class="keyword">catch</span> (ExecutionException ee) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> RpcException(<span class="string">"Failure while obtaining synchronous"</span> + <span class="string">"RPC result."</span>,</span><br><span class="line">                    ExceptionUtils.stripExecutionException(ee));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>AkkaRpcService类中的connect方法</p>
</blockquote>
<p>如代码清单所示，AkkaRpcService类中的内部connect方法的流程如下。</p>
<ul>
<li>通过actorSelection的方式往Akka地址对应的Actor发送Identify消息。对应的Actor会返回ActorIdentity消息。</li>
<li>从ActorIdentity消息中提取ActorRef，再往ActorRef发送RemoteHandshakeMessage的消息，与对应Actor的组件握手建立联系。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> &lt;C extends RpcGateway&gt; <span class="function">CompletableFuture&lt;C&gt; <span class="title">connect</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> String address,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> Class&lt;C&gt; clazz)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> connectInternal(</span><br><span class="line">            address,</span><br><span class="line">            clazz,</span><br><span class="line">            (ActorRef actorRef) -&gt; &#123;</span><br><span class="line">        Tuple2&lt;String, String&gt; addressHostname = extractAddressHostname(actorRef);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> AkkaInvocationHandler(</span><br><span class="line">                addressHostname.f0,</span><br><span class="line">                addressHostname.f1,</span><br><span class="line">                actorRef,</span><br><span class="line">                configuration.getTimeout(),</span><br><span class="line">                configuration.getMaximumFramesize(),</span><br><span class="line">                <span class="keyword">null</span>);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h1 id="状态管理与容错"><a href="#状态管理与容错" class="headerlink" title="状态管理与容错"></a>状态管理与容错</h1><p>提到实时计算引擎，人们自然而然地会将之与离线计算引擎分开讨论。对于离线计算引擎来说，由于需要计算的数据集是固定和有界的，当一个任务在提交执行过程中遇到不可预知的错误时，任务就会中断或失败。这个时候我们只需要找到问题的根源并进行修复，之后重新提交任务并运行即可。<br>在任务运行过程中无须太过关注中间状态的处理，只要任务逻辑与数据集是固定的，那么结果必然是相同的。</p>
<p>回到实时计算上来，与离线计算不同，实时计算的数据是无界的，任务触发执行后会永久运行下去，在执行过程中一旦有不可预知的错误（比如数据源出现脏数据）使得任务中断或失败，如果没有容错机制，那么实时计算会变得极不可靠。<br>Flink在容错方面的设计非常巧妙，通过引入状态的概念对数据处理时的快照进行管理，同时使用检查点机制定时将任务状态进行上报与存储，能够保证对数据的Exactly-once语义。</p>
<h2 id="状态"><a href="#状态" class="headerlink" title="状态"></a>状态</h2><p>状态在Flink中是特别重要的概念，如果对状态有很好的理解，我们就能更好地掌握Flink的特性。<br>接下来我们就对Flink的两大状态进行详细讲述。</p>
<h3 id="状态的原理与实现"><a href="#状态的原理与实现" class="headerlink" title="状态的原理与实现"></a>状态的原理与实现</h3><p>在Flink中，状态分为Keyed State和Operator State两种。<br>这两种状态又各自可以分为Raw State（原始状态）和Managed State（可管理状态）两种形式。<br>Managed State是官方推荐使用的状态形式，所有与DataStream相关的函数都可以使用它，我们在用Flink解决实际问题的时候，用得更多的也是Managed State。<br>接下来主要说明一下Managed Keyed State和Managed Operator State的实现原理。</p>
<h4 id="Managed-Keyed-State介绍"><a href="#Managed-Keyed-State介绍" class="headerlink" title="Managed Keyed State介绍"></a>Managed Keyed State介绍</h4><p>顾名思义，Managed Keyed State只可以使用在KeyedStream上，具体可以分为ValueState、ListState、ReducingState、AggregatingState、FoldingState和MapState（在未来版本中FoldingState会被AggregatingState替代）。<br>如果想要使用这些状态，那么首先需要在代码中声明StateDescriptor，代码如下。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">StateDescriptor</span>&lt;<span class="title">S</span> <span class="keyword">extends</span> <span class="title">State</span>, <span class="title">T</span>&gt; <span class="keyword">implements</span> <span class="title">Serializable</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">enum</span> <span class="title">Type</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Deprecated</span></span><br><span class="line">    UNKNOWN,</span><br><span class="line">    VALUE,</span><br><span class="line">    LIST,</span><br><span class="line">    REDUCING,</span><br><span class="line">    FOLDING,</span><br><span class="line">    AGGREGATING,</span><br><span class="line">    MAP</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>StateDescriptor构造函数会声明状态的名称和数据类型，也会在类中给出各种方法供用户使用。<br>所有Managed Keyed StateDescriptor的父类均为StateDescriptor。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="title">StateDescriptor</span><span class="params">(String name, TypeSerializer&lt;T&gt; serializer, @Nullable T defaultValue)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="title">StateDescriptor</span><span class="params">(String name, TypeInformation&lt;T&gt; typeInfo, @Nullable T defaultValue)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="title">StateDescriptor</span><span class="params">(String name, Class&lt;T&gt; type, @Nullable T defaultValue)</span></span></span><br></pre></td></tr></table></figure>
<p>StateDescriptor提供了三个构造函数，从代码可以看出，这三个构造函数的不同之处在于第二个参数的设置。</p>
<ul>
<li>第一个参数用来声明状态的名称，这个名称可以自定义。状态名称最好与状态的意义相关，且状态名称不可以重复。</li>
<li>第三个参数是默认值，如果状态没有被赋值，那么查询状态得到的返回值就是这个默认值。</li>
<li>第二个参数可以定义为TypeSerializer、TypeInformation和Class，分别对应状态数据类型的三种表达形式。</li>
</ul>
<p>了解了StateDescriptor的构造后，我们下一步需要知道StateDescriptor在什么地方进行初始化操作。<br>在本节的开头我们说过，所有与DataStream相关的函数都可以使用Managed State。状态记录了每个函数中的状态，所以Managed Keyed State的声明是在函数中初始化的，具体来说是在函数类的open方法中完成的。</p>
<p>状态初始化完成，就表明状态可用，Flink通过RuntimeContext操作状态。<br>根据定义Managed Keyed State类型的不同，RuntimeContext提供了不同的getState方法，如ValueState。<br>getState方法的内容如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> &lt;T&gt; <span class="function">ValueState&lt;T&gt; <span class="title">getState</span><span class="params">(ValueStateDescriptor&lt;T&gt; stateProperties)</span> </span>&#123;</span><br><span class="line">    KeyedStateStore keyedStateStore = checkPreconditionsAndGetKeyedStateStore(stateProperties);</span><br><span class="line">    stateProperties.initializeSerializerUnlessSet(getExecutionConfig());</span><br><span class="line">    <span class="keyword">return</span> keyedStateStore.getState(stateProperties);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>getState方法主要做以下三件事情。</p>
<ul>
<li>获取KeyedStateStore。KeyedStateStore是在StreamOperator中根据keyedStateBackend初始化得到的。KeyedStateStore是Keyed State存储的对象，每一次状态的变更都会同步到KeyedStateStore中去。</li>
<li>状态序列化方法初始化。提供一个序列化方法来指定声明状态序列化的方式，一个状态只会初始化一次，这是为了避免同一个状态被多种方式序列化。</li>
<li>从KeyedStateStore中得到状态的初始值。如果任务是第一次启动，那么会得到状态的默认值；如果任务是从检查点启动的，那么会获得从stateBackend中恢复的状态值。</li>
</ul>
<h4 id="Managed-Operator-State介绍"><a href="#Managed-Operator-State介绍" class="headerlink" title="Managed Operator State介绍"></a>Managed Operator State介绍</h4><p><br></p>
<h2 id="检查点"><a href="#检查点" class="headerlink" title="检查点"></a>检查点</h2><p>检查点（checkpoint）是Flink中一个很重要的名词。正是因为有了检查点机制，Flink在运行流式任务的时候才能保证系统内部的数据一致性</p>
<h3 id="检查点机制原理"><a href="#检查点机制原理" class="headerlink" title="检查点机制原理"></a>检查点机制原理</h3><p>前面着重讲解了Flink的状态知识，从中可知Flink的函数和算子都是带状态的，这些状态根据流进的数据而不断被更新。<br>基于容错的考虑，我们需要不断收集和保存状态的快照，一旦任务失败，就可以直接从保存的状态中快速恢复到失败前的执行状态。<br>这就是检查点机制的大致原理。</p>
<p>具体展开介绍检查点之前，我们需要先了解一些知识。检查点机制的实现需要持久存储的支持，主要分下面两种</p>
<ul>
<li>需要可根据时间进行回放的数据源存储，例如Kafka、RabbitMQ、Kinesis等；</li>
<li>需要持久存储来存放任务的状态，例如HDFS、S3、GFS等。</li>
</ul>
<p>检查点机制会定时收集任务的状态并上传到持久存储中，当任务失败进行恢复时，需要从数据源中进行数据回放，并重新进行消费计算。</p>
<h3 id="检查点执行过程"><a href="#检查点执行过程" class="headerlink" title="检查点执行过程"></a>检查点执行过程</h3><p>如果任务需要检查点机制的保障，则需要在代码中进行显式设置，因为默认是不开启检查点的。一旦开启了检查点，任务就会定时进行快照操作。下面我们就来仔细讲述检查点的完整执行过程。</p>
<ul>
<li>在任务的初始化过程中，JobMaster会通过SchedulerNG完成各种调度操作。<br>  SchedulerNG有个方法叫作startScheduling，在此方法中会调用ExecutionGraph的schedule-ForExecution方法进行作业的运行规划。</li>
<li>在scheduleForExecution方法中会首先判断作业的状态是否从created转换到running。<br>  状态的转换是通过transitionState方法完成的，在转换的过程中会通知所有JobStatusListener状态变更信息。负责检查点的JobStatusListener名为CheckpointCoordinator-DeActivator，一旦此监听器监听到任务状态变为running，就会立即调用Checkpoint-Coordinator触发startCheckpointScheduler方法进行检查点的调度操作。</li>
<li>在startCheckpointScheduler方法中将会触发一个定时任务ScheduledTrigger，这个定时任务负责根据用户配置的时间间隔进行运行状态处理。</li>
<li>ScheduledTrigger首先会拿到作业的所有Execution（单个ExecutionVertex的容器），然后判断所有要进行快照的任务是否都处于running状态。<br>  如果所有任务都处于running状态，就会再判断操作是检查点还是保存点（savepoint）。最后轮询所有的Execution，触发triggerCheckpoint方法。</li>
<li>Execution的triggerCheckpoint方法首先拿到运行Execution任务的LogicalSlot信息，再通过LogicalSlot得到此Slot所在TaskManager的TaskManagerGateway，并调用triggerCheckpoint方法。</li>
<li>TaskManagerGateway的triggerCheckpoint方法本质上是执行TaskExecutorGateway的triggerCheckpoint方法，在这个方法里，通过executionAttemptID得到具体的任务，最后触发任务的triggerCheckpointBarrier方法，进而通过任务的AbstractInvokable类执行triggerCheckpoint方法。在流任务中，所有任务都继承自StreamTask，而StreamTask恰恰继承自AbstractInvokable</li>
<li>当StreamTask执行triggerCheckpoint方法时，会将运行在此任务中的所有Stream-Operator取出，并轮询执行snapshotState方法，SnapshotState根据用户配置的StateBackend进行状态的snapShot操作。任务在进行快照的时候，会将状态和相应的metainfo异步写入文件系统中，然后返回相应的statehandle对象用作恢复。</li>
<li>在所有的算子全部完成状态snapShot并告知JobManager后，就可以认为一次检查点执行过程全部完成。</li>
</ul>
<p><br></p>
<h3 id="任务容错"><a href="#任务容错" class="headerlink" title="任务容错"></a>任务容错</h3><p>我们需要了解Flink的两个有关容错的概念：Restart Strategy和Failover Strategy。</p>
<ul>
<li>前者决定了失败的任务是否应该重启，什么时候重启；</li>
<li>后者决定了哪些任务需要重启。</li>
</ul>
<p>这两个概念的相关值都是通过参数配置的，具体可以参考Flink官方文档，这里不详细介绍，但无论是哪种配置，任务出错后进行恢复的本质是不变的——Task拿到最近一个检查点的状态进行恢复。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">initializeState</span><span class="params">(FunctionInitializationContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">    OperatorStateStore stateStore = context.getOperatorStateStore();</span><br><span class="line"></span><br><span class="line">    ListState&lt;Tuple2&lt;KafkaTopicPartition, Long&gt;&gt; oldRoundRobinListState =</span><br><span class="line">            stateStore.getSerializableListState(</span><br><span class="line">                DefaultOperatorStateBackend.DEFAULT_OPERATOR_STATE_NAME);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">this</span>.unionOffsetStates = stateStore.getUnionListState(<span class="keyword">new</span> ListStateDescriptor&lt;&gt;(</span><br><span class="line">            OFFSETS_STATE_NAME,</span><br><span class="line">            TypeInformation.of(</span><br><span class="line">            <span class="keyword">new</span> TypeHint&lt;Tuple2&lt;KafkaTopicPartition, Long&gt;&gt;() &#123;&#125;)));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (context.isRestored() &lt;&lt; !restoredFromOldState) &#123;</span><br><span class="line">        restoredState = <span class="keyword">new</span> TreeMap&lt;&gt;(<span class="keyword">new</span> KafkaTopicPartition.Comparator());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (Tuple2&lt;KafkaTopicPartition, Long&gt; kafkaOffset : oldRoundRobinListState.get()) &#123;</span><br><span class="line">            restoredFromOldState = <span class="keyword">true</span>;</span><br><span class="line">            unionOffsetStates.add(kafkaOffset);</span><br><span class="line">        &#125;</span><br><span class="line">        oldRoundRobinListState.clear();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (restoredFromOldState &lt;&lt; discoveryIntervalMillis != PARTITION_DISCOVERY_DISABLED) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</span><br><span class="line">                <span class="string">"Topic / partition discovery cannot be enabled if the job is"</span> + <span class="string">"restored from a savepoint from Flink 1.2.x."</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//计算所有需要恢复的状态值</span></span><br><span class="line">        <span class="keyword">for</span> (Tuple2&lt;KafkaTopicPartition, Long&gt; kafkaOffset : unionOffsetStates.get()) &#123;</span><br><span class="line">            restoredState.put(kafkaOffset.f0, kafkaOffset.f1);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>既然任务失败状态恢复的本质是相同的，那么我们就可以以一个典型的任务恢复过程FlinkKafkaConsumerBase为例来进行分析。</p>
<ul>
<li>这个类继承自RichParallelSourceFunction并且使用了CheckpointedFunction接口。<br>  根据之前介绍的状态相关内容，大家会立即想到这个类有两个重写方法——initializeState和snapshotState。前者在初始化或者恢复状态时调用，后者在检查点做快照时调用。当任务失败后重启时，首先会调用initializeState方法，这个方法包含以下三步。<ul>
<li>通过FunctionInitializationContext得到任务相应的OperatorStateStore</li>
<li>根据传入的相关参数从OperatorStateStore中拿出任务失败前最后一次成功检查点中的状态。相对于FlinkKafkaConsumerBase类来说，这一步拿出的是一个ListState类型，里面存储的是Tuple2&lt;KafkaTopicPartition, Long&gt;二元组数据结构。</li>
<li>根据FunctionInitializationContext判断这次initializeState的调用是否为任务重启恢复操作，如果是，则将上一步得到的ListState赋给全局变量restoredState，以供后面的open方法使用</li>
</ul>
</li>
<li>InitializeState方法执行完毕，紧接着会执行函数的open方法。<br>  这个方法在任务初始化的时候只会执行一次，一般有关任务的配置或者加载操作都会在open中完成。由于上一步我们已经从检查点中将任务状态（restoredState）取出<br>  因此在open中要做的就是将状态加载到任务中，让任务从状态断点处恢复运行。FlinkKafkaConsumerBase这个操作就是将Kafka相应的分区位移点（offset）信息从状态中恢复，继续从位移点消费数据。</li>
</ul>
<p>任务失败恢复的过程大致可以总结为两步</p>
<ul>
<li>首先算子从失败前任务状态存储中取出最后一次检查点中对应的状态；</li>
<li>然后算子加载对应的状态，从上次断点开始正常运行。不同算子恢复任务的不同之处只是在于从状态存储中恢复的状态类型不同，本质相同。</li>
</ul>
<p>在这里我们需要对一个知识点进行引申：任务并行度改变后状态的恢复也就是我们常说的状态重分配；针对改变并行度的算子，状态的恢复当然会不同，具体的操作在CheckpointCoordinator中进行。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 重新分配任务状态</span></span><br><span class="line"><span class="keyword">final</span> Map&lt;OperatorID, OperatorState&gt; operatorStates = latest.getOperatorStates();</span><br><span class="line"></span><br><span class="line">StateAssignmentOperation stateAssignmentOperation = <span class="keyword">new</span> StateAssignmentOperation(</span><br><span class="line">    latest.getCheckpointID(), tasks, operatorStates, allowNonRestoredState);</span><br><span class="line"></span><br><span class="line">stateAssignmentOperation.assignStates();</span><br></pre></td></tr></table></figure>
<p>构建完StateAssignmentOperation对象后，就会调用assignStates方法，这个方法会进行以下操作。</p>
<ul>
<li>判断并发度是否改变，如果没变，那么不重新分配，但如果任务状态的模式是广播类型，则会将此任务的状态广播给所有其他任务。</li>
<li>对于Operator State，会对每一个名称的状态计算出每个子任务中的元素个数之和（这就要求各个元素相互独立）并进行轮询调度（round robin）分配。</li>
<li>对于Keyed State的重新分配，首先根据新的并发度和最大并发度计算新的key-GroupRange，然后根据subtaskIndex获取keyGroupRange，最后获取到相应的keyStateHandle并完成状态的切分。</li>
</ul>
<p><br></p>
<h2 id="状态后端"><a href="#状态后端" class="headerlink" title="状态后端"></a>状态后端</h2><p>状态后端（State Backend），顾名思义，是用来存放任务状态的地方。<br>在Flink中状态后端分为三类：FsStateBackend、MemoryStateBackend和RocksDBStateBackend。</p>
<blockquote>
<p>这三种类型分别对应着不同的存储方式</p>
</blockquote>
<ul>
<li>FsStateBackend先把任务状态存储在TaskManager的内存中，当作业开始做检查点的时候，将内存中的状态写到文件系统中；</li>
<li>MemoryStateBackend也会将任务状态存储在TaskManager的内存中，但不同的是做检查点的时候，所有TaskManager会将内存中的状态上传至JobManager，存储在JobManager的内存中而不是可靠的外部存储中；</li>
<li>RocksDBStateBackend会将状态存储在RocksDB中，做检查点的时候，再将状态上传至可靠的文件系统中。</li>
</ul>
<p><br><br><br></p>
<h1 id="任务提交与执行"><a href="#任务提交与执行" class="headerlink" title="任务提交与执行"></a>任务提交与执行</h1><p>主要介绍任务提交的整个过程和实现原理，包括其中的DAG转换、Slot分配、任务状态的变化等。任务的提交因部署模式而异，这里不一一介绍每种部署模式的提交过程，只重点讲解使用比较广泛的Flink on YARN模式</p>
<h2 id="任务提交整体流程"><a href="#任务提交整体流程" class="headerlink" title="任务提交整体流程"></a>任务提交整体流程</h2><p>由于整个流程比较复杂，我们省去了一些与任务提交相关度不太高的环节，比如Flink的JobManager是怎么与YARN的ResourceManager交互来申请资源的，或者YARN的NodeManager是怎么启动Flink的TaskManager的。</p>
<p><img src="/2022/12/05/flink/image-30.png" width="1300px"></p>
<ul>
<li>提交作业：执行./bin/flink run -m yarn-cluster -d来提交任务，这里我们按照yarn-cluster模式来提交任务，并且使用detached模式。</li>
<li>解析参数：命令行入口类CliFrontend会解析相关参数，根据不同的命令和参数执行不同的逻辑。</li>
<li>生成JobGraph：如果判断是通过Per-Job（用-m yarn-cluster指定，后续版本中可能没有Per-Job的概念，这里不用纠结具体的叫法）和detached模式提交的任务，会通过PackagedProgramUtils的createJobGraph方法来创建当前任务的JobGraph。</li>
<li>创建描述符：创建YarnClusterDescriptor来提交YARN作业。</li>
<li>运行AppMaster：这里是向YARN集群提交一个任务，与Spark及其他引擎往YARN上提交任务的过程是一样的。具体就是使用YarnClient接口的相关方法提交任务。</li>
<li>上传任务资源文件：提交任务的过程中需要把任务用到的文件或配置上传到文件系统中，以使任务在不同的节点启动之后都可以获取到需要的资源。</li>
<li>提交任务：把任务提交给YARN的ResourceManager（RM）。YARN的RM会启动一个容器来运行JobManager。具体过程如下：创建一个新的任务，判断资源情况，调度器（Scheduler）进行调度，随后YARN的RM通知NodeManager启动服务。</li>
<li>启动容器：YARN的NodeManager收到RM的通知，进行一系列校验和资源文件的准备，包括文件的下载和环境变量的设置，然后运行启动脚本（由ContainersLauncher根据AppMaster的启动命令生成）启动AppMaster。</li>
<li>启动ClusterEntrypoint：启动Flink的AppMaster，入口类是ClusterEntrypoint。10）启动ResourceManager：ClusterEntrypoint会依次启动JobManager中的各个服务，首先启动负责资源管理的YarnResourceManager，这是JobManager内部的服务，与YARN的RM是不同的服务。</li>
<li>启动ResourceManager：ClusterEntrypoint会依次启动JobManager中的各个服务，首先启动负责资源管理的YarnResourceManager，这是JobManager内部的服务，与YARN的RM是不同的服务。</li>
<li>启动Dispatcher：Dispatcher主要负责接收任务的提交，包括REST方式，为Flink提供一个任务提交管理中心化的角色。Dispatcher还可以用来对JobManager进行容错管理，在JobManager失败后做恢复工作。</li>
<li>启动JobManager：JobManager对应的实现类是JobManagerRunner，用来管理作业的调度和执行。</li>
<li>启动JobMaster：JobManager会把与作业相关的具体事情委托给JobMaster，自己则主要做一些高可用相关的工作。</li>
<li>调度作业：JobMaster会根据JobGraph构建ExecutionGraph，具体的执行过程后面会详细分析。ExecutionGraph经过Slot的分配之后就可以进行真正的部署了。这个时候如果还没有有效的Slot，会先申请Slot。</li>
<li>申请资源：JobMaster在调度任务的时候会通过SlotPool进行Slot的申请和分配。SlotPool是通过YarnResourceManager进行Slot的请求的，而YarnResourceManager内部通过SlotManager进行Slot管理。YarnResourceManager收到Slot请求之后会先判断是否有有效的Slot可供分配。如果有就直接分配；如果没有，则需要启动一个新的TaskManager提供新的Slot。</li>
<li>请求YARN容器，即Flink中的TaskManager。</li>
<li>启动容器：YARN的NodeManager收到命令之后，启动我们需要的容器。</li>
<li>启动TaskExecutor：TaskManager的入口类是YarnTaskExecutorRunner，该类会负责启动TaskExecutor。</li>
<li>注册TaskManager：TaskExecutor启动之后会向YarnResourceManager注册，成功后再向SlotManager汇报自己的资源情况，也就是Slot，同时会启动心跳等服务。</li>
<li>注册Slot：在TaskExecutor向YarnResourceManager注册之后，SlotManager就有了我们需要的Slot。SlotManager会从等待的请求队列里开始分配资源，向TaskManager请求Slot的分配。</li>
<li>提供Slot：TaskExecutor收到Slot请求后，进行一些检查和异常的判断，没有问题的话就会将Slot分配给JobMaster。到这里ExecutionGraph就得到了需要的物理资源Slot。</li>
<li>部署：Execution执行部署任务流程，向TaskExecutor提交任务，TaskExecutor启动新的线程执行任务。到这里整个任务提交的流程结束。后3节会分别介绍其中的关键过程：DAG转换、Slot分配和任务执行。</li>
</ul>
<p><br></p>
<h2 id="DAG转换"><a href="#DAG转换" class="headerlink" title="DAG转换"></a>DAG转换</h2><p>上一节介绍了任务提交的整体流程，这一节重点看下Flink中的用户代码是怎么转化为物理执行算子的，这也就是DAG的转换过程。</p>
<h3 id="DAG的4层转换"><a href="#DAG的4层转换" class="headerlink" title="DAG的4层转换"></a>DAG的4层转换</h3><p>用户代码到Fink任务物理执行会经过多次转换，从最初的program依次到StreamGraph、JobGraph、ExecutionGraph，ExecutionGraph中的ExecutionVertex经过Slot的分配最终部署到TaskManager，形成分布式执行的任务。<br>我们先通过图从整体上看一下这4层转换的大致过程，后面再以具体的例子WordCount来详细分析每个过程。</p>
<blockquote>
<p>DAG的4层转换</p>
</blockquote>
<p><img src="/2022/12/05/flink/image-31.png" width="700px"></p>
<h3 id="WordCount转换过程"><a href="#WordCount转换过程" class="headerlink" title="WordCount转换过程"></a>WordCount转换过程</h3><p>下面以WordCount的例子来从源代码角度详细了解DAG的4层转换</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line">    <span class="comment">// *************************************************************************</span></span><br><span class="line">    <span class="comment">// PROGRAM</span></span><br><span class="line">    <span class="comment">// *************************************************************************</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 检查输入参数</span></span><br><span class="line">        <span class="keyword">final</span> ParameterTool params = ParameterTool.fromArgs(args);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// set up the execution environment</span></span><br><span class="line">        <span class="keyword">final</span> StreamExecutionEnvironment env =</span><br><span class="line">                StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 确保输入参数有效</span></span><br><span class="line">        env.getConfig().setGlobalJobParameters(params);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取输入数据</span></span><br><span class="line">        DataStream&lt;String&gt; text;</span><br><span class="line">        <span class="keyword">if</span> (params.has(<span class="string">"input"</span>)) &#123;</span><br><span class="line">            <span class="comment">//从给定的输入路径中读取文本文件</span></span><br><span class="line">            text = env.readTextFile(params.get(<span class="string">"input"</span>));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">"Executing WordCount example with default input data set."</span>);</span><br><span class="line">            System.out.println(<span class="string">"Use --input to specify file input."</span>);</span><br><span class="line">            <span class="comment">// 获取文本数据</span></span><br><span class="line">            text = env.fromElements(WordCountData.WORDS);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; counts =</span><br><span class="line">                <span class="comment">// 分词</span></span><br><span class="line">                text.flatMap(<span class="keyword">new</span> Tokenizer()).setParallelism(<span class="number">2</span>)</span><br><span class="line">                <span class="comment">// 汇总</span></span><br><span class="line">                .keyBy(<span class="number">0</span>).sum(<span class="number">1</span>).setParallelism(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 输出结果</span></span><br><span class="line">        <span class="keyword">if</span> (params.has(<span class="string">"output"</span>)) &#123;</span><br><span class="line">            counts.writeAsText(params.get(<span class="string">"output"</span>));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">"Printing result to stdout. Use --output to specify output path."</span>);</span><br><span class="line">            counts.print().setParallelism(<span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 执行</span></span><br><span class="line">        env.execute(<span class="string">"Streaming WordCount"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Tokenizer</span> <span class="keyword">implements</span> <span class="title">FlatMapFunction</span>&lt;<span class="title">String</span>,</span></span><br><span class="line"><span class="class">            <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String value, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out)</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 格式化并按行分隔</span></span><br><span class="line">            String[] tokens = value.toLowerCase().split(<span class="string">"\\W+"</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 发送元组</span></span><br><span class="line">            <span class="keyword">for</span> (String token : tokens) &#123;</span><br><span class="line">                <span class="keyword">if</span> (token.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    out.collect(<span class="keyword">new</span> Tuple2&lt;&gt;(token, <span class="number">1</span>));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="算子到StreamGraph的转换"><a href="#算子到StreamGraph的转换" class="headerlink" title="算子到StreamGraph的转换"></a>算子到StreamGraph的转换</h4><p>DataStream转换的过程会把算子（封装了用户的执行函数）封装成StreamTrans-formation，放到StreamExecutionEnvironment的变量Transformations中，StreamTransformation本身也持有前一个Transform的引用。<br>这样用户的转换逻辑就全部放到了Transformations中。<br>生成StreamGraph的过程就是把Transformations转换为StreamGraph的过程。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> List&lt;StreamTransformation&lt;?&gt;&gt; transformations = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br></pre></td></tr></table></figure>
<p>StreamTransformation生成StreamGraph的过程其实就是构造StreamNode的过程，StreamNode包含当前算子及算子的上下游关系。<br>每个StreamTransformation包含的算子构造一个StreamNode，StreamTransformation包含的上下游关系构造StreamEdge，如图所示。</p>
<p><img src="/2022/12/05/flink/image-32.png" width="900px"></p>
<h4 id="StreamGraph到JobGraph的转换"><a href="#StreamGraph到JobGraph的转换" class="headerlink" title="StreamGraph到JobGraph的转换"></a>StreamGraph到JobGraph的转换</h4><p>StreamGraph转换为JobGraph的过程就是构建JobVertex的过程，JobVertex也是后续Flink任务的最小调度单位。JobVertex可以包括多个算子，也就是把多个算子根据一定规则串联起来。<br>创建JobGraph主要是由StreamingJobGraphGenerator的createJobGraph方法完成的。</p>
<blockquote>
<p>该方法的主要逻辑如下</p>
</blockquote>
<ul>
<li>遍历StreamGraph，为每个streamNode生成byte数组类型的哈希值并赋值给OperatorID，作为状态恢复的唯一标识。</li>
<li>利用StreamNode及其相关关系构造JobVertex。其主要逻辑实现在StreamingJob-GraphGenerator的createChain方法中。该方法的主要逻辑如下。<ul>
<li>不能串联到一起的，单独生成JobVertex，并把算子中的用户函数（如WordCount的Tokenizer方法）及相关属性序列化到JobVertex的configuration中。</li>
<li>可以串联到一起的，选取串开头的StreamNode作为当前JobVertex的JobVertexID，将其他StreamNode都序列化到配置字段chainedTaskConfig_中。<br>  当然序列化的对象也是存储了StreamNode相关信息的StreamConfig类。算子之间的关系生成了JobEdge和IntermediateDataSet类，放到JobVertex中。</li>
</ul>
</li>
<li>设置Slot共享组及其他作业相关的属性，包括资源分配location属性、checkpoint等。</li>
</ul>
<p>WordCount生成的JobGraph如图所示。</p>
<p><img src="/2022/12/05/flink/image-33.png" width="500px"></p>
<p>哪些算子可以串联呢？直接看以下源代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isChainable</span><span class="params">(StreamEdge edge, StreamGraph streamGraph)</span> </span>&#123;</span><br><span class="line">    StreamNode upStreamVertex = edge.getSourceVertex();</span><br><span class="line">    StreamNode downStreamVertex = edge.getTargetVertex();</span><br><span class="line"></span><br><span class="line">    StreamOperator&lt;?&gt; headOperator = upStreamVertex.getOperator();</span><br><span class="line">    StreamOperator&lt;?&gt; outOperator = downStreamVertex.getOperator();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> downStreamVertex.getInEdges().size() == <span class="number">1</span></span><br><span class="line">        &lt;&lt; outOperator != <span class="keyword">null</span></span><br><span class="line">        &lt;&lt; headOperator != <span class="keyword">null</span></span><br><span class="line">        &lt;&lt; upStreamVertex.isSameSlotSharingGroup(downStreamVertex)</span><br><span class="line">        &lt;&lt; outOperator.getChainingStrategy() == ChainingStrategy.ALWAYS</span><br><span class="line">        &lt;&lt; (headOperator.getChainingStrategy() == ChainingStrategy.HEAD ||</span><br><span class="line">            headOperator.getChainingStrategy() == ChainingStrategy.ALWAYS)</span><br><span class="line">        &lt;&lt; (edge.getPartitioner() <span class="keyword">instanceof</span> ForwardPartitioner)</span><br><span class="line">        &lt;&lt; upStreamVertex.getParallelism() == downStreamVertex.getParallelism()</span><br><span class="line">        &lt;&lt; streamGraph.isChainingEnabled();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>开发者关注的是否可以串联的是：上下游并发是否一样，是否包含keyBy或者Rebalance的动作。<br>算子串联的过程就是循环判断所有的StreamNode是否符合要求。<br>对于上面的WordCount的例子，我们稍微设置下并发：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">env.getConfig().setParallelism(<span class="number">2</span>);</span><br><span class="line">text = env.fromElements(WordCountData.WORDS);</span><br><span class="line">DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; counts = text.flatMap(<span class="keyword">new</span> Tokenizer()).keyBy(<span class="number">0</span>).sum(<span class="number">1</span>);</span><br><span class="line">counts.print().setParallelism(<span class="number">3</span>);</span><br></pre></td></tr></table></figure>
<p>生成的JobGraph就变成图这样了</p>
<p><img src="/2022/12/05/flink/image-34.png" width="900px"></p>
<p><br></p>
<h4 id="JobGraph到ExecutionGraph的转换"><a href="#JobGraph到ExecutionGraph的转换" class="headerlink" title="JobGraph到ExecutionGraph的转换"></a>JobGraph到ExecutionGraph的转换</h4><p>ExecutionGraph是JobGraph的并发版本，每个JobVertex对应ExecutionJobVertex，ExecutionJobVertex就是JobVertex增加一些执行信息的封装类。<br>一个有10个并发的算子会生成1个JobVertex、1个ExecutionJobVertex和10个ExecutionVertex。ExecutionVertex代表一个并发的子任务，可以被执行一次或者多次，内部Execution对象表示执行状态。<br>当然在ExecutionGraph内部也有JobStatus对象来记录整个作业的执行状态。<br>ExecutionVertex是通过IntermediateResultPartition来连接的。</p>
<p>接着看上面WordCount的例子，JobGraph转换为ExecutionGraph的过程如图所示。<br><img src="/2022/12/05/flink/image-35.png" width="900px"></p>
<h4 id="ExecutionGraph到Task的转换"><a href="#ExecutionGraph到Task的转换" class="headerlink" title="ExecutionGraph到Task的转换"></a>ExecutionGraph到Task的转换</h4><p>ExecutionGraph到Task需要经过资源的分配即Slot的分配，然后部署。</p>
<p><br><br><br></p>
<h2 id="Slot分配"><a href="#Slot分配" class="headerlink" title="Slot分配"></a>Slot分配</h2><p>本节重点介绍Slot的分配过程。<br>本节不涉及Slot在ResourceManager和TaskManager之间的申请过程，这里假设所有需要的Slot都已经在JobMaster的SlotPool中申请好。</p>
<h3 id="相关概念和实现类"><a href="#相关概念和实现类" class="headerlink" title="相关概念和实现类"></a>相关概念和实现类</h3><p>下面看几个重要的逻辑角色，它们一起配合管理Slot，而且相互之间有一些实现上的依赖或继承关系。</p>
<h4 id="SlotManager和SlotPool"><a href="#SlotManager和SlotPool" class="headerlink" title="SlotManager和SlotPool"></a>SlotManager和SlotPool</h4><p>SlotManager是ResourceManager用来管理Slot的，它维护了所有已经注册的Slot的状态及使用情况。<br>而SlotPool是JobManager中用来服务Slot请求和分配的，当Slot不足时它会向ResourceManager请求更多的Slot。<br>SlotPool即使在ResourceManager服务无法响应的时候也可以单独提供服务。</p>
<p>它们之间的关系和交互如图所示。<br><img src="/2022/12/05/flink/image-36.png" width="400px"></p>
<h4 id="PhysicalSlot、LogicalSlot、MultiTaskSlot、SingleTaskSlot"><a href="#PhysicalSlot、LogicalSlot、MultiTaskSlot、SingleTaskSlot" class="headerlink" title="PhysicalSlot、LogicalSlot、MultiTaskSlot、SingleTaskSlot"></a>PhysicalSlot、LogicalSlot、MultiTaskSlot、SingleTaskSlot</h4><p>PhysicalSlot和LogicalSlot是用来抽象Slot概念的，而MultiTaskSlot和SingleTaskSlot是用来辅助Slot的分配而用到的包装类，不对应任何概念，进一步说，TaskSlot的这两个实现类只是用来辅助共享Slot分配，如果没有设置Slot共享组，甚至不需要这两个类。<br>PhysicalSlot表示物理意义上的Slot，已经分配了唯一标识AllocationID，拥有TaskManagerGateway等属性，可以用来部署任务。<br>LogicalSlot（见图）表示逻辑意义上的Slot，一个LogicalSlot对应一个Execution-Vertex或任务，或者多个LogicalSlot对应一个PhysicalSlot，表示它们共用同一个Slot执行。</p>
<p><img src="/2022/12/05/flink/image-37.png" width="900px"></p>
<p>PhysicalSlot唯一的实现类是AllocatedSlot，LogicalSlot的主要实现类是SingleLogicalSlot，它们都实现了tryAssignPayload方法，也就是说AllocatedSlot可以装载一个SingleLogicalSlot，SingleLogicalSlot可以装载一个Execution（Execution表示ExecutionVertex的一次执行）。<br>这里payLoad表示“被分配给”的意思，也就是说Execution会拥有一个SingleLogicalSlot，而SingleLogicalSlot会拥有AllocatedSlot。AllocatedSlot包含Slot的物理信息，如Task-ManagerGateway，可以用来执行一次Execution。</p>
<p>MultiTaskSlot是为了完成多个LogicalSlot对一个PhysicalSlot的映射而用到的工具类。<br>MultiTaskSlot和SingleTaskSlot的接口都是TaskSlot。<br>MultiTaskSlot是一个树形结构，叶子节点就是SingleTaskSlot，非叶子节点还是MultiTaskSlot。<br>树的根节点是MultiTaskSlot，根节点会被分配一个SlotContext，SlotContext具体实现就是AllocatedSlot，也就是Physical-Slot。<br>树的所有叶子节点都会共享这个PhysicalSlot，而每个叶子节点SingleTaskSlot会对应一个SingleLogicalSlot，也就是LogicalSlot，这样就可以利用该树形结构表达多个LogicalSlot对一个PhysicalSlot的映射。<br>每个叶子节点都有唯一的AbstractID，这个就是JobVertexID，也就是说每个物理Slot节点上执行的任务都是不同的，不可能同一个任务的并发执行在相同的Slot上。</p>
<p>MultiTaskSlot表示的是同一个Slot共享组下的Slot分配，这个是通过SlotSharing-Manager来保证的，每个Slot共享组都会唯一对应一个SlotSharingManager。</p>
<p><br></p>
<h3 id="Slot申请流程"><a href="#Slot申请流程" class="headerlink" title="Slot申请流程"></a>Slot申请流程</h3><p>之前JobMaster负责任务的调度和部署。入口方法是startScheduling方法，JobMaster会委托给LegacyScheduler执行。<br>LegacyScheduler是ExecutionGraph的一个门面类，具体的实现还是通过ExecutionGraph。<br>作业的调度和部署是以ExecutionVertex为单位进行的。<br>主要的方法是ExecutionGraph的scheduleForExecution。<br>下面先来看一下整个过程（见图），然后再对具体方法进行分析。</p>
<p><img src="/2022/12/05/flink/image-38.png" width="900px"></p>
<p>SchedulingUtils会根据ScheduleMode进入不同的方法，走不同的调度流程。Schedule-Mode主要有以下几种。</p>
<ul>
<li>LAZY_FROM_SOURCES：下游的任务需要在上游结果产生的前提下进行调度，一般用在离线的场景。</li>
<li>LAZY_FROM_SOURCES_WITH_BATCH_SLOT_REQUEST：与LAZY_FROM_SOURCES基本一致，不同的是这种模式支持在Slot资源不足的情况下执行作业，但用户需要确保作业中没有shuffle操作。</li>
<li>EAGER：立刻调度所有的任务，流任务一般采用这种模式。</li>
</ul>
<h3 id="任务部署"><a href="#任务部署" class="headerlink" title="任务部署"></a>任务部署</h3><p>经过上面的Slot申请之后，就可以进行部署工作了。<br>部署的主要逻辑在Execution的deploy方法中，实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">deploy</span><span class="params">()</span> <span class="keyword">throws</span> JobException </span>&#123;</span><br><span class="line">    assertRunningInJobMasterMainThread();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> LogicalSlot slot = assignedResource;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 去掉了非核心逻辑代码</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> TaskDeploymentDescriptor deployment = TaskDeploymentDescriptorFactory</span><br><span class="line">            .fromExecutionVertex(vertex, attemptNumber)</span><br><span class="line">            .createDeploymentDescriptor(</span><br><span class="line">                    slot.getAllocationId(),</span><br><span class="line">                    slot.getPhysicalSlotNumber(),</span><br><span class="line">                    taskRestore,</span><br><span class="line">                    producedPartitions.values());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 赋空，方便GC</span></span><br><span class="line">        taskRestore = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> TaskManagerGateway taskManagerGateway = slot.getTaskManagerGateway();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> ComponentMainThreadExecutor jobMasterMainThreadExecutor =</span><br><span class="line">            vertex.getExecutionGraph().getJobMasterMainThreadExecutor();</span><br><span class="line"></span><br><span class="line">        CompletableFuture</span><br><span class="line">            .supplyAsync(() -&gt; taskManagerGateway.submitTask(deployment, rpcTimeout), executor)</span><br><span class="line">            .thenCompose(Function.identity())</span><br><span class="line">            .whenCompleteAsync((ack, failure) -&gt; &#123;</span><br><span class="line">                <span class="comment">// 只响应失败的案例</span></span><br><span class="line">                <span class="keyword">if</span> (failure != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (failure <span class="keyword">instanceof</span> TimeoutException) &#123;</span><br><span class="line">                        String taskname = vertex.getTaskNameWithSubtaskIndex()</span><br><span class="line">                                + <span class="string">" ("</span> + attemptId + <span class="string">')'</span>;</span><br><span class="line"></span><br><span class="line">                        markFailed(<span class="keyword">new</span> Exception(</span><br><span class="line">                                <span class="string">"Cannot deploy task "</span> + taskname + <span class="string">" - TaskManager ("</span></span><br><span class="line">                                + getAssignedResourceLocation()</span><br><span class="line">                                + <span class="string">") not responding after a rpcTimeout of "</span></span><br><span class="line">                                + rpcTimeout, failure));</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        markFailed(failure);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            jobMasterMainThreadExecutor);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        markFailed(t);</span><br><span class="line">        ExceptionUtils.rethrow(t);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>整个过程比较清楚，就是拿到分配的Slot构造TaskDeploymentDescriptor，然后通过TaskManagerGateway进行提交。<br>TaskDeploymentDescriptor包装了执行任务所需的大部分信息，其中的信息都经过了序列化。<br>下面就来具体分析提交之后的过程。</p>
<p><br></p>
<h2 id="任务执行机制"><a href="#任务执行机制" class="headerlink" title="任务执行机制"></a>任务执行机制</h2><h3 id="任务执行过程"><a href="#任务执行过程" class="headerlink" title="任务执行过程"></a>任务执行过程</h3><p>ExecutionVertex在经过Slot分配之后进行部署，TaskManager会收到submitTask的请求，启动并执行任务。<br>入口代码在TaskExecutor的submitTask方法中。我们根据图来看一下整个过程。</p>
<p><img src="/2022/12/05/flink/image-39.png" width="1300px"></p>
<ul>
<li>初始化StreamTask<br>  在任务启动之后构造StreamTask，并调用其中的invoke方法。<br>  StreamTask是流作业的执行基类，是调度和执行的基本单元和实现类。StreamTask会运行我们的算子，算子可能以算子串的形式存在。<br>  StreamTask最重要的方法是invoke方法。invoke方法主要完成以下几项内容。<ul>
<li>初始化stateBackend，加载operatorChain。</li>
<li>执行init方法。<br>  该方法是个抽象方法，每个具体的StreamTask类都有不同的实现。StreamTask的主要实现类有OneInputStreamTask（一个输入的任务）和SourceStreamTask（source处的任务）。对于OneInputStreamTask来说，init的主要工作是构建InputGate，用来消费分区的数据。</li>
<li>初始化算子的状态（从检查点恢复数据），然后打开所有的算子。<br>  这里最终会调用ProcessFunction的open方法，也就是用户实现的函数的open方法。</li>
<li>开始运行算子，也就是图中的步骤2。在输入数据处理完成后，进入close流程。</li>
<li>关闭过程主要包括：timerService（用来注册Timer）停止服务；关闭所有的算子；清空所有缓存的数据；清理所有的算子。该方法是用来释放资源的，比如关闭stateBackend。</li>
<li>执行一个finally步骤，包括停止timerService，停止异步检查点进程，做些清理工作，以及关闭recordWriter。</li>
</ul>
</li>
<li>执行处理方法<br>  看过Flink早期版本代码的读者看到performDefaultAction方法可能会感到疑惑，怎么增加了这样一个方法？<br>  Flink的早期版本（如1.4版本）中StreamTask的run方法是个抽象方法，不同的实现类有不同的实现；<br>  而在我们分析的1.9版本中，run方法变成了具体方法，把performDefaultAction拿出来让各实现类实现。<br>  简单看一下代码就会发现，1.9版本增加了一个mailbox变量，这就是稍后会讲到的Flink对线程模型的优化——MailBox线程模型。<br>  这里performDefaultAction就是各个StreamTask要实现的具体方法，也就是算子的主要工作流程入口。</li>
<li>拉取数据<br>  我们来看StreamTask的一个具体实现：SourceStreamTask。<br>  SourceStreamTask的perform-DefaultAction（该方法也有一些与MailBox有关的逻辑，可以忽略，只需关注主要过程）经过一系列的调用最终会启动SourceFunction的run方法。<br>  对于流任务的Source来说，SourceFunction是一个无限循环的函数，永不休止地进行数据的消费或者生产。</li>
<li>发送数据<br>  数据在SourceFunction中产生之后，主线程会调用sourceContext进行收集，并经过Output接口实现类将其发送到网络端或下游算子。<br>  在图中有两个Output的接口实现类，分别是RecordWriterOutput和ChainingOutput。<ul>
<li>RecordWriterOutput：将数据通过RecordWriter发送出去。</li>
<li>ChainingOutput：将数据推送到下一个算子，主要出现在算子串中。</li>
</ul>
</li>
<li>处理数据我们来看StreamTask另一个经常使用的具体实现：OneInputStreamTask。<br>  OneInput-StreamTask的performDefaultAction方法就是调用StreamOneInputProcessor的processInput，然后进一步调用算子的processElement。<br>  图中给出的是我们比较常见的一个算子基础类AbstractUdfStreamOperator。<br>  顾名思义这个类就是可以接受用户定义函数（UDF）的算子类。<br>  AbstractUdfStreamOperator的processElement会调用userFunction的具体方法，也就是用户实现的方法。<br>  这对于MapFunction来说，就是调用Map方法；对于FlatMap-Function来说，就是调用FlatMap方法；对于SinkFunction来说，就是调用invoke方法。</li>
<li>算子串处理数据<br>  如果当前OneInputStreamTask的算子是一个算子串，那么经过第一个算子的process-Element方法之后，ChainingOutput会调用collect方法把数据推送到下一个算子，然后接着经过下一个算子的processElement方法。</li>
<li>将数据发送到外部<br>  如果当前算子是StreamSink，那么userFunction就是SinkFunction，最终会调用Sink-Function的invoke方法，把数据发送到外部系统。</li>
</ul>
<p><img src="/2022/12/05/flink/image-40.png" width="900px"></p>
<p>首先在SourceFunction处生成或者拉取数据，然后通过SourceContext将数据收集到Output中，这里的Output是RecordWriterOutput，这样数据会通过网络或者本地的方式被发送到一个任务中。<br>下一个任务，这里是FlatMap，通过StreamTaskInput获取到数据，数据经过算子调用map函数，也就是Tokenizer处理之后，被收集到CountingOutput（只起到计数的作用），接着CountingOutput转手把数据给了RecordWriterOutput，由RecordWriterOutput再把数据发送到网络或者通过本地内存传输。<br>经过网络传输（稍后介绍）和数据的重新分区，StreamGroupedReduce算子拿到了数据，进行求和计算，然后通过CopyingChainingOutput把数据推送到StreamSink算子，由StreamSink调用userFunction也就是PrintSinkFunction将数据打印到标准输出。</p>
<p><br></p>
<h3 id="MailBox线程模型"><a href="#MailBox线程模型" class="headerlink" title="MailBox线程模型"></a>MailBox线程模型</h3><p>MailBox线程模型是Flink 1.9版本引入的任务线程模型，它对早期版本中的简单线程模型进行了升级，优化了代码结构，提高了运行效率。</p>
<p><img src="/2022/12/05/flink/image-41.png" width="700px"></p>
<h4 id="改进理由"><a href="#改进理由" class="headerlink" title="改进理由"></a>改进理由</h4><p>为什么要对StreamTask的线程模型进行优化？Flink 1.9版本的代码已经经过部分的改造，不能很好地说明问题，下面以Flink 1.4版本代码为例来说明。<br>StreamTask内部有一个Object类型的锁变量lock，该变量会在多个地方用到，用来同步算子处理数据和检查点、定时器触发等操作。（为什么需要同步呢？读者可以自己思考下。）我们通过图来看看。<br>StreamTask的锁变量被多个地方引用和使用，而且还通过SourceContext的API暴露给了用户。<br>Flink 1.4及之前版本的实现有以下不足之处：锁对象在多个类中传递和使用，代码的可读性和后期的维护成本都是问题，而且后续开发的功能容易因锁的使用不当而出现问题。把框架内部的锁暴露给用户，这不是一个好的设计。</p>
<h4 id="MailBox模型"><a href="#MailBox模型" class="headerlink" title="MailBox模型"></a>MailBox模型</h4><p>MailBox模型借鉴Actor模型的设计理念，把需要同步的行为（action）放到一个队列或者消息容器里，然后单线程顺序获取行为，最后执行。</p>
<h4 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h4><p>对于具体实现，最简单的想法就是通过一个阻塞队列实现。<br>Flink 1.9版本是用一个ringBuffer的Runnable数组缓存行为，然后实现take或put相关方法。<br>这里我们看看Flink 1.10版本的实现（该版本在本书发售之前已经发布，并且这部分代码已经比较完善）。</p>
<p><br><br><br></p>

        
    </section>
</article>



<div class="comments">
    <div id="disqus_thread">
        <p class="comment-tips">国内查看评论需要代理~</p>
    </div>
    <script>
    window.disqus_config = function () {
        this.language = 'zh';
        this.page.url = 'http://www.coderss.cn/2022/12/05/flink/';
        this.page.title = 'Flink笔记';
        this.page.identifier = '2022/12/05/flink/';
    };
    (function() { // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');
        s.src = 'https://name.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

</div>
        <footer class="footer">
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, Theme by <a href="https://github.com/sanonz/hexo-theme-concise" target="_blank">Concise</a>
</footer>

<script type="text/javascript" src="//s13.cnzz.com/z_stat.php?id=1234567890&amp;web_id=1234567890"></script>


    </div>

    <script type="text/javascript" src="https://cdn.bootcss.com/jquery/1.9.0/jquery.min.js"></script>
    
    <script type="text/javascript" src="/js/scrollspy.min.js"></script>
    
    <script type="text/javascript">
        $(function() {
            var nodes = {
                nav: $('#nav'),
                aside: $('#aside'),
                navTags: $('#nav-tags')
            };

            $('#open-panel, #aside-mask').on('click', function() {
                nodes.aside.toggleClass('panel-show');
            });
            $('#nav-tag').on('click', function(event) {
                event.preventDefault();console.log(nodes.navTags.attr('class'))
                nodes.navTags.toggleClass('tag-show');console.log(nodes.navTags.attr('class'))
            })/*.hover(function() {
                nodes.navTags.addClass('tag-show');
            }, function() {
                nodes.navTags.removeClass('tag-show');
            });*/

            
            $(document.body).scrollspy({target: '#aside-inner'});
            
        });
    </script>

</body>
</html>
