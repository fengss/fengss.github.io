<!DOCTYPE html>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="UTF-8">

    

    

    <title>Linux-tc-qdisc管理网络带宽 | Coderss</title>
    <meta name="author" content="coder">
    <meta name="version" content="1.0.0">
    <meta name="keywords" content="">
    <meta name="description" content="Linux-tc-qdisc笔记知识详解笔记
Linux 的带宽管理能力足以媲美许多高端、专用的带宽管理系统
本文内容来自Linux Advanced Routing &amp;amp; Traffic Control HOWTO (2012),这是一份在线文档(小书),直译为《Linux 高级路由与流量控制手册》
术语为方便理解接下来更复杂的配置,我们需要先引入一些概念。由于这项技术本身比较复杂, 发展也还处在较为早期的阶段,因此大家可能会用不同的术语描述同一样东西。
下列术语大体上来自draft-i">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    <meta name="baidu-site-verification" content="F0CXvmUgA9">

    
    
    <link rel="icon" href="/favicon.png">
    

    <link rel="stylesheet" href="/css/style.css">
</head>
<body>

    <div class="app">
        <header class="header clearfix">
    <div id="nav" class="nav">
    <button id="open-panel" class="open-panel"><i class="icon-library"></i></button>

    <nav class="nav-inner">

        
        
        <li class="nav-item">
            <a class="nav-link" href="/">首页</a>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/categories/back-end">Java后端</a>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/categories/cpp">Cpp嵌入式</a>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/categories/go">Go云原生</a>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/categories/cloud">Linux安全</a>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/categories/reverse">Win安全</a>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/categories/data">数据与算法</a>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/categories/work">工作相关</a>
        </li>
        
        
        
        <li class="nav-item nav-item-tag">
            <a id="nav-tag" class="nav-link" href="#">文章标签</a>
            <div id="nav-tags" class="nav-tag-wrap">
                <i class="nav-tag-arrow"></i>
                
  <div class="widget-wrap">
    <h3 class="widget-title">
        <i class="icon-tag vm"></i>
        <span class="vm">Tags</span>
    </h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AI/">AI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Boost库/">Boost库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Collection/">Collection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Cpp编程/">Cpp编程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Fescar/">Fescar</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gc/">Gc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/K8s/">K8s</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MapReduce/">MapReduce</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Math/">Math</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Net/">Net</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nosql/">Nosql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python计算库/">Python计算库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Rust/">Rust</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sharding-jdbc/">Sharding-jdbc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SkyWalking/">SkyWalking</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/">Spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TensorFlow/">TensorFlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Turi/">Turi</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Windows系统/">Windows系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Windows驱动/">Windows驱动</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Yarn/">Yarn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/assembly/">assembly</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/c-cpp语言/">c/cpp语言</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/debug/">debug</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/design/">design</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/">docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dubbo/">dubbo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/eth/">eth</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flume/">flume</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go/">go</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go-kernel/">go-kernel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/io/">io</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/juc/">juc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kubernetes/">kubernetes</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/map/">map</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mfc/">mfc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/microservice/">microservice</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mybatis/">mybatis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/netty/">netty</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python-book/">python-book</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/qt/">qt</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sentinel/">sentinel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/skycoin/">skycoin</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spring/">spring</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spring-cloud/">spring-cloud</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/stl/">stl</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tomcat/">tomcat</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/x86-Windows系统总结/">x86 Windows系统总结</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/中台/">中台</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分布式文件系统/">分布式文件系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/多线程编程/">多线程编程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/嵌入式/">嵌入式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/架构/">架构</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/消息队列/">消息队列</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网络编程/">网络编程</a></li></ul>
    </div>
  </div>


            </div>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/archives">历史归档</a>
        </li>
        
        
        

    </nav>
</div>

    <aside id="aside" class="aside">
    <div id="aside-mask" class="aside-mask"></div>
    <div id="aside-inner" class="aside-inner">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"><i class="icon-search-stroke"></i></button><input type="hidden" name="sitesearch" value="http://www.coderss.cn"></form>

        
        
        
        
        

        
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#术语"><span class="toc-number">1.</span> <span class="toc-text">术语</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#使用建议-何时选择哪种队列"><span class="toc-number">2.</span> <span class="toc-text">使用建议:何时选择哪种队列?</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#队列和排队规则"><span class="toc-number">3.</span> <span class="toc-text">队列和排队规则</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#简单、不分类排队规则"><span class="toc-number">4.</span> <span class="toc-text">简单、不分类排队规则</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#pfifo-fast-先入先出队列"><span class="toc-number">4.1.</span> <span class="toc-text">pfifo_fast(先入先出队列)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#参数与用法"><span class="toc-number">4.1.1.</span> <span class="toc-text">参数与用法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#priomap"><span class="toc-number">4.1.1.1.</span> <span class="toc-text">priomap</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#txqueuelen"><span class="toc-number">4.1.1.2.</span> <span class="toc-text">txqueuelen</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TBF-Token-Bucket-Filter-令牌桶过滤器"><span class="toc-number">4.2.</span> <span class="toc-text">TBF(Token Bucket Filter,令牌桶过滤器)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#参数与用法-1"><span class="toc-number">4.2.1.</span> <span class="toc-text">参数与用法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#limit-or-latency"><span class="toc-number">4.2.1.1.</span> <span class="toc-text">limit or latency</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#burst-buffer-maxburst"><span class="toc-number">4.2.1.2.</span> <span class="toc-text">burst/buffer/maxburst</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#mpu"><span class="toc-number">4.2.1.3.</span> <span class="toc-text">mpu</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#rate"><span class="toc-number">4.2.1.4.</span> <span class="toc-text">rate</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#peakrate"><span class="toc-number">4.2.1.5.</span> <span class="toc-text">peakrate</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#mtu-minburst"><span class="toc-number">4.2.1.6.</span> <span class="toc-text">mtu/minburst</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#示例配置"><span class="toc-number">4.2.2.</span> <span class="toc-text">示例配置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SFQ-Stochastic-Fairness-Queueing-随机公平排队"><span class="toc-number">4.3.</span> <span class="toc-text">SFQ(Stochastic Fairness Queueing,随机公平排队)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#参数与用法-2"><span class="toc-number">4.3.1.</span> <span class="toc-text">参数与用法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#perturb"><span class="toc-number">4.3.1.1.</span> <span class="toc-text">perturb</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#quantum"><span class="toc-number">4.3.1.2.</span> <span class="toc-text">quantum</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#limit"><span class="toc-number">4.3.1.3.</span> <span class="toc-text">limit</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#示例配置-1"><span class="toc-number">4.3.2.</span> <span class="toc-text">示例配置</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#分类别排队规则-Classful-qdisc"><span class="toc-number">5.</span> <span class="toc-text">分类别排队规则(Classful qdisc)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Classful-qdisc-amp-class-中的-flow"><span class="toc-number">5.1.</span> <span class="toc-text">Classful qdisc &amp; class 中的 flow</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#qdisc大家庭-roots-handles-siblings-and-parents"><span class="toc-number">5.2.</span> <span class="toc-text">qdisc大家庭:roots, handles, siblings and parents</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#如何用过滤器-filters-对流量进行分类"><span class="toc-number">5.2.1.</span> <span class="toc-text">如何用过滤器(filters )对流量进行分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#包是如何从-qdisc-出队-dequeue-然后交给硬件的"><span class="toc-number">5.2.2.</span> <span class="toc-text">包是如何从 qdisc 出队(dequeue)然后交给硬件的</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PRIO-qdisc-优先级排队规则"><span class="toc-number">5.3.</span> <span class="toc-text">PRIO qdisc(优先级排队规则)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#参数与用法-3"><span class="toc-number">5.3.1.</span> <span class="toc-text">参数与用法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#示例配置-2"><span class="toc-number">5.3.2.</span> <span class="toc-text">示例配置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#著名的-CBQ-Class-Based-Queueing-qdisc"><span class="toc-number">5.4.</span> <span class="toc-text">著名的 CBQ(Class Based Queueing)qdisc</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CBQ-shaping-详解"><span class="toc-number">5.4.1.</span> <span class="toc-text">CBQ shaping 详解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CBQ-classful-behaviour"><span class="toc-number">5.4.2.</span> <span class="toc-text">CBQ classful behaviour</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#决定-link-sharing-amp-borrowing-的-CBQ-参数"><span class="toc-number">5.4.3.</span> <span class="toc-text">决定 link sharing &amp; borrowing 的 CBQ 参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#示例配置-3"><span class="toc-number">5.4.4.</span> <span class="toc-text">示例配置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HTB-Hierarchical-Token-Bucket-层级令牌桶"><span class="toc-number">5.5.</span> <span class="toc-text">HTB(Hierarchical Token Bucket,层级令牌桶)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#示例配置-4"><span class="toc-number">5.5.1.</span> <span class="toc-text">示例配置</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#用过滤器对流量进行分类"><span class="toc-number">6.</span> <span class="toc-text">用过滤器对流量进行分类</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#一些简单的流量过滤-filtering-示例"><span class="toc-number">6.1.</span> <span class="toc-text">一些简单的流量过滤(filtering)示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#常用-filtering-命令"><span class="toc-number">6.2.</span> <span class="toc-text">常用 filtering 命令</span></a></li></ol></li></ol>
        
    </div>
</aside>

</header>

        <div id="content" class="content"><article class="article" itemscope="" itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
           Linux-tc-qdisc管理网络带宽
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="/2022/01/23/linux-tc/">
    
    <i class="icon-calendar"></i>
    
    <time datetime="2022-01-23T03:40:19.000Z" itemprop="datePublished">2022-01-23</time>
</a>

            
<div class="article-tag-list">
    <i class="icon-tag"></i>
    <a class="article-tag-link" href="/tags/Linux/">Linux</a>
</div>


        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <p>Linux-tc-qdisc笔记知识详解笔记<br><a id="more"></a></p>
<p>Linux 的带宽管理能力足以媲美许多高端、专用的带宽管理系统</p>
<p>本文内容来自<a href="https://lartc.org/howto/index.html" target="_blank" rel="noopener">Linux Advanced Routing &amp; Traffic Control HOWTO (2012)</a>,这是一份在线文档(小书),直译为《Linux 高级路由与流量控制手册》</p>
<h1 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h1><p>为方便理解接下来更复杂的配置,我们需要先引入一些概念。由于这项技术本身比较复杂, 发展也还处在较为早期的阶段,因此大家可能会用不同的术语描述同一样东西。</p>
<p>下列术语大体上来自<a href="http://www.ietf.org/internet-drafts/draft-ietf-diffserv-model-06.txt" target="_blank" rel="noopener">draft-ietf-diffserv-model-06.txt, An Informal Management Model for Diffserv Routers</a> 。想进一步了解一些术语的定义,可参考这份文档。</p>
<blockquote>
<p>我们接下来会用到下列术语</p>
</blockquote>
<ul>
<li>Queueing Discipline (qdisc,排队规则)</li>
</ul>
<p>管理设备队列(queues of devices)的算法,可以是管理入向(incoing/ingress )队列,也可以是管理出向队列(outgoing/egress)。</p>
<ul>
<li>root qdisc(根排队规则)</li>
</ul>
<p>attach 到网络设备的那个 qdisc。</p>
<ul>
<li>Classless qdisc(无类别排队规则)</li>
</ul>
<p>对所有包一视同仁,同等对待。</p>
<ul>
<li>Classful qdisc(有类别排队规则)</li>
</ul>
<p>一个 classful qdisc 会包含多个类别(classes)。每个类别(class)可以进一步包 含其他 qdisc,可以是 classful qdisc,也可以是 classless qdisc。<br>严格按定义来说,pfifo_fast 属于有类别排队规则(classful),因为它内部包 含了三个 band,而这些 band 实际上是 class。但从用户配置的视角来说,它是 classless 的,因为这三个内部 class 用户是无法通过 tc 命令配置的。</p>
<ul>
<li>Classes(类别)</li>
</ul>
<p>每个 classful qdisc 可能会包含几个 class,这些都是 qdisc 内部可见的。对于每 个 class,也是可以再向其添加其他 class 的。因此,一个 class 的 parent 可以 是一个 qdisc,也可以是另一个 class。</p>
<p>Leaf class 是没有 child class 的 class。这种 class 中 attach 了一个 qdisc ,负责该 class 的数据发送。</p>
<p>创建一个 class 时会自动 attach 一个 fifo qdisc。而当向这个 class 添加 child class 时,这个 fifo qdisc 会被自动删除。对于 leaf class,可以用一个更合适的 qdisc 来替换掉这个fifo qdisc。你甚至能用一个 classful qdisc 来替换这个 fifo qdisc,这样就可以添加其他 class了。</p>
<ul>
<li>Classifier(分类器)</li>
</ul>
<p>每个 classful qdisc 需要判断每个包应该放到哪个 class。这是通过分类器完成的。</p>
<ul>
<li>Filter(过滤器)</li>
</ul>
<p>分类过程(Classification)可以通过过滤器(filters)完成。过滤器包含许多的判 断条件,匹配到条件之后就算 filter 匹配成功了。</p>
<ul>
<li>Scheduling(调度)</li>
</ul>
<p>在分类器的协助下,一个 qdisc 可以判断某些包是不是要先于其他包发送出去,这个过程称为调度,可以通过例如前面提到的 pfifo_fast qdisc 完成。调度也被称为重排序(reordering),但后者容易引起混淆。</p>
<ul>
<li>Shaping(整形)</li>
</ul>
<p>在包发送出去之前进行延迟处理,以达到预设的最大发送速率的过程。整形是在 egress 做的(前面提到了,ingress 方向的不叫shaping,叫 policing,译者注)。 不严格地说,丢弃包来降低流量的过程有时也称为整形。</p>
<ul>
<li>Policing(执行策略,决定是否丢弃包)</li>
</ul>
<p>延迟或丢弃(delaying or dropping)包来达到预设带宽的过程。 在 Linux 上, policing 只能对包进行丢弃,不能延迟 —— 没有“入向队列”(”ingress queue”)。</p>
<ul>
<li>Work-Conserving qdisc(随到随发 qdisc)</li>
</ul>
<p>work-conserving qdisc 只要有包可发送就立即发送。换句话说,只要网卡处于可发送状态(对于 egress qdisc 来说),它永远不会延迟包的发送。</p>
<ul>
<li>non-Work-Conserving qdisc(非随到随发 qdisc)</li>
</ul>
<p>某些 qdisc,例如 TBF,可能会延迟一段时间再将一个包发送出去,以达到期望的带宽 。这意味着它们有时即使有能力发送,也不会发送。</p>
<blockquote>
<p>有了以上概念,我们来看它们都是在哪里用到的。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">                Userspace programs</span><br><span class="line">                     ^</span><br><span class="line">                     |</span><br><span class="line">     +---------------+-----------------------------------------+</span><br><span class="line">     |               Y                                         |</span><br><span class="line">     |    -------&gt; IP Stack                                    |</span><br><span class="line">     |   |              |                                      |</span><br><span class="line">     |   |              Y                                      |</span><br><span class="line">     |   |              Y                                      |</span><br><span class="line">     |   ^              |                                      |</span><br><span class="line">     |   |  / ----------&gt; Forwarding -&gt;                        |</span><br><span class="line">     |   ^ /                           |                       |</span><br><span class="line">     |   |/                            Y                       |</span><br><span class="line">     |   |                             |                       |</span><br><span class="line">     |   ^                             Y          /-qdisc1-\   |</span><br><span class="line">     |   |                            Egress     /--qdisc2--\  |</span><br><span class="line">  ---&gt;-&gt;Ingress                       Classifier ---qdisc3---- | -&gt;</span><br><span class="line">     |   Qdisc                                   \__qdisc4__/  |</span><br><span class="line">     |                                            \-qdiscN_/   |</span><br><span class="line">     |                                                         |</span><br><span class="line">     +----------------------------------------------------------+</span><br><span class="line"></span><br><span class="line">Thanks to Jamal Hadi Salim for this ASCII representation.</span><br></pre></td></tr></table></figure>
<p>上图中的框代表 Linux 内核。最左侧的箭头表示流量从外部网络进入主机。然后进入 Ingress Qdisc,这里会对包进行过滤,根据结果决定是否要丢弃这个包。<br>这个过程称为<code>“Policing”</code>。这个过程发生在内核处理的很早阶段,在穿过大部 分内核基础设施之前。因此在这里丢弃包是很高效的,不会消耗大量 CPU。</p>
<p>如果判断允许这个包通过,那它的目的端可能是本机上的应用,这种情况下它会进入内核 IP 协议栈进行进一步处理,最后交给相应的用户态程序。<br>另外这个包的目的地也可能是其他主机上的应用,这种情况下就需要通过这台机器 Egress Classifier 再发送出去。主机程序也可能会发送数据,这种情况下也会通过 Egress Classifier 发送。</p>
<p>Egress Classifier 中会用到很多 qdisc。默认情况下只有一个:<code>pfifo_fast qdisc</code>,它永远会接收包这称为<code>“入队”</code>。</p>
<p>此时包位于 qdisc 中了,等待内核召唤,然后通过网络接口发送出去。 这称为<code>“出队”</code>。<br>以上画的是单网卡的情况。在多网卡的情况下,每个网卡都有自己的 ingress 和 egress hooks。</p>
<p><br></p>
<h1 id="使用建议-何时选择哪种队列"><a href="#使用建议-何时选择哪种队列" class="headerlink" title="使用建议:何时选择哪种队列?"></a>使用建议:何时选择哪种队列?</h1><p>总结起来上面几种都是简单的 qdisc,通过重排序(reordering)、降速(slowing)或丢包(dropping)来实现流量管理。</p>
<p>选择使用哪种 qdisc 时,下面几点可供参考。其中提到了几种在第 14 章才会介绍到的 qdisc。</p>
<ul>
<li>单纯对出向流量限速(slow down outgoing traffic),推荐使用 TBF。如果是 针对大带宽进行限速,需要将 bucket 调大。</li>
<li>如果带宽已经打满,想确保带宽没有被任何单个 session 占据,推荐使用 SFQ。</li>
<li>If you have a big backbone and know what you are doing, consider Random Early Drop (see Advanced chapter).</li>
<li>对(不再转发的)入向流量整形,使用 Ingress Policer。顺便说一句,入向整形称为 ‘policing’,而不是 ‘shaping’。</li>
<li>对需要本机转发的流量整形,<ul>
<li>如果目的端是单个设备,那在目的端设备上使用 TBF。</li>
<li>如果目的端是多个设备(同一个入向设备分流到多个目的设备),使用 Ingress Policer。</li>
</ul>
</li>
<li>如果你不需要整形,只是想看看网络接口(interface)是否过载(so loaded that it has to queue), 使用 pfifo queue(注意不是 pfifo_fast)。pfifo 内部没有 bands,但会记录 backlog 的大小。</li>
<li>最后 —— 你还可以尝试“社会学整形”(”social shaping”)。有时候一些问题是无法单纯 用技术解决的。用户会对技术限制充满敌意。和气地对别人说几句好话,也许你需要的 带宽就解决了。</li>
</ul>
<p><br><br><br></p>
<h1 id="队列和排队规则"><a href="#队列和排队规则" class="headerlink" title="队列和排队规则"></a>队列和排队规则</h1><p>通过对包进行排队,我们可以决定数据的发送方式。但理解下面这一点非常重要:我们只能对发送的数据进行整形。<br>互联网的工作机制决定了接收端无法直接控制发送端的行为。这就像你家的 (实体！)邮箱一样:除非能联系到所有人(告诉他们未经同意不要寄信给你),否则你无法控制别人寄多少东西过来。</p>
<p>但与实际生活不同的是,互联网基于TCP/IP协议栈,这多少会带来一些帮助。TCP/IP 无法提前知道两台主机之间的网络带宽,因此开始时它会以越来越快的速度发送数据(慢启 动),直到开始出现丢包,这时它知道已经没有可用空间来存储这些待发送的包了,因此就会降低发送速度。TCP/IP 的实际工作过程比这个更智能一点,后面会再讨论。</p>
<p>这就好比你留下一半的信件在实体邮箱里不取,期望别人知道这个状况后会停止给你寄新的信件。 但不幸的是,这种方式只对互联网管用,对你的实体邮箱无效 :-)</p>
<p>如果内网有一台路由器,你希望限制某几台主机的下载速度,那你应该找到发送数据到 这些主机的路由器内部接口,然后在这些 路由器内部接口上做整流。<br>此外还要确保链路瓶颈也在你的控制范围内。<br>例如如果网卡是 100Mbps,但路由器的链路带宽是 256Kbps,那首先应该确保不要发送过多数据给路由器,因为它扛不住, 否则链路控制和带宽整形的决定权就不在主机侧而到路由器侧了。</p>
<p>要达到限速目的,需要对<code>“发送队列”</code>有完全的把控,这里的<code>“发送队列”</code>也就是整条链路上最慢的一段。 幸运的是大多数情况下这个条件都是能满足的。</p>
<p><br><br><br></p>
<h1 id="简单、不分类排队规则"><a href="#简单、不分类排队规则" class="headerlink" title="简单、不分类排队规则"></a>简单、不分类排队规则</h1><p>如前所述,排队规则改变了数据的发送方式。</p>
<p>不分类(或称无类别)排队规则(classless queueing disciplines)可以对某个网络 接口(interface)上的所有流量进行无差别整形。包括对数据进行:</p>
<ul>
<li>重新调度(reschedule)</li>
<li>增加延迟(delay)</li>
<li>丢弃(drop)</li>
</ul>
<p>与 classless qdisc 对应的是 classful qdisc,即有类别(或称分类别)排队规则,后者是一个排队规则中又包含其他 排队规则(qdisc-containing-qdiscs)！先理解了 classless qdisc,才能理解 classful qdisc。</p>
<p>目前最常用的 classless qdisc 是 pfifo_fast qdisc,这也是默认排队规则。 这也解释了为什么这些高级功能如此健壮:本质上来说,它们不过是 “另一个队列”而已。<br>每种队列都有自己的优缺点。某些队列可能并未充分测试。</p>
<h2 id="pfifo-fast-先入先出队列"><a href="#pfifo-fast-先入先出队列" class="headerlink" title="pfifo_fast(先入先出队列)"></a>pfifo_fast(先入先出队列)</h2><p>如名字所示,这是一个先入先出队列(First In, First Out),因此对所有包都一视同仁</p>
<p><img src="/2022/01/23/linux-tc/pfifo_fast-qdisc.png" width="400px"></p>
<p>pfifo_fast 有三个所谓的 “band”(可理解为三个队列),编号分别为 0、1、2:</p>
<ul>
<li>每个 band 上分别执行 FIFO 规则。</li>
<li>但是如果 band 0 有数据,就不会处理 band 1；同理,band 1 有数据时, 不会去处理 band 2。</li>
<li>内核会检查数据包的 TOS 字段,将“最小延迟”的包放到 band 0。</li>
</ul>
<p>不要将 pfifo_fast qdisc 与后面介绍的 PRIO qdisc 混淆,后者是 classful 的！ 虽然二者行为类似,但 pfifo_fast 是无类别的,这意味你无法通过 tc 命令向 pfifo_fast 内添加另一个 qdisc。</p>
<h3 id="参数与用法"><a href="#参数与用法" class="headerlink" title="参数与用法"></a>参数与用法</h3><p>pfifo_fast qdisc 默认配置是写死的,因此无法更改。</p>
<p>下面介绍这份写死的配置是什么样的。</p>
<h4 id="priomap"><a href="#priomap" class="headerlink" title="priomap"></a>priomap</h4><p>priomap 决定了如何将内核设置的 packet priority 映射到 band。priority 位于包的 TOS 字段</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">   0     1     2     3     4     5     6     7</span><br><span class="line">+-----+-----+-----+-----+-----+-----+-----+-----+</span><br><span class="line">|                 |                       |     |</span><br><span class="line">|   PRECEDENCE    |          TOS          | MBZ |</span><br><span class="line">|                 |                       |     |</span><br><span class="line">+-----+-----+-----+-----+-----+-----+-----+-----+</span><br></pre></td></tr></table></figure>
<p>TOS 字段占用 4 个比特,各 bit 含义如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Binary Decimcal  Meaning</span><br><span class="line">-----------------------------------------</span><br><span class="line">1000   8         Minimize delay (md)</span><br><span class="line">0100   4         Maximize throughput (mt)</span><br><span class="line">0010   2         Maximize reliability (mr)</span><br><span class="line">0001   1         Minimize monetary cost (mmc)</span><br><span class="line">0000   0         Normal Service</span><br></pre></td></tr></table></figure>
<p><code>tcpdump -vv</code>会打印包的 TOS 字段,其中的 TOS 值对应下面的第一列:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">TOS     Bits  Means                    Linux Priority    Band</span><br><span class="line">------------------------------------------------------------</span><br><span class="line">0x0     0     Normal Service           0 Best Effort     1</span><br><span class="line">0x2     1     Minimize Monetary Cost   1 Filler          2</span><br><span class="line">0x4     2     Maximize Reliability     0 Best Effort     1</span><br><span class="line">0x6     3     mmc+mr                   0 Best Effort     1</span><br><span class="line">0x8     4     Maximize Throughput      2 Bulk            2</span><br><span class="line">0xa     5     mmc+mt                   2 Bulk            2</span><br><span class="line">0xc     6     mr+mt                    2 Bulk            2</span><br><span class="line">0xe     7     mmc+mr+mt                2 Bulk            2</span><br><span class="line">0x10    8     Minimize Delay           6 Interactive     0</span><br><span class="line">0x12    9     mmc+md                   6 Interactive     0</span><br><span class="line">0x14    10    mr+md                    6 Interactive     0</span><br><span class="line">0x16    11    mmc+mr+md                6 Interactive     0</span><br><span class="line">0x18    12    mt+md                    4 Int. Bulk       1</span><br><span class="line">0x1a    13    mmc+mt+md                4 Int. Bulk       1</span><br><span class="line">0x1c    14    mr+mt+md                 4 Int. Bulk       1</span><br><span class="line">0x1e    15    mmc+mr+mt+md             4 Int. Bulk       1</span><br></pre></td></tr></table></figure>
<p>第二列是对应的十进制表示,第三列是对应的含义。例如,15 表示这个包期望<code>Minimal Monetary Cost + Maximum Reliability + Maximum Throughput + Minimum Delay</code>。<br>我把这样的包称为<code>“荷兰包”</code>。第四列是对应到 Linux 内核的优先级；最后一列是 映射到的 band,从命令行输出看,形式为:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1, 2, 2, 2, 1, 2, 0, 0 , 1, 1, 1, 1, 1, 1, 1, 1</span><br></pre></td></tr></table></figure>
<p>例如priority 4 会映射到 band 1。priomap 还能列出 priority &gt; 7 的那些 不是由 TOS 映射、而是由其他方式设置的优先级。<br>例如下表列出了应 用(application)是如何设置它们的 TOS 字段的,来自 RFC 1349(更多信息可阅 读全文),</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">TELNET                   1000           (minimize delay)</span><br><span class="line">FTP     Control          1000           (minimize delay)</span><br><span class="line">        Data             0100           (maximize throughput)</span><br><span class="line"></span><br><span class="line">TFTP                     1000           (minimize delay)</span><br><span class="line"></span><br><span class="line">SMTP    Command phase    1000           (minimize delay)</span><br><span class="line">        DATA phase       0100           (maximize throughput)</span><br><span class="line"></span><br><span class="line">DNS     UDP Query        1000           (minimize delay)</span><br><span class="line">        TCP Query        0000</span><br><span class="line">        Zone Transfer    0100           (maximize throughput)</span><br><span class="line"></span><br><span class="line">NNTP                     0001           (minimize monetary cost)</span><br><span class="line"></span><br><span class="line">ICMP    Errors           0000</span><br><span class="line">        Requests         0000 (mostly)</span><br><span class="line">        Responses        &lt;same as request&gt; (mostly)</span><br></pre></td></tr></table></figure>
<h4 id="txqueuelen"><a href="#txqueuelen" class="headerlink" title="txqueuelen"></a>txqueuelen</h4><p>发送队列长度,是一个网络接口(interface)参数,可以用 ifconfig 命令设置。<br>例如<code>ifconfig eth0 txqueuelen 10</code>。</p>
<p>tc 命令无法修改这个值。</p>
<p><br><br><br></p>
<h2 id="TBF-Token-Bucket-Filter-令牌桶过滤器"><a href="#TBF-Token-Bucket-Filter-令牌桶过滤器" class="headerlink" title="TBF(Token Bucket Filter,令牌桶过滤器)"></a>TBF(Token Bucket Filter,令牌桶过滤器)</h2><p>TBF 是一个简单 qdisc,对于没有超过预设速率的流量直接透传,但也能容忍超过预设速率的短时抖动。<br>TBF 非常简洁,对网络和处理器都很友好。 如果只是想实现接口限速,那 TBF 是第一选择。</p>
<p><img src="/2022/01/23/linux-tc/tbf-qdisc.png" width="400px"></p>
<p>TBF 实现包括几部分:</p>
<ul>
<li>A buffer (bucket):bucket 最重要的参数是它的大小,即能容纳的 token 数量。</li>
<li>Tokens:token 会以特定的速率(specific rate)填充 bucket 缓冲区。</li>
</ul>
<p>当一个包到来时,会从 bucket 中拿到一个 token,然后收集这个包的信息,最后从 bucket 中删除这个 token。 这个算法和 token flow、data flow 结合起来,会产生三种可能的场景:</p>
<ul>
<li><code>数据速率 == token 速率</code>:每个包都能找到一个对应的token,然后直接从队列出去,没有延时(delay)。</li>
<li><code>数据速率 &lt; token 速率</code>:正常到来的数据都能及时发送出去,然后删除一个 token。 由于 token 速率大于数据速率,会产生 bucket 积压,极端情况会将 bucket 占满。如果数据速率突然高于 token 速率,就可以消耗这些积压的 token 。因此积压的 token 有一个额外好处:能够容忍短时数据速率抖动(burst)。</li>
<li><code>数据速率 &gt; token 速率</code>:token 很快就会用完,然后 TBF 会关闭(throttle )一会。这种 情况称为 overlimit(超过限制)。如果包还是源源不断地到来,就会产生丢包。<br>第三种非常重要,因为它使我们能够对数据可用的带宽进行整形(administratively shape the bandwidth)。</li>
</ul>
<p>积压的 token 使得超过限速的短时抖动数据仍然能发送,不会丢包,但持续的 overload 会导致数据不断被 delay,然后被丢弃。</p>
<blockquote>
<p>注意:在实际的实现中,token 是基于字节数,而不是包数。</p>
</blockquote>
<h3 id="参数与用法-1"><a href="#参数与用法-1" class="headerlink" title="参数与用法"></a>参数与用法</h3><p>虽然通常情况下并不需要修改 TBF 配置参数,但我们还是可以看一下有哪些。<br>首先永远可用的参数:</p>
<h4 id="limit-or-latency"><a href="#limit-or-latency" class="headerlink" title="limit or latency"></a>limit or latency</h4><ul>
<li>limit:因等待可用 token 而被放入队列的字节数。</li>
<li>latency:每个包在 TBF 中停留的最长时间。随后会基于 latency、bucket size、rate 和 peakrate(如果设置了)来计算 limit。</li>
</ul>
<h4 id="burst-buffer-maxburst"><a href="#burst-buffer-maxburst" class="headerlink" title="burst/buffer/maxburst"></a>burst/buffer/maxburst</h4><p>bucket 的大小,单位是字节。这是累积可用的 token 所支持的最大字节数。总体来说,越大的整流速率需要越大的缓冲区。要在 Intel 网卡上实现 10Mbps 整流,你至少需要 10KB 缓冲区。</p>
<p>如果缓冲区太小,可能会丢包,因为 token 到来太快导致无法放入 bucket 中。</p>
<h4 id="mpu"><a href="#mpu" class="headerlink" title="mpu"></a>mpu</h4><p>“零长度”的包占用的并不是零带宽。例如对于以太网,任何一个包的字节数不会少于 64。 Minimum Packet Unit(最小包单元)决定了一个包所使用的最小 token 量。</p>
<h4 id="rate"><a href="#rate" class="headerlink" title="rate"></a>rate</h4><p>速度旋钮(speedknob)。</p>
<blockquote>
<p>如果当前 bucket 中有 token,并且没有禁止 bucket 的 token 删除动作,那默认情况下 ,它会全速删除。如果不期望这种行为,那可以设置下面几个参数</p>
</blockquote>
<h4 id="peakrate"><a href="#peakrate" class="headerlink" title="peakrate"></a>peakrate</h4><p>如前所述,默认情况下,包到了之后只要有 token 就会被立即发送。这可能不是你期望的,尤其当 bucket 很大的时候。<br>peakrate 可指定 bucket 发送数据的最快速度。通常来说,这需要做的就是:<code>放行一个包 - 等待恰当的时长 - 放行下一个包</code>。通过计算等待时长,最终实现了 peakrate 效果。<br>但实际中由于 Unix 默认的 10ms 定时器精读限制,如果平均每个包 10K bits , 我们只能做到 1Mbps peakrate！(10Kb/10ms = 1000Kbps = 1Mbps,译注)。</p>
<h4 id="mtu-minburst"><a href="#mtu-minburst" class="headerlink" title="mtu/minburst"></a>mtu/minburst</h4><p>1Mbit/s 的 peakrate 通常并不是很有用,因为实际中的带宽要远大于此。实现更高 peakrate 的一种方式是:每个 timer tick 发送多个包,在效果上就好像我们创建了第二个 bucket！<br>这第二个 bucket 默认只有一个包(defaults to a single packet),完全算不上一个 bucket。<br>计算最大可能的 peakrate 时,用 MTU 乘以 100(更准确地说,乘以 HZ 数,例如 Intel 上是 100,Alpha 上是 1024)。</p>
<h3 id="示例配置"><a href="#示例配置" class="headerlink" title="示例配置"></a>示例配置</h3><blockquote>
<p>一个简单但非常有用的配置</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> tc qdisc add dev ppp0 root tbf rate 220kbit latency 50ms burst 1540</span><br></pre></td></tr></table></figure>
<blockquote>
<p>为什么说这个配置很有用呢？</p>
</blockquote>
<p>如果你有一个 queue 很大的网络设备,例如 DSL modem 或 cable modem,而且用一个快速设备(例如以太网接口)连接到这个网络设备,那你会发现大文件上传会严重影响实时交互。<br>这是因为上传的数据会被缓存到 modem 的 queue 里,而且缓存的数据量很大(以提升吞吐) 。但这并不是期望的,你希望的是 queue 不要太大,这样能保证交换式数据的实时性,因 此能在上传数据过程中同时做其他事情。<br>上面的配置将发送速率降低到了 modem 不会对数据进行排队缓存(queuing)的水平 —— 此时 queue 前移到了 Linux 中,而我们可以将它控制在一个合理的范围内。</p>
<p>这里的<code>220kbit</code>是上行链路的真实带宽乘以一个系数,如果你的 modem 足够快,可以将 burst 调大一些。</p>
<p><br></p>
<h2 id="SFQ-Stochastic-Fairness-Queueing-随机公平排队"><a href="#SFQ-Stochastic-Fairness-Queueing-随机公平排队" class="headerlink" title="SFQ(Stochastic Fairness Queueing,随机公平排队)"></a>SFQ(Stochastic Fairness Queueing,随机公平排队)</h2><p>随机公平排队(SFQ)是公平排队算法族的一个简单实现。<br>相比其他算法,SFQ 精准性要差一些,但它所需的计算量也更少,而结果几乎是完全公平的(almost perfectly fair)。</p>
<p><img src="/2022/01/23/linux-tc/sfq-qdisc.png" width="400px"></p>
<p>SFQ 中的核心是 conversion(会话)或 flow(流),大部分情况下都对应一个 TCP session 或 UDP stream。<br>每个 conversion 对应一个 FIFO queue,然后将流量分到不同 queue。发送数据时按照 round robin 方式,每个 session 轮流发送。</p>
<p>这种机制会产生非常公平的结果,不会因为单个 conversion 太大而把其他 conversion 的带宽都挤占掉。<br>SFQ 被称为“随机的”(stochastic)是因为它其实并没有为每个 session 分配一个 queue,而是用算法将流量哈希到了一组有限的 queue。</p>
<p>但这里会出现另一个问题:多个 session 会可能会哈希到同一个 bucket(哈希槽), 进而导致每个 session 的 quota 变小,达不到预期的整流带宽(或速度)。为避免这个问题过于明显,SFQ 会不断变换它使用的哈希算法,最终任何两个会话冲突的持续时间都不会很长,只会有几秒钟。</p>
<p>SFQ 只有在实际出向带宽已经非常饱和的情况下才有效,这一点非常重要！否则, Linux 机器上就不存在 queue,因此也就没用效果。稍后会看到如何将 SFQ 与其他 qdisc 相结合来实现一般情况下的公平排队。</p>
<p>说的更明确一点:没用配套的整流配置的话,单纯在(连接 modem 的)以太网接口上配置SFQ是毫无意义的。</p>
<h3 id="参数与用法-2"><a href="#参数与用法-2" class="headerlink" title="参数与用法"></a>参数与用法</h3><p>SFQ 大部分情况下默认参数就够了,</p>
<h4 id="perturb"><a href="#perturb" class="headerlink" title="perturb"></a>perturb</h4><p>每隔多少秒就重新配置哈希算法。如果这个参数没设,哈希算法就永远不会重新配置。 建议显式设置这个参数,不要为空。10s 可能是个不错的选择。</p>
<h4 id="quantum"><a href="#quantum" class="headerlink" title="quantum"></a>quantum</h4><p>在轮到下一个 queue 发送之前,当前 queue 允许出队(dequeue)的最大字节数。默认是一个 MTU。不建议设置为小于 MTU 的值。</p>
<h4 id="limit"><a href="#limit" class="headerlink" title="limit"></a>limit</h4><p>SFQ 能缓存的最大包数(超过这个阈值将导致丢包)。</p>
<h3 id="示例配置-1"><a href="#示例配置-1" class="headerlink" title="示例配置"></a>示例配置</h3><p>如果你有一个带宽已经饱和的网络设备,例如一个电话调制解调器(phone modem),那下面的配置有助于提高公平性</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ tc qdisc add dev ppp0 root sfq perturb 10</span><br><span class="line"></span><br><span class="line">$ tc -s -d qdisc ls</span><br><span class="line">qdisc sfq 800c: dev ppp0 quantum 1514b limit 128p flows 128/1024 perturb 10sec</span><br><span class="line"> Sent 4812 bytes 62 pkts (dropped 0, overlimits 0)</span><br></pre></td></tr></table></figure>
<p>解释:</p>
<ul>
<li><code>800c:</code>:自动分配的 handle number(句柄编号)</li>
<li><code>limit 128p</code>:最大缓存 128 个包</li>
<li><code>flows 128/1024</code>:这个 sfq 有 1024 个哈希槽(hash buckets),其中 128 个当前有 数据待发送。</li>
<li><code>perturb 10sec</code>:每隔 10s 换一次哈希算法。</li>
</ul>
<p><br><br><br></p>
<h1 id="分类别排队规则-Classful-qdisc"><a href="#分类别排队规则-Classful-qdisc" class="headerlink" title="分类别排队规则(Classful qdisc)"></a>分类别排队规则(Classful qdisc)</h1><p>如果想对不同类型的流量做不同处理,那 classful qdisc 非常有用。其中一种是 CBQ( Class Based Queueing,基于类别的排队),由于这种类型的 qdisc 使用太广泛了,导致大家将广义上基于类别的排队等同于 CBQ(identify queueing with classes solely with CBQ),但实际并非如此。</p>
<p>CBQ 只是其中最古老也是最复杂的一种。它的行为有时可能在你的意料之外。 那些钟爱 “sendmail effect” 的人可能感到震惊。</p>
<blockquote>
<p>sendmail effect:对于任何复杂的技术,没有文档的实现一定是最好的实现。<br>Any complex technology which doesn’t come with documentation must be the best available.</p>
</blockquote>
<p>接下来介绍更多关于 CBQ 及其类似 qdisc 的信息。</p>
<p><br></p>
<h2 id="Classful-qdisc-amp-class-中的-flow"><a href="#Classful-qdisc-amp-class-中的-flow" class="headerlink" title="Classful qdisc &amp; class 中的 flow"></a>Classful qdisc &amp; class 中的 flow</h2><p>当流量进入一个 classful qdisc 时,该 qdisc 需要将其发送到内部的某个 class 即需要对这个包进行“分类”。而要这个判断过程,实际上是查询所谓的“过滤器”。过滤器是在 qdisc 中被调用的,而不是其他地方,理解一点非常重要！</p>
<p>过滤器返回一个判决结果给 qdisc,qdisc 据此将包 enqueue 到合适的 class。<br>每个 subclass 可能会进一步执行其他 filters,以判断是否需要进一步处理。如果没有其他过滤器,这个 class 将把包 enqueue 到它自带的 qdisc。</p>
<p>除了能包含其他 qdisc,大部分 classful qdisc 还会执行流量整形。<br>这对包调度(packet scheduling,例如,基于 SFQ)和速率控制(rate control)都非常有用。 当高速设备(例如,以太网)连接到一个低速设备(例如一个调制解调器)时,会用到这个功能。</p>
<p>如果只运行 SFQ,那接下来不会发生什么事情,因为包会无延迟地进入和离开路由器:网卡的发送速度要远大于真实的链路速度。瓶颈不在主机中,就无法用“队列”(queue )来调度这些流量。</p>
<p><br></p>
<h2 id="qdisc大家庭-roots-handles-siblings-and-parents"><a href="#qdisc大家庭-roots-handles-siblings-and-parents" class="headerlink" title="qdisc大家庭:roots, handles, siblings and parents"></a>qdisc大家庭:roots, handles, siblings and parents</h2><ul>
<li><code>每个接口都有一个 egress &quot;root qdisc&quot;</code>。默认情况下这个 root qdisc 就是前面提到的<code>classless pfifo_fast qdisc</code>。<blockquote>
<p>回忆前面实体邮箱的类比。理论上 egress 流量是本机可控的,所以需要配备一个 qdisc 来提供这种控制能力。</p>
</blockquote>
</li>
<li>每个 qdisc 和 class 都会分配一个相应的 handle(句柄),可以指定 handle 对 qdisc 进行配置。</li>
<li>每个接口可能还会有一个 ingress qdisc,用来对入向流量执行策略(which polices traffic coming in)。<blockquote>
<p>理论上 ingress 基本是不受本机控制的,主动权在外部,所以不一定会有 qdisc。译注。</p>
</blockquote>
</li>
</ul>
<p>关于 handle</p>
<ul>
<li>每个 handle 由两部分组成,<major>:<minor>。</minor></major></li>
<li>按照惯例,root qdisc 的 handle 为 1:,这是 1:0 的简写。</li>
<li>每个 qdisc 的 minor number 永远是 0。</li>
</ul>
<p>关于 class</p>
<ul>
<li>每个 class 的 major number 必须与其 parent 一致。</li>
<li>major number 在一个 egress 或 ingress 内必须唯一。</li>
<li>minor number 在一个 qdisc 或 class 内必须唯一。</li>
</ul>
<blockquote>
<p>上面的解释有点模糊,可对照 tc(8) man page 的解释:<br>所有 qdiscs、classes 和 filters 都有 ID,这些 ID 可以是指定的,也可以是自动分的。<br>ID 格式 major:minor,major 和 minor 都是 16 进制数字,不超过 2 字节。 两个特殊值:</p>
<ul>
<li>root 的 major 和 minor 初始化全 1。</li>
<li>省略未指定的部分将为全 0。</li>
</ul>
</blockquote>
<p>下面分别介绍以上三者的 ID 规范。</p>
<ul>
<li>qdisc:qdisc 可能会有 children。<ul>
<li>major 部分:称为 handle,表示的 qdisc 的唯一性。</li>
<li>minor 部分:留给 class 的 namespace。</li>
</ul>
</li>
<li>class:class 依托在 qdisc 内,<ul>
<li>major 部分:继承 class 所在的 qdisc 的 major。</li>
<li>minor 部分:称为 classid,在所在的 qdisc 内唯一就行。</li>
</ul>
</li>
<li>filter:由三部分构成,只有在使用 hashed filter hierarchy 时才会用到。</li>
</ul>
<h3 id="如何用过滤器-filters-对流量进行分类"><a href="#如何用过滤器-filters-对流量进行分类" class="headerlink" title="如何用过滤器(filters )对流量进行分类"></a>如何用过滤器(filters )对流量进行分类</h3><p>综上一个典型的 handle 层级如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">          1:   root qdisc</span><br><span class="line">           |</span><br><span class="line">          1:1    child class</span><br><span class="line">        /  |  \</span><br><span class="line">       /   |   \</span><br><span class="line">      /    |    \</span><br><span class="line">      /    |    \</span><br><span class="line">   1:10  1:11  1:12   child classes</span><br><span class="line">    |      |     |</span><br><span class="line">    |     11:    |    leaf class</span><br><span class="line">    |            |</span><br><span class="line">    10:         12:   qdisc</span><br><span class="line">   /   \       /   \</span><br><span class="line">10:1  10:2   12:1  12:2   leaf classes</span><br></pre></td></tr></table></figure>
<p>但不要被这棵树迷惑！不要以为内核位于树的顶点,网络位于下面。包只会通过 root qdisc 入队或出队,这也是内核唯一与之交互的部分。<br>一个包可能会被链式地分类如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1: -&gt; 1:1 -&gt; 1:12 -&gt; 12: -&gt; 12:2</span><br></pre></td></tr></table></figure>
<p>最后到达 attach 到<code>class 12:2</code>的 qdisc 的队列。<br>在这个例子中树的每个<code>“节点”</code>( node)上都 attach 了一个 filter,每个 filter 都会给出一个判断结果,根据判断结果 选择一个合适的分支将包发送过去。<br>这是常规的流程。但下面这种流程也是有可能的:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1: -&gt; 12:2</span><br></pre></td></tr></table></figure>
<p>在这种情况下,attach 到 root qdisc 的 filter 决定直接将包发给 12:2。</p>
<h3 id="包是如何从-qdisc-出队-dequeue-然后交给硬件的"><a href="#包是如何从-qdisc-出队-dequeue-然后交给硬件的" class="headerlink" title="包是如何从 qdisc 出队(dequeue)然后交给硬件的"></a>包是如何从 qdisc 出队(dequeue)然后交给硬件的</h3><p>当内核决定从 qdisc dequeue packet 交给接口(interface)发送时,它会</p>
<ul>
<li>向 root qdisc<code>1:</code>发送一个 dequeue request</li>
<li><code>1:</code>会将这个请求转发给<code>1:1</code>,后者会进一步向下传递,转发给<code>10:</code>、<code>11:</code>、<code>12:</code></li>
<li>每个 qdisc 会查询它们的 siblings,并尝试在上面执行 dequeue() 方法。</li>
</ul>
<p>在这个例子中,内核需要遍历整棵树,因为只有<code>12:2</code>中有数据包。</p>
<p>简单来说,嵌套类只会和它们的 parent qdiscs 通信,而永远不会直 接和接口交互。<code>内核只会调用 root qdisc</code>的<code>dequeue()</code>方法！<br>最终结果是,classes dequeue 的速度永远不会超过它们的 parents 允许的速度。而这正 是我们所期望的:这样就能在内层使用一个 SFQ 做纯调度,它不用做任何整形的工作;然后在外层使用一个整形 qdisc 专门负责整形。</p>
<p><br><br><br></p>
<h2 id="PRIO-qdisc-优先级排队规则"><a href="#PRIO-qdisc-优先级排队规则" class="headerlink" title="PRIO qdisc(优先级排队规则)"></a>PRIO qdisc(优先级排队规则)</h2><p><code>PRIO</code>qdisc 实际上不会整形行,只会根据设置的过滤器对流量分类。</p>
<p><img src="/2022/01/23/linux-tc/prio-qdisc-1.gif" width="600px"></p>
<p>可以将<code>PRIO qdisc</code>理解为<code>pfifo_fast qdisc</code>的升级版,它也有多个band,但 每个 band 都是一个独立的 class,而不是简单的 FIFO。</p>
<p><img src="/2022/01/23/linux-tc/prio-qdisc-2.gif" width="600px"></p>
<p>当一个包 enqueue 到 PRIO qdisc 之后,它会根据设置的 filters 选择一个 class ,并将包送到这个 class。默认情况下会创建三个 class。每个 class 默认情况下都包含一个纯 FIFO qdisc,没有其他内部结构,但你可以用其他类型的 qdisc 替换掉 FIFO。</p>
<p>当从 PRIO qdisc 取出(dequeue)一个包时,会先尝<code>:1</code>。只有 lower bands/classes 没有数据包可取时,才会尝试 higher classes。</p>
<p>如果想基于 tc filters 而不仅仅是 TOS flags 做流量优先级分类时,这个 qdisc 会非常 有用。还可以向这三个预置的 classes 添加额外的 qdisc,毕竟 pfifo_fast 只能提供简单的 FIFO qdisc。</p>
<p>由于 PRIO 没有流量整形功能,因此针对 SFQ 的忠告也适用于这里:</p>
<ul>
<li>如果你的物理链路已经打满了,可以用 PRIO qdisc (对流量进行分类),或者</li>
<li>在外层嵌套一个 classful qdisc,后者负责流量整形。<br>用正式的术语来说,PRIO qdisc 是一个 work-conserving 调度器(随到随发)。</li>
</ul>
<h3 id="参数与用法-3"><a href="#参数与用法-3" class="headerlink" title="参数与用法"></a>参数与用法</h3><p>下面几个参数能被 tc 识别:</p>
<ul>
<li><p>bands<br>需要创建的 band 数量。这个每个 band 实际上都是一个 class。如果改变这个配置, 还需要同时修改 priomap 参数。</p>
</li>
<li><p>priomap<br>如果没有提供 tc filters 来指导如何对流量分类,那 PRIO qdisc 将依据 TC_PRIO 优先级来决定优先级。这里的工作方式与 pfifo_fast qdisc 是类似的, 更多细节可以参考前面的 pfifo_fast 小节。<br>PRIO qdisc 里面的 band 都是 class,默认情况下名字分别为 major:1、 major:2、 major:3, 因此如果你的 PRIO qdisc 是 12:,那 tc filter 送到 12:1 的流量就有更高的优先级。<br>重复一遍:band 0 对应的 minor number 是 1！ band 1 对应的 minor number 是 2 ,以此类推。</p>
</li>
</ul>
<h3 id="示例配置-2"><a href="#示例配置-2" class="headerlink" title="示例配置"></a>示例配置</h3><p>我们将创建一棵如下所示的树</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">          1:   root qdisc</span><br><span class="line">         / | \</span><br><span class="line">        /  |  \</span><br><span class="line">       /   |   \</span><br><span class="line">     1:1  1:2  1:3    classes</span><br><span class="line">      |    |    |</span><br><span class="line">     10:  20:  30:    qdiscs    qdiscs</span><br><span class="line">     sfq  tbf  sfq</span><br><span class="line">band  0    1    2</span><br></pre></td></tr></table></figure>
<p>高吞吐流量将送到<code>30:</code>,交互式流量(interactive traffic)将送到<code>20:</code>或<code>10:</code>。</p>
<blockquote>
<p>命令行</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> tc qdisc add dev eth0 root handle 1: prio # This *instantly* creates classes 1:1, 1:2, 1:3</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span> tc qdisc add dev eth0 parent 1:1 handle 10: sfq</span><br><span class="line"><span class="meta">$</span> tc qdisc add dev eth0 parent 1:2 handle 20: tbf rate 20kbit buffer 1600 limit 3000</span><br><span class="line"><span class="meta">$</span> tc qdisc add dev eth0 parent 1:3 handle 30: sfq</span><br></pre></td></tr></table></figure>
<p>然后查看创建出来的 qdisc:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> tc -s qdisc ls dev eth0</span><br><span class="line">qdisc sfq 30: quantum 1514b</span><br><span class="line"> Sent 0 bytes 0 pkts (dropped 0, overlimits 0)</span><br><span class="line"></span><br><span class="line"> qdisc tbf 20: rate 20Kbit burst 1599b lat 667.6ms</span><br><span class="line"> Sent 0 bytes 0 pkts (dropped 0, overlimits 0)</span><br><span class="line"></span><br><span class="line"> qdisc sfq 10: quantum 1514b</span><br><span class="line"> Sent 132 bytes 2 pkts (dropped 0, overlimits 0)</span><br><span class="line"></span><br><span class="line"> qdisc prio 1: bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1</span><br><span class="line"> Sent 174 bytes 3 pkts (dropped 0, overlimits 0)</span><br></pre></td></tr></table></figure>
<p>可以看到,band 0 已经有了一些流量,而且在执行这条命令的过程中,刚好又发送了一个 包！<br>现在我们来用 scp 命令传输一些数据,它会自动设置 TOS flags</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> scp tc ahu@10.0.0.11:./</span><br><span class="line">ahu@10.0.0.11's password:</span><br><span class="line">tc                   100% |*****************************|   353 KB    00:00</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span> tc -s qdisc ls dev eth0</span><br><span class="line">qdisc sfq 30: quantum 1514b</span><br><span class="line"> Sent 384228 bytes 274 pkts (dropped 0, overlimits 0)</span><br><span class="line"></span><br><span class="line"> qdisc tbf 20: rate 20Kbit burst 1599b lat 667.6ms</span><br><span class="line"> Sent 2640 bytes 20 pkts (dropped 0, overlimits 0)</span><br><span class="line"></span><br><span class="line"> qdisc sfq 10: quantum 1514b</span><br><span class="line"> Sent 2230 bytes 31 pkts (dropped 0, overlimits 0)</span><br><span class="line"></span><br><span class="line"> qdisc prio 1: bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1</span><br><span class="line"> Sent 389140 bytes 326 pkts (dropped 0, overlimits 0)</span><br></pre></td></tr></table></figure>
<p>可以看到,所有的流量都进入了优先级最低的 handle<code>30:</code>,这正是我们期望的。为了验证交互式流量会进入优先级更高的 bands,我们可以生成一些交互式流量。 然后再来查看统计</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> tc -s qdisc ls dev eth0</span><br><span class="line">qdisc sfq 30: quantum 1514b</span><br><span class="line"> Sent 384228 bytes 274 pkts (dropped 0, overlimits 0)</span><br><span class="line"></span><br><span class="line"> qdisc tbf 20: rate 20Kbit burst 1599b lat 667.6ms</span><br><span class="line"> Sent 2640 bytes 20 pkts (dropped 0, overlimits 0)</span><br><span class="line"></span><br><span class="line"> qdisc sfq 10: quantum 1514b</span><br><span class="line"> Sent 14926 bytes 193 pkts (dropped 0, overlimits 0)</span><br><span class="line"></span><br><span class="line"> qdisc prio 1: bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1</span><br><span class="line"> Sent 401836 bytes 488 pkts (dropped 0, overlimits 0)</span><br></pre></td></tr></table></figure>
<p>正如预期 —— 所有额外流量都进入了<code>10:</code>,这是我们优先级最高的 qdisc。handle<code>30:</code>的流量这次没有增长,而刚才它吸收了所有的 scp 流量。</p>
<p><br><br><br></p>
<h2 id="著名的-CBQ-Class-Based-Queueing-qdisc"><a href="#著名的-CBQ-Class-Based-Queueing-qdisc" class="headerlink" title="著名的 CBQ(Class Based Queueing)qdisc"></a>著名的 CBQ(Class Based Queueing)qdisc</h2><p>前面提到,CBQ(Class Based Queueing,基于类的排队) 是最复杂、最花哨、最少被理 解、也可能是最难用对的 qdisc。这并非因为它的发明者都是魔鬼或者能力不够,而是因为 CBQ 算法经常不够精确,而这是由于它与 Linux 的工作方式不是太匹配造成的。</p>
<p>除了是 classful qdisc 之外,CBQ 还是一个整流器(shaper),作为一个整流器来说, 其实它工作地并不是非常理想。理想的工作方式应该是这样的:如果想将一个 10Mbps 的连 接整形为 1Mbps,那这条链路应该有 90% 的时间是空闲的。否则,我们就需要 throttle 来确保链路 90% 的时间是空闲的。</p>
<p>但空闲时间是很难测量的,CBQ 的方式是:用硬件层连续两次请求数据的时间间隔(毫秒)来推算。这可以用来近似估计链路的空闲状态(how full or empty the link is)。<br>这种测量方式是非常间接的,因此结果并不总是很准确。<br>例如接口的物理带宽是 100Mbps ,但它可能永远打不到 100Mbps,而原因可能是网卡驱动写的太烂。另一个例子,PCMCIA 网卡永远打不到 100Mbps,这是由于其总线设计导致的,因此又回到那个问题:应该 如何计算空闲时间？</p>
<p>当考虑到非纯物理网络设备(not-quite-real network devices)时,例如 PPP over Ethernet 或 PPTP over TCP/IP,情况会更加糟糕。在这些场景中,有效带 宽可能是由到用户空间的管道(pipe)效率决定的 —— 这个值可能很高。<br>真正测量过的人会发现,CBQ 并不是永远很精确,有时甚至完全偏离了真实值。<br>但在某些场景下,CBQ 能很好地满足需求。基于本文的介绍,你应该能恰当地配置 CBQ,使其在大部分情况下都工作良好。</p>
<h3 id="CBQ-shaping-详解"><a href="#CBQ-shaping-详解" class="headerlink" title="CBQ shaping 详解"></a>CBQ shaping 详解</h3><p>如前所述,CBQ 的工作原理是:在发送包之前等待足够长的时间,以将带宽控制到期望的阈值。为实现这个目标,它需要计算包之间的等待间隔。</p>
<p>系统在运行过程中会计算一个有效空闲时间(effective idletime):用指数加权移动平均( exponential weighted moving average,EWMA)来计算,这个算法假设包的优先级大小 是指数变化的,越近的包(recent packets)优先级越高。UNIX 的 loadaverage 指标 就是用的这个算法。</p>
<p>平均空闲时间(<code>avgidle</code>)的定义:<code>avgidle = 有效空闲时间(EWMA)- 计算出的空闲时间</code>,</p>
<ul>
<li>理想的未过载链路(loaded link):avgidle = 0,每经过精确地计算出的时间间隔,就有一个数据 包到来(packets arrive exactly once every calculated interval)。</li>
<li>过载链路(overloaded link):avgidle &lt; 0,如果这个负值变得太大,CBQ 会关闭一 会,表示超出限制了(overlimit)。</li>
<li>空闲链路(idle link):avgidle &lt; 0,而且这个值可能会非常大,这可能会导致 累积几个小时之后,算法允许无限大的带宽(infinite bandwidths after a few hours of silence)。 为防止这种情况发生,avgidle 会设置一个上限(maxidle)。</li>
</ul>
<p>如果发生 overlimit,理论上 CBQ 会严格等待 calculated_idletime,然后才发生下一个包,然后再次 throttle 自己。<br>但此时也要注意 minburst 参数,见下面。</p>
<blockquote>
<p>下面是整形(shaping)相关的配置参数</p>
</blockquote>
<ul>
<li><p>avpkt<br>平均包长,单位是字节。计算 maxidle 时会用到。</p>
</li>
<li><p>bandwidth<br>设备的物理带宽,计算 idle time 时会用到。</p>
</li>
<li><p>cell<br>包长的增长步长。设备发送不同长度的包时,耗时可能是不一样的,与包长有关。 例如,一个 800Byte 和一个 806Byte 的包所花的发送时间可能是一样的。默认值通常是 8,必须是 2 的幂次。</p>
</li>
<li><p>maxburst<br>计算 maxidle 时用到,单位:包数(number of packets)。<br>当 avgidle == maxidle 时,可以并发发送 maxburst 个包,直到 avgidle == 0。 注意 maxidle 是无法直接设置的,只能通过这个参数间接设置。</p>
</li>
<li><p>minburst<br>前面提到,overlimit 情况下 CBQ 要执行 throttle。理想情况下是精确 throttle calculated idel time,然后发送一个包。但对 Unix 内核来说,通常很难调度 10ms 以下精度的事件,因此最好的方式就是 throttle 更长一段时间,然后一次发 送 minburst 个包,然后再睡眠 minburst 倍的时间。<br>The time to wait is called the offtime。从较长时间跨度看,更大的 minburst 会使得整形更加精确,但会导致在毫秒级别有更大的波动性。</p>
</li>
<li><p>minidle<br>如果 avgidle &lt; 0,那说明 overlimits,需要等到 avgidle 足够大才能发送下一个包。 为防止突然的 burst 打爆链路带宽,当 avgidle 降到一个非常小的值之后,会 reset 到 minidle。 minidle 的单位是负微秒(negative microseconds),因此 10 就表示 idle time 下限是 -10us。</p>
</li>
<li><p>mpu<br>最小包长(Minimum packet size)—— 需要这个参数是因为,即使是零字节的包在以太 网上传输时也会被填充到 64 字节,因此总会有一个发送耗时。 CBQ 需要这个参数来精确计算 idle time。</p>
</li>
<li><p>rate<br>期望的离开这个 qdisc 的流量速率(rate of traffic)—— 这就是“速度旋钮”(speed knob)！</p>
</li>
</ul>
<p>在内部 CBQ 有很多优化。例如在 dequeue 包时,已经明确知道没有数据的 class 都会跳过。<br>Overlimit 的 class 会通过降低其有效优先级(effective priority)的方式进行惩罚。 所有这些都是很智能也很复杂的。</p>
<p><br></p>
<h3 id="CBQ-classful-behaviour"><a href="#CBQ-classful-behaviour" class="headerlink" title="CBQ classful behaviour"></a>CBQ classful behaviour</h3><p>除了整形之外,基于前面提到的 idletime 近似,CBQ 也能完成类似 PRIO queue 的功能 ,因为 class 可以有不同优先级,优先级高的总是限于优先级低的被 poll。<br>每次硬件层请求一个数据包来发送时,都会开启一个 weighted round robin (WRR)过程, 从优先级最高的 class 开始(注意,优先级越高对应的 priority number 越小)。<br>优先级相同的 class 会作为一组,依次判断它们是否有数据要发送。</p>
<p>下列参数控制 WRR 过程:</p>
<ul>
<li><p>allot<br>当外层 CBQ 收到网卡要发送一个数据包的请求后,它会按照 prio 参数指定的 优先级,尝试依次 classes 内 attach 的所有内部 qdiscs。 每个 class 被轮到时, 它只能发送有限的一些数据。alloct 就是这个数据量的一个基本单位。更多信息参见 weight 参数。</p>
</li>
<li><p>prio<br>CBQ 也能执行与 PRIO 设备一样的行为。内部 classes 都有一个优先级 prio,高 优先级的会先于低优先级的被 poll。</p>
</li>
<li><p>weight<br>这个参数用于 WRR 过程。每个 class 都有机会发送数据。如果要指定某个 class 使 用更大的带宽,就调大其 weight。<br>CBQ 会将一个 class 内的所有权重归一化,因此指定用整数还是小数都没关系:重要 的是比例。大家的经验值是 “rate/10”,这个值看上去工作良好。归一化后的 weight 乘以 allot,决定了每次能发送的数据量。</p>
</li>
</ul>
<blockquote>
<p>注意:CBQ 层级内的所有 class 要共享同一个 major number！</p>
</blockquote>
<p><br></p>
<h3 id="决定-link-sharing-amp-borrowing-的-CBQ-参数"><a href="#决定-link-sharing-amp-borrowing-的-CBQ-参数" class="headerlink" title="决定 link sharing &amp; borrowing 的 CBQ 参数"></a>决定 link sharing &amp; borrowing 的 CBQ 参数</h3><p>除了限制特定类型的流量,还能指定哪些 class 能从另外哪些 class 借容量(borrow capacity)或者说,借带宽(对前一种 class 来说是借入,对后一种 class 来说就是借出)。</p>
<ul>
<li><p>isolated/sharing<br>配置了 isolated 的 class 不会向 sibling classes 借出带宽。如果多个应用 之间在链路利用上是竞争或互斥的,彼此不想给对方带宽,那可以用这个配置。<br>tc 工具还有一个 sharing 配置,作用于 isolated 相反。</p>
</li>
<li><p>bounded/borrow<br>也可以配置 class 为 bounded,这表示它不会向其他 siblings 借带宽。<br>tc 工具还支持一个 borrow 选项,作用于 bounded 相反。</p>
</li>
</ul>
<p>一个典型场景可能是:同一个链路上有两个应用,二者都是 isolated + bounded ,这表示二者都只会限制在它们各自分配的速率内,不会互相借带宽。<br>有了这样的 agency class(代理类),可能还会有其他允许交换带宽的 class。</p>
<p><br></p>
<h3 id="示例配置-3"><a href="#示例配置-3" class="headerlink" title="示例配置"></a>示例配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">      1:           root qdisc</span><br><span class="line">      |</span><br><span class="line">     1:1           child class</span><br><span class="line">    /   \</span><br><span class="line">   /     \</span><br><span class="line"> 1:3     1:4       leaf classes</span><br><span class="line">  |       |</span><br><span class="line"> 30:     40:       qdiscs</span><br><span class="line">(sfq)   (sfq)</span><br></pre></td></tr></table></figure>
<p>这个例子将</p>
<ul>
<li>webserver 限制为5Mbps。</li>
<li>SMTP 流量限制到 3Mbps。</li>
<li>webserver + SMTP 总共不超过6Mbps。</li>
<li>物理网卡是 100Mbps。</li>
<li>每个 class 之间可以互借带宽。</li>
</ul>
<p>命令<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> tc qdisc add dev eth0 root handle 1:0 cbq bandwidth 100Mbit         \</span><br><span class="line">  avpkt 1000 cell 8</span><br><span class="line"><span class="meta">$</span> tc class add dev eth0 parent 1:0 classid 1:1 cbq bandwidth 100Mbit  \</span><br><span class="line">  rate 6Mbit weight 0.6Mbit prio 8 allot 1514 cell 8 maxburst 20      \</span><br><span class="line">  avpkt 1000 bounded</span><br></pre></td></tr></table></figure></p>
<p>上面两条命令创建了 root qdisc 和相应的<code>1:1</code>class。这个<code>1:1</code>class 是 bounded 类型,因此总带宽不会超过设置的 6Mbps 限制。<br>如前所述CBQ 需要很多速度选项(knobs,旋钮式开关)。但用到的参数前面都介绍过了。如果 HTB 来实现这个功能,就会简单很多。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> tc class add dev eth0 parent 1:1 classid 1:3 cbq bandwidth 100Mbit  \</span><br><span class="line">  rate 5Mbit weight 0.5Mbit prio 5 allot 1514 cell 8 maxburst 20      \</span><br><span class="line">  avpkt 1000</span><br><span class="line"><span class="meta">$</span> tc class add dev eth0 parent 1:1 classid 1:4 cbq bandwidth 100Mbit  \</span><br><span class="line">  rate 3Mbit weight 0.3Mbit prio 5 allot 1514 cell 8 maxburst 20      \</span><br><span class="line">  avpkt 1000</span><br></pre></td></tr></table></figure>
<p>上面两个创建的是叶子节点(leaf classes)。注意其中是如何配置速率的。<br>两个 class 都没有配置 bounded 参数,但它们都连着到了 1:1 class,后者是有限速不超过6Mbps 的。因此这两个 leaf class 的总带宽不会超过6Mbps。<br>另外需要注意classid 中的 major number 必须要和 parent qdisc 中的 major number 一样！</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> tc qdisc add dev eth0 parent 1:3 handle 30: sfq</span><br><span class="line"><span class="meta">$</span> tc qdisc add dev eth0 parent 1:4 handle 40: sfq</span><br></pre></td></tr></table></figure>
<p>每个 class 默认都有一个 FIFO qdisc。<br>但我们将其替换成了 SFQ 这样每条 flow 都能被独立、平等对待了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> tc filter add dev eth0 parent 1:0 protocol ip prio 1 u32 match ip \</span><br><span class="line">  sport 80 0xffff flowid 1:3</span><br><span class="line"><span class="meta">$</span> tc filter add dev eth0 parent 1:0 protocol ip prio 1 u32 match ip \</span><br><span class="line">  sport 25 0xffff flowid 1:4</span><br></pre></td></tr></table></figure>
<p>这些过滤规则直接作用在 root qdisc 上,作用是将流量分类到下面正确的 qdisc。<br>注意其中是先用 tc class add 命令往 qdisc 内添加 class,然后又用 tc qdisc add命令向 class 内添加 qdisc。</p>
<blockquote>
<p>你可能会好奇:没有匹配到以上两条规则的流量怎么办？</p>
</blockquote>
<p>在本例中它们会进入 1:0 接受处理,而这里是没有限速的。<br>如果SMTP+web的总带宽超过6Mbps,那总带宽将根据给定的权重参数分为两部分, 5/8 给 webserver,3/8 给邮件服务。<br>也可以说在这个配置下,webserver 流量在任何时候至少能获得<code>5/8 * 6Mbps = 3.75Mbps</code>带宽。</p>
<p><br><br><br></p>
<h2 id="HTB-Hierarchical-Token-Bucket-层级令牌桶"><a href="#HTB-Hierarchical-Token-Bucket-层级令牌桶" class="headerlink" title="HTB(Hierarchical Token Bucket,层级令牌桶)"></a>HTB(Hierarchical Token Bucket,层级令牌桶)</h2><p>Martin Devera (devik) 意识到 CBQ 太复杂了,并且没有针对很多典型的场景进行优化。因此他设计了 HTB,这种层级化的方式对下面这些场景很适用:</p>
<ul>
<li>有一个固定总带宽,想将其分割成几个部分,分别用作不同目的</li>
<li>每个部分的带宽是有保证的(guaranteed bandwidth)</li>
<li>还可以指定每个部分向其他部分借带宽</li>
</ul>
<p><img src="/2022/01/23/linux-tc/htb-borrow.png" width="600px"></p>
<p>HTB 的工作方式与 CBQ 类似,但不是借助于计算空闲时间(idle time)来实现整形。 在内部,它其实是一个 classful TBF(令牌桶过滤器)这也是它叫层级令牌桶(HTB)的原因。HTB 的参数并不多,在它的网站文档 里都已经写的很明确了。</p>
<p>即使发现你的 HTB 配置越来越复杂,这些配置还是能比较好地扩展(scales well)。<br>而使用 CBQ 的话,即使在简单场景下配置就很复杂了！ HTB3(HTB 的不同版本参见其官方文档)现在已经并入正式内核了。<br>但你可能还是要应用一个tc的patch:HTB 内核和用户空间模块的主版本号必须相同,否则 tc HTB 无法正常工作。</p>
<p>如果使用的内核版本已经支持 HTB,那非常建议用用看。</p>
<h3 id="示例配置-4"><a href="#示例配置-4" class="headerlink" title="示例配置"></a>示例配置</h3><p>功能几乎与前面的 CBQ 示例配置一样的 HTB 配置:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> tc qdisc add dev eth0 root handle 1: htb default 30</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span> tc class add dev eth0 parent 1: classid 1:1 htb rate 6mbit burst 15k</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span> tc class add dev eth0 parent 1:1 classid 1:10 htb rate 5mbit burst 15k</span><br><span class="line"><span class="meta">$</span> tc class add dev eth0 parent 1:1 classid 1:20 htb rate 3mbit ceil 6mbit burst 15k</span><br><span class="line"><span class="meta">$</span> tc class add dev eth0 parent 1:1 classid 1:30 htb rate 1kbit ceil 6mbit burst 15k</span><br></pre></td></tr></table></figure>
<p>HTB 作者推荐在这些 class 内部使用 SFQ:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> tc qdisc add dev eth0 parent 1:10 handle 10: sfq perturb 10</span><br><span class="line"><span class="meta">$</span> tc qdisc add dev eth0 parent 1:20 handle 20: sfq perturb 10</span><br><span class="line"><span class="meta">$</span> tc qdisc add dev eth0 parent 1:30 handle 30: sfq perturb 10</span><br></pre></td></tr></table></figure>
<p>最后将流量导向这些 class 的过滤器(filters):</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> U32="tc filter add dev eth0 protocol ip parent 1:0 prio 1 u32"</span><br><span class="line"><span class="meta">$</span> $U32 match ip dport 80 0xffff flowid 1:10</span><br><span class="line"><span class="meta">$</span> $U32 match ip sport 25 0xffff flowid 1:20</span><br></pre></td></tr></table></figure>
<p><br></p>
<h1 id="用过滤器对流量进行分类"><a href="#用过滤器对流量进行分类" class="headerlink" title="用过滤器对流量进行分类"></a>用过滤器对流量进行分类</h1><p>每次要判断将包送到哪个 class 进行处理时,都会调用所谓的<code>“classifier chain”</code>(分类器链)。这个 chain 由 attach 到 classful qdisc 的所有 filter 构成。<br>还是前面那个例子(包最终到<code>12:2</code>)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">         root 1:</span><br><span class="line">           |</span><br><span class="line">         _1:1_</span><br><span class="line">        /  |  \</span><br><span class="line">       /   |   \</span><br><span class="line">      /    |    \</span><br><span class="line">    10:   11:   12:</span><br><span class="line">   /   \       /   \</span><br><span class="line">10:1  10:2   12:1  12:2</span><br></pre></td></tr></table></figure>
<p>当 enqueue 一个包时,在每一个分叉的地方都需要查询相关的过滤规则。</p>
<p>一种典型的配置是:</p>
<ul>
<li>在 1:1 配置一个 filter,将包送到 12:。</li>
<li>在 12: 配置一个 filter,将包送到12:2。</li>
</ul>
<p>另外一种配置:将两个 filters 都配置在<code>1:1</code>,但将更精确的 filter 下放到更下面的位置有助于提升性能。<br>需要注意的是,包是无法向上过滤的。 另外使用 HTB 时,所有的 filters 必须 attach 到 root！<br>包只能向下 enqueue！当 dequeue 时,它们会重新上来,到达要发送它的网络接口。 包并不是一路向下,最后从叶子节点到达网卡的！</p>
<p><br></p>
<h2 id="一些简单的流量过滤-filtering-示例"><a href="#一些简单的流量过滤-filtering-示例" class="headerlink" title="一些简单的流量过滤(filtering)示例"></a>一些简单的流量过滤(filtering)示例</h2><p>正如在 Classifier 章节中介绍的,匹配语法非常复杂,但功能强大,可以对几乎任何东西进行匹配。<br>这里先从简单的开始。假设有一个名为<code>10:</code>的 PRIO qdisc,其中包含了三个 class,我们想将所有端口 22 的流量都导向优先级最高的band,那 filters 将如下:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> tc filter add dev eth0 protocol ip parent 10: prio 1 u32 match \</span><br><span class="line">  ip dport 22 0xffff flowid 10:1</span><br><span class="line"><span class="meta">$</span> tc filter add dev eth0 protocol ip parent 10: prio 1 u32 match \</span><br><span class="line">  ip sport 80 0xffff flowid 10:1</span><br><span class="line"><span class="meta">$</span> tc filter add dev eth0 protocol ip parent 10: prio 2 flowid 10:2</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这几行命令是什么意思？第一条命令</p>
</blockquote>
<ul>
<li><code>tc filter add dev eth0</code>:attach 到 eth0 设备。</li>
<li><code>parent 10:</code>:父设备是<code>10:</code>。</li>
<li><code>prio 1</code>优先级为 1(数字越小,优先级越高)。</li>
<li><code>u32 match ip dport 22 0xffff filter</code>:精确匹配 dst port 22,并将匹配的包发送到 band<code>10:1</code>。</li>
</ul>
<p>第二条命令与第一条类似,不过匹配的源端口 80。第三条命令表示所有未匹配到上面的包 ,都发送到优先级次高的 band<code>10:2</code>。<br>上面的命令中需要指定网络接口(interface),因为每个接口都有自己独立的 handle 空间。<br>要精确匹配单个 IP 地址,使用下面的命令:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> tc filter add dev eth0 parent 10:0 protocol ip prio 1 u32 \</span><br><span class="line">  match ip dst 4.3.2.1/32 flowid 10:1</span><br><span class="line"><span class="meta">$</span> tc filter add dev eth0 parent 10:0 protocol ip prio 1 u32 \</span><br><span class="line">  match ip src 1.2.3.4/32 flowid 10:1</span><br><span class="line"><span class="meta">$</span> tc filter add dev eth0 protocol ip parent 10: prio 2      \</span><br><span class="line">  flowid 10:2</span><br></pre></td></tr></table></figure>
<p>这会将<code>dst_ip=4.3.2.1</code>或<code>src_ip=1.2.3.4</code>的流量送到优先级最高的队列,其他流量送到优先级次高的队列。<br>还可以将多个 match 级联起来,同时匹配源 IP 和 port:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> tc filter add dev eth0 parent 10:0 protocol ip prio 1 u32 match ip src 4.3.2.1/32 \</span><br><span class="line">  match ip sport 80 0xffff flowid 10:1</span><br></pre></td></tr></table></figure>
<p><br></p>
<h2 id="常用-filtering-命令"><a href="#常用-filtering-命令" class="headerlink" title="常用 filtering 命令"></a>常用 filtering 命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tc filter add dev eth0 parent 1:0 protocol ip prio 1 u32 ..</span><br></pre></td></tr></table></figure>
<p>这种是所谓的 u32 匹配,特点是能匹配包的任何部分:</p>
<ul>
<li>匹配源/目的 IP 地址<ul>
<li><code>match ip src 1.2.3.0/24</code></li>
<li><code>match ip dst 4.3.2.0/24</code></li>
<li>匹配单个 IP:指定掩码 /32,或者直接省略掩码部分</li>
</ul>
</li>
<li>匹配源/目的端口,任何 IP 协议<ul>
<li><code>match ip sport 80 0xffff</code></li>
<li><code>match ip dport 80 0xffff</code></li>
</ul>
</li>
<li>匹配 ip protocol(tcp, udp, icmp, gre, ipsec)<br>  使用<code>/etc/protocols</code>里面的协议号,例如ICMP 是<code>1</code>:<code>match ip protocol 1 0xff</code>。</li>
<li><p>匹配 fwmark<br>  可以用 ipchains/iptables 等工具对包打标(mark),这些 mark 在不同接口 之间路由时是不会丢失的(survive routing across interfaces)。这非常有用,例 如,实现“只对从 eth0 进入 eth1 的流量进行整形”的功能。语法:</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> tc filter add dev eth1 protocol ip parent 1:0 prio 1 handle 6 fw flowid 1:1</span><br></pre></td></tr></table></figure>
<p>注意这里用的已经不是 u32 匹配了！<br>对包打标(mark):</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> iptables -A PREROUTING -t mangle -i eth0 -j MARK --set-mark 6</span><br></pre></td></tr></table></figure>
<p>  上面的 6 只是本例随便设置的一个数字,可以是任意值。<br>  如果不想理解完整的 tc filter 语法,那可以选择用 iptables 来打标,根据fwmark 完成分类功能。<br>  iptables 还可以打印统计信息,有助于判断你设置的规则是否生效。下面的命令会打 印 mangle 表内所有的 mark 规则,已经每个规则已经匹配到多少包和字节数:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -L -t mangle -n -v</span><br></pre></td></tr></table></figure>
</li>
<li><p>匹配 TOS 字段<br>  选择交互式、最小延迟(interactive, minimum delay)流量:</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> tc filter add dev ppp0 parent 1:0 protocol ip prio 10 u32 \</span><br><span class="line">match ip tos 0x10 0xff flowid 1:4</span><br></pre></td></tr></table></figure>
<p>  高吞吐流量(bulk traffic)对应的过滤条件是 0x08 0xff。</p>
</li>
</ul>
<p>更多过滤相关的命令(filtering commands),见 Advanced Filters 章节。</p>

        
    </section>
</article>



<div class="comments">
    <div id="disqus_thread">
        <p class="comment-tips">国内查看评论需要代理~</p>
    </div>
    <script>
    window.disqus_config = function () {
        this.language = 'zh';
        this.page.url = 'http://www.coderss.cn/2022/01/23/linux-tc/';
        this.page.title = 'Linux-tc-qdisc管理网络带宽';
        this.page.identifier = '2022/01/23/linux-tc/';
    };
    (function() { // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');
        s.src = 'https://name.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

</div>
        <footer class="footer">
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, Theme by <a href="https://github.com/sanonz/hexo-theme-concise" target="_blank">Concise</a>
</footer>

<script type="text/javascript" src="//s13.cnzz.com/z_stat.php?id=1234567890&amp;web_id=1234567890"></script>


    </div>

    <script type="text/javascript" src="https://cdn.bootcss.com/jquery/1.9.0/jquery.min.js"></script>
    
    <script type="text/javascript" src="/js/scrollspy.min.js"></script>
    
    <script type="text/javascript">
        $(function() {
            var nodes = {
                nav: $('#nav'),
                aside: $('#aside'),
                navTags: $('#nav-tags')
            };

            $('#open-panel, #aside-mask').on('click', function() {
                nodes.aside.toggleClass('panel-show');
            });
            $('#nav-tag').on('click', function(event) {
                event.preventDefault();console.log(nodes.navTags.attr('class'))
                nodes.navTags.toggleClass('tag-show');console.log(nodes.navTags.attr('class'))
            })/*.hover(function() {
                nodes.navTags.addClass('tag-show');
            }, function() {
                nodes.navTags.removeClass('tag-show');
            });*/

            
            $(document.body).scrollspy({target: '#aside-inner'});
            
        });
    </script>

</body>
</html>
